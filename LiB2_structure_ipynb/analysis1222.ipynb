{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1dc6e9-c789-4af0-ab4c-85da1da82c7e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing: Al_Metal_md_300K.traj\n",
      "  -> Total Al: 996, Surface: 76, Bulk: 920\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from ase.io.trajectory import Trajectory\n",
    "from ase.geometry import get_distances  # 直接インポート\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 全体のフォントサイズ設定\n",
    "plt.rcParams.update({\n",
    "    'font.size': 14, \n",
    "    'axes.labelsize': 16, \n",
    "    'xtick.labelsize': 14, \n",
    "    'ytick.labelsize': 14,\n",
    "    'legend.fontsize': 12\n",
    "})\n",
    "\n",
    "# --- RDFを手動で計算する関数 ---\n",
    "def compute_manual_rdf(atoms, indices1, indices2, rmax=6.0, nbins=100):\n",
    "    if len(indices1) == 0 or len(indices2) == 0:\n",
    "        return np.zeros(nbins), np.linspace(0, rmax, nbins+1)\n",
    "    \n",
    "    # 1次元配列であることを保証\n",
    "    idx1 = indices1.flatten()\n",
    "    idx2 = indices2.flatten()\n",
    "    \n",
    "    p1 = atoms.positions[idx1]\n",
    "    p2 = atoms.positions[idx2]\n",
    "\n",
    "    # 距離の計算\n",
    "    _, dists = get_distances(p1, p2, cell=atoms.cell, pbc=atoms.pbc)\n",
    "    \n",
    "    # 自己相関排除 (同じ原子ID同士の距離0を除外)\n",
    "    valid_dists = dists[dists > 0.01] if np.array_equal(idx1, idx2) else dists\n",
    "    \n",
    "    hist, bin_edges = np.histogram(valid_dists, range=(0, rmax), bins=nbins)\n",
    "    return hist, bin_edges\n",
    "\n",
    "def analyze_md_results(traj_path, output_dir, label):\n",
    "    print(f\"Analyzing: {traj_path.name}\")\n",
    "    try:\n",
    "        traj = Trajectory(traj_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\"); return\n",
    "\n",
    "    if len(traj) == 0: return\n",
    "\n",
    "    # --- 基本情報の取得 ---\n",
    "    initial_atoms = traj[0] # 初期構造\n",
    "    final_atoms = traj[-1]\n",
    "    cell_vol = final_atoms.get_volume()\n",
    "    cell_diag = final_atoms.get_cell().diagonal()\n",
    "    symbols = np.array(final_atoms.get_chemical_symbols())\n",
    "    \n",
    "    indices = {s: np.where(symbols == s)[0] for s in ['Al', 'O', 'Li', 'H','F']}\n",
    "    \n",
    "    # --- 表面/内部 Alの分類 (初期配置のZ座標で判定) ---\n",
    "    surface_al_indices = []\n",
    "    bulk_al_indices = []\n",
    "    if len(indices['Al']) > 0:\n",
    "        al_positions = initial_atoms.positions[indices['Al']]\n",
    "        z_max = np.max(al_positions[:, 2])\n",
    "        # 最表面から 4.0 Angstrom 以内を「表面」と定義\n",
    "        surface_mask = al_positions[:, 2] > (z_max - 4.0)\n",
    "        surface_al_indices = indices['Al'][surface_mask]\n",
    "        bulk_al_indices = indices['Al'][~surface_mask]\n",
    "\n",
    "    print(f\"  -> Total Al: {len(indices['Al'])}, Surface: {len(surface_al_indices)}, Bulk: {len(bulk_al_indices)}\")\n",
    "\n",
    "    # --- データ蓄積用リスト ---\n",
    "    time_points = []   # 時間 (ps)\n",
    "    \n",
    "    # 配位数関連\n",
    "    cn_avg_list = []      # 平均配位数\n",
    "    reacted_al_list = []  # 反応した(CN>=1) Alの数\n",
    "    \n",
    "    # MSD関連\n",
    "    msd_total_list = []\n",
    "    msd_surface_list = []\n",
    "    msd_bulk_list = []\n",
    "    \n",
    "    # 分子生成関連 (H2)\n",
    "    h2_count_list = []\n",
    "\n",
    "    # RDF用\n",
    "    rdf_rmax = 6.0\n",
    "    rdf_nbins = 100\n",
    "    rdf_sum = np.zeros(rdf_nbins)\n",
    "    rdf_count = 0\n",
    "    start_rdf_frame = int(len(traj) * 0.5)\n",
    "\n",
    "    # 初期位置の保存 (flattenで1次元化を保証)\n",
    "    idx_al_total = indices['Al'].flatten()\n",
    "    idx_al_surface = surface_al_indices.flatten() if len(surface_al_indices) > 0 else np.array([])\n",
    "    idx_al_bulk = bulk_al_indices.flatten() if len(bulk_al_indices) > 0 else np.array([])\n",
    "    \n",
    "    initial_pos_total = initial_atoms.positions[idx_al_total] if len(idx_al_total) > 0 else None\n",
    "    initial_pos_surface = initial_atoms.positions[idx_al_surface] if len(idx_al_surface) > 0 else None\n",
    "    initial_pos_bulk = initial_atoms.positions[idx_al_bulk] if len(idx_al_bulk) > 0 else None\n",
    "\n",
    "    # 時間計算の設定\n",
    "    # 例: 40000 stepsで40ps。trajに80フレームある場合、1フレーム=0.5ps\n",
    "    total_sim_time_ps = 40.0 # シミュレーション総時間 (ps) ※適宜変更してください\n",
    "    dt_ps = total_sim_time_ps / max(len(traj), 1)\n",
    "\n",
    "    for i, atoms in enumerate(traj):\n",
    "        current_time = i * dt_ps\n",
    "        time_points.append(current_time)\n",
    "\n",
    "        # 1. 配位数解析 (Al-O) - 【修正箇所】\n",
    "        current_cn_avg = 0\n",
    "        current_reacted_count = 0\n",
    "        \n",
    "        idx_al = indices['Al'].flatten()\n",
    "        idx_o = indices['O'].flatten()\n",
    "\n",
    "        if len(idx_al) > 0 and len(idx_o) > 0:\n",
    "            # ase.geometry.get_distances で計算 (戻り値はフラットな配列)\n",
    "            p1 = atoms.positions[idx_al]\n",
    "            p2 = atoms.positions[idx_o]\n",
    "            _, d_len = get_distances(p1, p2, cell=atoms.cell, pbc=atoms.pbc)\n",
    "            \n",
    "            # (N_Al, N_O) の行列に整形\n",
    "            d_matrix = d_len.reshape(len(idx_al), len(idx_o))\n",
    "            \n",
    "            # 各Al原子ごとのOの数 (2.5A以内)\n",
    "            cn_per_atom = np.sum(d_matrix < 2.5, axis=1)\n",
    "            \n",
    "            current_cn_avg = np.mean(cn_per_atom)\n",
    "            current_reacted_count = np.sum(cn_per_atom >= 1) # 1つ以上酸素がついているAlの数\n",
    "\n",
    "        cn_avg_list.append(current_cn_avg)\n",
    "        reacted_al_list.append(current_reacted_count)\n",
    "\n",
    "        # 2. MSD計算 (Total, Surface, Bulk)\n",
    "        def calc_msd(current_atoms_pos, init_pos):\n",
    "            if init_pos is None or len(init_pos) == 0: return 0\n",
    "            diff = current_atoms_pos - init_pos\n",
    "            return np.mean(np.sum(diff**2, axis=1))\n",
    "\n",
    "        if len(idx_al_total) > 0:\n",
    "            msd_total_list.append(calc_msd(atoms.positions[idx_al_total], initial_pos_total))\n",
    "        else:\n",
    "            msd_total_list.append(0)\n",
    "            \n",
    "        if len(idx_al_surface) > 0:\n",
    "            msd_surface_list.append(calc_msd(atoms.positions[idx_al_surface], initial_pos_surface))\n",
    "        else:\n",
    "            msd_surface_list.append(0)\n",
    "\n",
    "        if len(idx_al_bulk) > 0:\n",
    "            msd_bulk_list.append(calc_msd(atoms.positions[idx_al_bulk], initial_pos_bulk))\n",
    "        else:\n",
    "            msd_bulk_list.append(0)\n",
    "\n",
    "        # 3. 水素分子(H2)検出\n",
    "        h2_count = 0\n",
    "        idx_h = indices['H'].flatten()\n",
    "        if len(idx_h) > 1:\n",
    "            p_h = atoms.positions[idx_h]\n",
    "            _, h_dists = get_distances(p_h, p_h, cell=atoms.cell, pbc=atoms.pbc)\n",
    "            # 自己距離(0)を除外\n",
    "            valid_h = h_dists[h_dists > 0.01]\n",
    "            # ペア数なので2で割る\n",
    "            h2_count = np.sum(valid_h < 0.85) // 2 \n",
    "        h2_count_list.append(h2_count)\n",
    "\n",
    "        # 4. RDF積算\n",
    "        if i >= start_rdf_frame:\n",
    "            hist, edges = compute_manual_rdf(atoms, indices['Al'], indices['O'], rmax=rdf_rmax, nbins=rdf_nbins)\n",
    "            rdf_sum += hist\n",
    "            rdf_count += 1\n",
    "            bin_edges = edges\n",
    "\n",
    "    # --- CSV出力 1: 時系列データ (Trends) ---\n",
    "    df_trends = pd.DataFrame({\n",
    "        'Time_ps': time_points,\n",
    "        'CN_Avg': cn_avg_list,\n",
    "        'Reacted_Al_Count': reacted_al_list,\n",
    "        'H2_Count': h2_count_list,\n",
    "        'MSD_Total': msd_total_list,\n",
    "        'MSD_Surface': msd_surface_list,\n",
    "        'MSD_Bulk': msd_bulk_list\n",
    "    })\n",
    "    df_trends.to_csv(output_dir / f\"{label}_trends.csv\", index=False)\n",
    "\n",
    "    # --- グラフ描画 (Time軸) ---\n",
    "    \n",
    "    # Plot 1: MSD (Surface vs Bulk)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(time_points, msd_surface_list, label='Surface Al', color='red', lw=2)\n",
    "    plt.plot(time_points, msd_bulk_list, label='Bulk Al', color='blue', linestyle='--', lw=1)\n",
    "    plt.plot(time_points, msd_total_list, label='Total Al', color='gray', alpha=0.5)\n",
    "    plt.xlabel(\"Time (ps)\"); plt.ylabel(\"MSD ($\\AA^2$)\")\n",
    "    plt.title(f\"MSD Analysis: {label}\")\n",
    "    plt.legend(); plt.grid(True)\n",
    "    plt.savefig(output_dir / f\"{label}_msd_detailed.png\"); plt.close()\n",
    "\n",
    "    # Plot 2: Reaction Progress (Reacted Count & H2)\n",
    "    fig, ax1 = plt.subplots(figsize=(8, 6))\n",
    "    ax2 = ax1.twinx()\n",
    "    ax1.plot(time_points, reacted_al_list, 'g-', label='Reacted Al Count (CN>=1)', lw=2)\n",
    "    ax2.plot(time_points, h2_count_list, 'm--', label='H2 Molecule Count', lw=2)\n",
    "    ax1.set_xlabel(\"Time (ps)\")\n",
    "    ax1.set_ylabel(\"Count (Al atoms)\", color='g')\n",
    "    ax2.set_ylabel(\"Count (H2 molecules)\", color='m')\n",
    "    lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "    ax1.legend(lines1 + lines2, labels1 + labels2, loc='upper left')\n",
    "    plt.title(f\"Reaction Progress: {label}\")\n",
    "    plt.savefig(output_dir / f\"{label}_reaction.png\"); plt.close()\n",
    "\n",
    "    # Plot 3: Density Profile\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    density_data = {}\n",
    "    bins_z = np.linspace(0, cell_diag[2], 101)\n",
    "    bin_centers_z = 0.5 * (bins_z[1:] + bins_z[:-1])\n",
    "    density_data['Z_axis'] = bin_centers_z\n",
    "    for spec, idx in indices.items():\n",
    "        idx_flat = idx.flatten()\n",
    "        if len(idx_flat) > 0:\n",
    "            hist_vals, _ = np.histogram(final_atoms.positions[idx_flat, 2], bins=bins_z)\n",
    "            density_data[spec] = hist_vals\n",
    "            plt.plot(bin_centers_z, hist_vals, label=spec, lw=2)\n",
    "    pd.DataFrame(density_data).to_csv(output_dir / f\"{label}_density.csv\", index=False)\n",
    "    plt.title(f\"Density: {label}\"); plt.xlabel(\"Z (Å)\"); plt.legend()\n",
    "    plt.savefig(output_dir / f\"{label}_density.png\"); plt.close()\n",
    "\n",
    "    # Plot 4: RDF\n",
    "    if rdf_count > 0:\n",
    "        r = 0.5 * (bin_edges[1:] + bin_edges[:-1])\n",
    "        dr = bin_edges[1] - bin_edges[0]\n",
    "        rho = len(indices['O']) / cell_vol\n",
    "        shell_vol = 4 * np.pi * r**2 * dr\n",
    "        gr = (rdf_sum / rdf_count) / (len(indices['Al']) * shell_vol * rho)\n",
    "        pd.DataFrame({'r': r, 'g_r': gr}).to_csv(output_dir / f\"{label}_rdf_Al_O.csv\", index=False)\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        plt.plot(r, gr, color='blue', lw=2)\n",
    "        plt.title(f\"RDF Al-O: {label}\"); plt.xlabel(\"r (Å)\"); plt.ylabel(\"g(r)\"); plt.grid(True)\n",
    "        plt.savefig(output_dir / f\"{label}_rdf_Al_O.png\"); plt.close()\n",
    "\n",
    "    print(f\"   -> Finished {label}\")\n",
    "\n",
    "def main_analysis():\n",
    "    base_dir = Path(\"/home/jovyan/Kaori/MD/LiB_2/structure/Al_LiOH_v4_NPT\")\n",
    "    analysis_dir = base_dir / \"analysis_results\"\n",
    "    analysis_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    for target in [\"Al_Metal\", \"Al_Oxide\"]:\n",
    "        for temp in [300, 400, 500, 600, 750, 900]:\n",
    "            traj_file = base_dir / f\"{target}_md_{temp}K.traj\"\n",
    "            if traj_file.exists():\n",
    "                analyze_md_results(traj_file, analysis_dir, f\"{target}_{temp}K\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43a8776-d28e-4034-8a81-c377cc557df6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0339b67-6374-4a4c-acf3-03915772f843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing: Al_Metal_md_300K.traj\n",
      "  -> Total Al: 996, Surface: 89, Bulk: 907\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from ase.io.trajectory import Trajectory\n",
    "from ase.geometry import get_distances  # 直接インポート\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 全体のフォントサイズ設定\n",
    "plt.rcParams.update({\n",
    "    'font.size': 14, \n",
    "    'axes.labelsize': 16, \n",
    "    'xtick.labelsize': 14, \n",
    "    'ytick.labelsize': 14,\n",
    "    'legend.fontsize': 12\n",
    "})\n",
    "\n",
    "# --- RDFを手動で計算する関数 ---\n",
    "def compute_manual_rdf(atoms, indices1, indices2, rmax=6.0, nbins=100):\n",
    "    if len(indices1) == 0 or len(indices2) == 0:\n",
    "        return np.zeros(nbins), np.linspace(0, rmax, nbins+1)\n",
    "    \n",
    "    # 1次元配列であることを保証\n",
    "    idx1 = indices1.flatten()\n",
    "    idx2 = indices2.flatten()\n",
    "    \n",
    "    p1 = atoms.positions[idx1]\n",
    "    p2 = atoms.positions[idx2]\n",
    "\n",
    "    # 距離の計算\n",
    "    _, dists = get_distances(p1, p2, cell=atoms.cell, pbc=atoms.pbc)\n",
    "    \n",
    "    # 自己相関排除 (同じ原子ID同士の距離0を除外)\n",
    "    valid_dists = dists[dists > 0.01] if np.array_equal(idx1, idx2) else dists\n",
    "    \n",
    "    hist, bin_edges = np.histogram(valid_dists, range=(0, rmax), bins=nbins)\n",
    "    return hist, bin_edges\n",
    "\n",
    "def analyze_md_results(traj_path, output_dir, label):\n",
    "    print(f\"Analyzing: {traj_path.name}\")\n",
    "    try:\n",
    "        traj = Trajectory(traj_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\"); return\n",
    "\n",
    "    if len(traj) == 0: return\n",
    "\n",
    "    # --- 基本情報の取得 ---\n",
    "    initial_atoms = traj[0] # 初期構造\n",
    "    final_atoms = traj[-1]\n",
    "    cell_vol = final_atoms.get_volume()\n",
    "    cell_diag = final_atoms.get_cell().diagonal()\n",
    "    symbols = np.array(final_atoms.get_chemical_symbols())\n",
    "    \n",
    "    indices = {s: np.where(symbols == s)[0] for s in ['Al', 'O', 'Li', 'H','F']}\n",
    "    \n",
    "    # --- 表面/内部 Alの分類 (初期配置のZ座標で判定) ---\n",
    "    surface_al_indices = []\n",
    "    bulk_al_indices = []\n",
    "    if len(indices['Al']) > 0:\n",
    "        al_positions = initial_atoms.positions[indices['Al']]\n",
    "        z_max = np.max(al_positions[:, 2])\n",
    "        # 最表面から 4.0 Angstrom 以内を「表面」と定義\n",
    "        surface_mask = al_positions[:, 2] > (z_max - 4.0)\n",
    "        surface_al_indices = indices['Al'][surface_mask]\n",
    "        bulk_al_indices = indices['Al'][~surface_mask]\n",
    "\n",
    "    print(f\"  -> Total Al: {len(indices['Al'])}, Surface: {len(surface_al_indices)}, Bulk: {len(bulk_al_indices)}\")\n",
    "\n",
    "    # --- データ蓄積用リスト ---\n",
    "    time_points = []   # 時間 (ps)\n",
    "    \n",
    "    # 配位数関連\n",
    "    cn_avg_list = []      # 平均配位数\n",
    "    reacted_al_list = []  # 反応した(CN>=1) Alの数\n",
    "    \n",
    "    # MSD関連\n",
    "    msd_total_list = []\n",
    "    msd_surface_list = []\n",
    "    msd_bulk_list = []\n",
    "    \n",
    "    # 分子生成関連 (H2)\n",
    "    h2_count_list = []\n",
    "\n",
    "    # RDF用\n",
    "    rdf_rmax = 6.0\n",
    "    rdf_nbins = 100\n",
    "    rdf_sum = np.zeros(rdf_nbins)\n",
    "    rdf_count = 0\n",
    "    start_rdf_frame = int(len(traj) * 0.5)\n",
    "\n",
    "    # 初期位置の保存 (flattenで1次元化を保証)\n",
    "    idx_al_total = indices['Al'].flatten()\n",
    "    idx_al_surface = surface_al_indices.flatten() if len(surface_al_indices) > 0 else np.array([])\n",
    "    idx_al_bulk = bulk_al_indices.flatten() if len(bulk_al_indices) > 0 else np.array([])\n",
    "    \n",
    "    initial_pos_total = initial_atoms.positions[idx_al_total] if len(idx_al_total) > 0 else None\n",
    "    initial_pos_surface = initial_atoms.positions[idx_al_surface] if len(idx_al_surface) > 0 else None\n",
    "    initial_pos_bulk = initial_atoms.positions[idx_al_bulk] if len(idx_al_bulk) > 0 else None\n",
    "\n",
    "    # 時間計算の設定\n",
    "    # 例: 40000 stepsで40ps。trajに80フレームある場合、1フレーム=0.5ps\n",
    "    total_sim_time_ps = 40.0 # シミュレーション総時間 (ps) ※適宜変更してください\n",
    "    dt_ps = total_sim_time_ps / max(len(traj), 1)\n",
    "\n",
    "    for i, atoms in enumerate(traj):\n",
    "        current_time = i * dt_ps\n",
    "        time_points.append(current_time)\n",
    "\n",
    "        # 1. 配位数解析 (Al-O) - 【修正箇所】\n",
    "        current_cn_avg = 0\n",
    "        current_reacted_count = 0\n",
    "        \n",
    "        idx_al = indices['Al'].flatten()\n",
    "        idx_o = indices['O'].flatten()\n",
    "\n",
    "        if len(idx_al) > 0 and len(idx_o) > 0:\n",
    "            # ase.geometry.get_distances で計算 (戻り値はフラットな配列)\n",
    "            p1 = atoms.positions[idx_al]\n",
    "            p2 = atoms.positions[idx_o]\n",
    "            _, d_len = get_distances(p1, p2, cell=atoms.cell, pbc=atoms.pbc)\n",
    "            \n",
    "            # (N_Al, N_O) の行列に整形\n",
    "            d_matrix = d_len.reshape(len(idx_al), len(idx_o))\n",
    "            \n",
    "            # 各Al原子ごとのOの数 (2.5A以内)\n",
    "            cn_per_atom = np.sum(d_matrix < 2.5, axis=1)\n",
    "            \n",
    "            current_cn_avg = np.mean(cn_per_atom)\n",
    "            current_reacted_count = np.sum(cn_per_atom >= 1) # 1つ以上酸素がついているAlの数\n",
    "\n",
    "        cn_avg_list.append(current_cn_avg)\n",
    "        reacted_al_list.append(current_reacted_count)\n",
    "\n",
    "        # 2. MSD計算 (Total, Surface, Bulk)\n",
    "        def calc_msd(current_atoms_pos, init_pos):\n",
    "            if init_pos is None or len(init_pos) == 0: return 0\n",
    "            diff = current_atoms_pos - init_pos\n",
    "            return np.mean(np.sum(diff**2, axis=1))\n",
    "\n",
    "        if len(idx_al_total) > 0:\n",
    "            msd_total_list.append(calc_msd(atoms.positions[idx_al_total], initial_pos_total))\n",
    "        else:\n",
    "            msd_total_list.append(0)\n",
    "            \n",
    "        if len(idx_al_surface) > 0:\n",
    "            msd_surface_list.append(calc_msd(atoms.positions[idx_al_surface], initial_pos_surface))\n",
    "        else:\n",
    "            msd_surface_list.append(0)\n",
    "\n",
    "        if len(idx_al_bulk) > 0:\n",
    "            msd_bulk_list.append(calc_msd(atoms.positions[idx_al_bulk], initial_pos_bulk))\n",
    "        else:\n",
    "            msd_bulk_list.append(0)\n",
    "\n",
    "        # 3. 水素分子(H2)検出\n",
    "        h2_count = 0\n",
    "        idx_h = indices['H'].flatten()\n",
    "        if len(idx_h) > 1:\n",
    "            p_h = atoms.positions[idx_h]\n",
    "            _, h_dists = get_distances(p_h, p_h, cell=atoms.cell, pbc=atoms.pbc)\n",
    "            # 自己距離(0)を除外\n",
    "            valid_h = h_dists[h_dists > 0.01]\n",
    "            # ペア数なので2で割る\n",
    "            h2_count = np.sum(valid_h < 0.85) // 2 \n",
    "        h2_count_list.append(h2_count)\n",
    "\n",
    "        # 4. RDF積算\n",
    "        if i >= start_rdf_frame:\n",
    "            hist, edges = compute_manual_rdf(atoms, indices['Al'], indices['O'], rmax=rdf_rmax, nbins=rdf_nbins)\n",
    "            rdf_sum += hist\n",
    "            rdf_count += 1\n",
    "            bin_edges = edges\n",
    "\n",
    "    # --- CSV出力 1: 時系列データ (Trends) ---\n",
    "    df_trends = pd.DataFrame({\n",
    "        'Time_ps': time_points,\n",
    "        'CN_Avg': cn_avg_list,\n",
    "        'Reacted_Al_Count': reacted_al_list,\n",
    "        'H2_Count': h2_count_list,\n",
    "        'MSD_Total': msd_total_list,\n",
    "        'MSD_Surface': msd_surface_list,\n",
    "        'MSD_Bulk': msd_bulk_list\n",
    "    })\n",
    "    df_trends.to_csv(output_dir / f\"{label}_trends.csv\", index=False)\n",
    "\n",
    "    # --- グラフ描画 (Time軸) ---\n",
    "    \n",
    "    # Plot 1: MSD (Surface vs Bulk)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(time_points, msd_surface_list, label='Surface Al', color='red', lw=2)\n",
    "    plt.plot(time_points, msd_bulk_list, label='Bulk Al', color='blue', linestyle='--', lw=1)\n",
    "    plt.plot(time_points, msd_total_list, label='Total Al', color='gray', alpha=0.5)\n",
    "    plt.xlabel(\"Time (ps)\"); plt.ylabel(\"MSD ($\\AA^2$)\")\n",
    "    plt.title(f\"MSD Analysis: {label}\")\n",
    "    plt.legend(); plt.grid(True)\n",
    "    plt.savefig(output_dir / f\"{label}_msd_detailed.png\"); plt.close()\n",
    "\n",
    "    # Plot 2: Reaction Progress (Reacted Count & H2)\n",
    "    fig, ax1 = plt.subplots(figsize=(8, 6))\n",
    "    ax2 = ax1.twinx()\n",
    "    ax1.plot(time_points, reacted_al_list, 'g-', label='Reacted Al Count (CN>=1)', lw=2)\n",
    "    ax2.plot(time_points, h2_count_list, 'm--', label='H2 Molecule Count', lw=2)\n",
    "    ax1.set_xlabel(\"Time (ps)\")\n",
    "    ax1.set_ylabel(\"Count (Al atoms)\", color='g')\n",
    "    ax2.set_ylabel(\"Count (H2 molecules)\", color='m')\n",
    "    lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "    ax1.legend(lines1 + lines2, labels1 + labels2, loc='upper left')\n",
    "    plt.title(f\"Reaction Progress: {label}\")\n",
    "    plt.savefig(output_dir / f\"{label}_reaction.png\"); plt.close()\n",
    "\n",
    "    # Plot 3: Density Profile\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    density_data = {}\n",
    "    bins_z = np.linspace(0, cell_diag[2], 101)\n",
    "    bin_centers_z = 0.5 * (bins_z[1:] + bins_z[:-1])\n",
    "    density_data['Z_axis'] = bin_centers_z\n",
    "    for spec, idx in indices.items():\n",
    "        idx_flat = idx.flatten()\n",
    "        if len(idx_flat) > 0:\n",
    "            hist_vals, _ = np.histogram(final_atoms.positions[idx_flat, 2], bins=bins_z)\n",
    "            density_data[spec] = hist_vals\n",
    "            plt.plot(bin_centers_z, hist_vals, label=spec, lw=2)\n",
    "    pd.DataFrame(density_data).to_csv(output_dir / f\"{label}_density.csv\", index=False)\n",
    "    plt.title(f\"Density: {label}\"); plt.xlabel(\"Z (Å)\"); plt.legend()\n",
    "    plt.savefig(output_dir / f\"{label}_density.png\"); plt.close()\n",
    "\n",
    "    # Plot 4: RDF\n",
    "    if rdf_count > 0:\n",
    "        r = 0.5 * (bin_edges[1:] + bin_edges[:-1])\n",
    "        dr = bin_edges[1] - bin_edges[0]\n",
    "        rho = len(indices['O']) / cell_vol\n",
    "        shell_vol = 4 * np.pi * r**2 * dr\n",
    "        gr = (rdf_sum / rdf_count) / (len(indices['Al']) * shell_vol * rho)\n",
    "        pd.DataFrame({'r': r, 'g_r': gr}).to_csv(output_dir / f\"{label}_rdf_Al_O.csv\", index=False)\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        plt.plot(r, gr, color='blue', lw=2)\n",
    "        plt.title(f\"RDF Al-O: {label}\"); plt.xlabel(\"r (Å)\"); plt.ylabel(\"g(r)\"); plt.grid(True)\n",
    "        plt.savefig(output_dir / f\"{label}_rdf_Al_O.png\"); plt.close()\n",
    "\n",
    "    print(f\"   -> Finished {label}\")\n",
    "\n",
    "def main_analysis():\n",
    "    base_dir = Path(\"/home/jovyan/Kaori/MD/LiB_2/structure/Al_Li_F\")\n",
    "    analysis_dir = base_dir / \"analysis_results\"\n",
    "    analysis_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    for target in [\"Al_Metal\", \"Al_Oxide\"]:\n",
    "        for temp in [300, 400, 500, 600, 750, 900]:\n",
    "            traj_file = base_dir / f\"{target}_md_{temp}K.traj\"\n",
    "            if traj_file.exists():\n",
    "                analyze_md_results(traj_file, analysis_dir, f\"{target}_{temp}K\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d36c73-2b38-44de-890e-bfb658d7caba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee62f917-edfe-45ee-84ae-09775b95c3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing: Al_Oxide_md_300K.traj\n",
      "  -> Total Al: 608, Surface: 52, Bulk: 556\n",
      "   -> Finished Al_Oxide_300K\n",
      "Analyzing: Al_Oxide_md_400K.traj\n",
      "  -> Total Al: 608, Surface: 55, Bulk: 553\n",
      "   -> Finished Al_Oxide_400K\n",
      "Analyzing: Al_Oxide_md_500K.traj\n",
      "  -> Total Al: 608, Surface: 55, Bulk: 553\n",
      "   -> Finished Al_Oxide_500K\n",
      "Analyzing: Al_Oxide_md_600K.traj\n",
      "  -> Total Al: 608, Surface: 38, Bulk: 570\n",
      "   -> Finished Al_Oxide_600K\n",
      "Analyzing: Al_Oxide_md_750K.traj\n",
      "  -> Total Al: 608, Surface: 39, Bulk: 569\n",
      "   -> Finished Al_Oxide_750K\n",
      "Analyzing: Al_Oxide_md_900K.traj\n",
      "  -> Total Al: 608, Surface: 44, Bulk: 564\n",
      "   -> Finished Al_Oxide_900K\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from ase.io.trajectory import Trajectory\n",
    "from ase.geometry import get_distances  # 直接インポート\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 全体のフォントサイズ設定\n",
    "plt.rcParams.update({\n",
    "    'font.size': 20, \n",
    "    'axes.labelsize': 20, \n",
    "    'xtick.labelsize': 20, \n",
    "    'ytick.labelsize': 20,\n",
    "    'legend.fontsize': 20\n",
    "})\n",
    "\n",
    "# --- RDFを手動で計算する関数 ---\n",
    "def compute_manual_rdf(atoms, indices1, indices2, rmax=6.0, nbins=100):\n",
    "    if len(indices1) == 0 or len(indices2) == 0:\n",
    "        return np.zeros(nbins), np.linspace(0, rmax, nbins+1)\n",
    "    \n",
    "    # 1次元配列であることを保証\n",
    "    idx1 = indices1.flatten()\n",
    "    idx2 = indices2.flatten()\n",
    "    \n",
    "    p1 = atoms.positions[idx1]\n",
    "    p2 = atoms.positions[idx2]\n",
    "\n",
    "    # 距離の計算\n",
    "    _, dists = get_distances(p1, p2, cell=atoms.cell, pbc=atoms.pbc)\n",
    "    \n",
    "    # 自己相関排除 (同じ原子ID同士の距離0を除外)\n",
    "    valid_dists = dists[dists > 0.01] if np.array_equal(idx1, idx2) else dists\n",
    "    \n",
    "    hist, bin_edges = np.histogram(valid_dists, range=(0, rmax), bins=nbins)\n",
    "    return hist, bin_edges\n",
    "\n",
    "def analyze_md_results(traj_path, output_dir, label):\n",
    "    print(f\"Analyzing: {traj_path.name}\")\n",
    "    try:\n",
    "        traj = Trajectory(traj_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\"); return\n",
    "\n",
    "    if len(traj) == 0: return\n",
    "\n",
    "    # --- 基本情報の取得 ---\n",
    "    initial_atoms = traj[0] # 初期構造\n",
    "    final_atoms = traj[-1]\n",
    "    cell_vol = final_atoms.get_volume()\n",
    "    cell_diag = final_atoms.get_cell().diagonal()\n",
    "    symbols = np.array(final_atoms.get_chemical_symbols())\n",
    "    \n",
    "    indices = {s: np.where(symbols == s)[0] for s in ['Al', 'O', 'Li', 'H','F']}\n",
    "    \n",
    "    # --- 表面/内部 Alの分類 (初期配置のZ座標で判定) ---\n",
    "    surface_al_indices = []\n",
    "    bulk_al_indices = []\n",
    "    if len(indices['Al']) > 0:\n",
    "        al_positions = initial_atoms.positions[indices['Al']]\n",
    "        z_max = np.max(al_positions[:, 2])\n",
    "        # 最表面から 4.0 Angstrom 以内を「表面」と定義\n",
    "        surface_mask = al_positions[:, 2] > (z_max - 4.0)\n",
    "        surface_al_indices = indices['Al'][surface_mask]\n",
    "        bulk_al_indices = indices['Al'][~surface_mask]\n",
    "\n",
    "    print(f\"  -> Total Al: {len(indices['Al'])}, Surface: {len(surface_al_indices)}, Bulk: {len(bulk_al_indices)}\")\n",
    "\n",
    "    # --- データ蓄積用リスト ---\n",
    "    time_points = []   # 時間 (ps)\n",
    "    \n",
    "    # 配位数関連\n",
    "    cn_avg_list = []      # 平均配位数\n",
    "    reacted_al_list = []  # 反応した(CN>=1) Alの数\n",
    "    \n",
    "    # MSD関連\n",
    "    msd_total_list = []\n",
    "    msd_surface_list = []\n",
    "    msd_bulk_list = []\n",
    "    \n",
    "    # 分子生成関連 (H2)\n",
    "    h2_count_list = []\n",
    "\n",
    "    # RDF用\n",
    "    rdf_rmax = 6.0\n",
    "    rdf_nbins = 100\n",
    "    rdf_sum = np.zeros(rdf_nbins)\n",
    "    rdf_count = 0\n",
    "    start_rdf_frame = int(len(traj) * 0.5)\n",
    "\n",
    "    # 初期位置の保存 (flattenで1次元化を保証)\n",
    "    idx_al_total = indices['Al'].flatten()\n",
    "    idx_al_surface = surface_al_indices.flatten() if len(surface_al_indices) > 0 else np.array([])\n",
    "    idx_al_bulk = bulk_al_indices.flatten() if len(bulk_al_indices) > 0 else np.array([])\n",
    "    \n",
    "    initial_pos_total = initial_atoms.positions[idx_al_total] if len(idx_al_total) > 0 else None\n",
    "    initial_pos_surface = initial_atoms.positions[idx_al_surface] if len(idx_al_surface) > 0 else None\n",
    "    initial_pos_bulk = initial_atoms.positions[idx_al_bulk] if len(idx_al_bulk) > 0 else None\n",
    "\n",
    "    # 時間計算の設定\n",
    "    # 例: 40000 stepsで40ps。trajに80フレームある場合、1フレーム=0.5ps\n",
    "    total_sim_time_ps = 40.0 # シミュレーション総時間 (ps) ※適宜変更してください\n",
    "    dt_ps = total_sim_time_ps / max(len(traj), 1)\n",
    "\n",
    "    for i, atoms in enumerate(traj):\n",
    "        current_time = i * dt_ps\n",
    "        time_points.append(current_time)\n",
    "\n",
    "        # 1. 配位数解析 (Al-O) - 【修正箇所】\n",
    "        current_cn_avg = 0\n",
    "        current_reacted_count = 0\n",
    "        \n",
    "        idx_al = indices['Al'].flatten()\n",
    "        idx_o = indices['O'].flatten()\n",
    "\n",
    "        if len(idx_al) > 0 and len(idx_o) > 0:\n",
    "            # ase.geometry.get_distances で計算 (戻り値はフラットな配列)\n",
    "            p1 = atoms.positions[idx_al]\n",
    "            p2 = atoms.positions[idx_o]\n",
    "            _, d_len = get_distances(p1, p2, cell=atoms.cell, pbc=atoms.pbc)\n",
    "            \n",
    "            # (N_Al, N_O) の行列に整形\n",
    "            d_matrix = d_len.reshape(len(idx_al), len(idx_o))\n",
    "            \n",
    "            # 各Al原子ごとのOの数 (2.5A以内)\n",
    "            cn_per_atom = np.sum(d_matrix < 2.5, axis=1)\n",
    "            \n",
    "            current_cn_avg = np.mean(cn_per_atom)\n",
    "            current_reacted_count = np.sum(cn_per_atom >= 1) # 1つ以上酸素がついているAlの数\n",
    "\n",
    "        cn_avg_list.append(current_cn_avg)\n",
    "        reacted_al_list.append(current_reacted_count)\n",
    "\n",
    "        # 2. MSD計算 (Total, Surface, Bulk)\n",
    "        def calc_msd(current_atoms_pos, init_pos):\n",
    "            if init_pos is None or len(init_pos) == 0: return 0\n",
    "            diff = current_atoms_pos - init_pos\n",
    "            return np.mean(np.sum(diff**2, axis=1))\n",
    "\n",
    "        if len(idx_al_total) > 0:\n",
    "            msd_total_list.append(calc_msd(atoms.positions[idx_al_total], initial_pos_total))\n",
    "        else:\n",
    "            msd_total_list.append(0)\n",
    "            \n",
    "        if len(idx_al_surface) > 0:\n",
    "            msd_surface_list.append(calc_msd(atoms.positions[idx_al_surface], initial_pos_surface))\n",
    "        else:\n",
    "            msd_surface_list.append(0)\n",
    "\n",
    "        if len(idx_al_bulk) > 0:\n",
    "            msd_bulk_list.append(calc_msd(atoms.positions[idx_al_bulk], initial_pos_bulk))\n",
    "        else:\n",
    "            msd_bulk_list.append(0)\n",
    "\n",
    "        # 3. 水素分子(H2)検出\n",
    "        h2_count = 0\n",
    "        idx_h = indices['H'].flatten()\n",
    "        if len(idx_h) > 1:\n",
    "            p_h = atoms.positions[idx_h]\n",
    "            _, h_dists = get_distances(p_h, p_h, cell=atoms.cell, pbc=atoms.pbc)\n",
    "            # 自己距離(0)を除外\n",
    "            valid_h = h_dists[h_dists > 0.01]\n",
    "            # ペア数なので2で割る\n",
    "            h2_count = np.sum(valid_h < 0.85) // 2 \n",
    "        h2_count_list.append(h2_count)\n",
    "\n",
    "        # 4. RDF積算\n",
    "        if i >= start_rdf_frame:\n",
    "            hist, edges = compute_manual_rdf(atoms, indices['Al'], indices['O'], rmax=rdf_rmax, nbins=rdf_nbins)\n",
    "            rdf_sum += hist\n",
    "            rdf_count += 1\n",
    "            bin_edges = edges\n",
    "\n",
    "    # --- CSV出力 1: 時系列データ (Trends) ---\n",
    "    df_trends = pd.DataFrame({\n",
    "        'Time_ps': time_points,\n",
    "        'CN_Avg': cn_avg_list,\n",
    "        'Reacted_Al_Count': reacted_al_list,\n",
    "        'H2_Count': h2_count_list,\n",
    "        'MSD_Total': msd_total_list,\n",
    "        'MSD_Surface': msd_surface_list,\n",
    "        'MSD_Bulk': msd_bulk_list\n",
    "    })\n",
    "    df_trends.to_csv(output_dir / f\"{label}_trends.csv\", index=False)\n",
    "\n",
    "    # --- グラフ描画 (Time軸) ---\n",
    "    \n",
    "    # Plot 1: MSD (Surface vs Bulk)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(time_points, msd_surface_list, label='Surface Al', color='red', lw=2)\n",
    "    plt.plot(time_points, msd_bulk_list, label='Bulk Al', color='blue', linestyle='--', lw=1)\n",
    "    plt.plot(time_points, msd_total_list, label='Total Al', color='gray', alpha=0.5)\n",
    "    plt.xlabel(\"Time (ps)\"); plt.ylabel(\"MSD ($\\AA^2$)\")\n",
    "    plt.title(f\"MSD Analysis: {label}\")\n",
    "    plt.legend(); plt.grid(True)\n",
    "    plt.savefig(output_dir / f\"{label}_msd_detailed.png\"); plt.close()\n",
    "\n",
    "    # Plot 2: Reaction Progress (Reacted Count & H2)\n",
    "    fig, ax1 = plt.subplots(figsize=(8, 6))\n",
    "    ax2 = ax1.twinx()\n",
    "    ax1.plot(time_points, reacted_al_list, 'g-', label='Reacted Al Count (CN>=1)', lw=2)\n",
    "    ax2.plot(time_points, h2_count_list, 'm--', label='H2 Molecule Count', lw=2)\n",
    "    ax1.set_xlabel(\"Time (ps)\")\n",
    "    ax1.set_ylabel(\"Count (Al atoms)\", color='g')\n",
    "    ax2.set_ylabel(\"Count (H2 molecules)\", color='m')\n",
    "    lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "    ax1.legend(lines1 + lines2, labels1 + labels2, loc='upper left')\n",
    "    plt.title(f\"Reaction Progress: {label}\")\n",
    "    plt.savefig(output_dir / f\"{label}_reaction.png\"); plt.close()\n",
    "\n",
    "    # Plot 3: Density Profile\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    density_data = {}\n",
    "    bins_z = np.linspace(0, cell_diag[2], 101)\n",
    "    bin_centers_z = 0.5 * (bins_z[1:] + bins_z[:-1])\n",
    "    density_data['Z_axis'] = bin_centers_z\n",
    "    for spec, idx in indices.items():\n",
    "        idx_flat = idx.flatten()\n",
    "        if len(idx_flat) > 0:\n",
    "            hist_vals, _ = np.histogram(final_atoms.positions[idx_flat, 2], bins=bins_z)\n",
    "            density_data[spec] = hist_vals\n",
    "            plt.plot(bin_centers_z, hist_vals, label=spec, lw=2)\n",
    "    pd.DataFrame(density_data).to_csv(output_dir / f\"{label}_density.csv\", index=False)\n",
    "    plt.title(f\"Density: {label}\"); plt.xlabel(\"Z (Å)\"); plt.legend()\n",
    "    plt.savefig(output_dir / f\"{label}_density.png\"); plt.close()\n",
    "\n",
    "    # Plot 4: RDF\n",
    "    if rdf_count > 0:\n",
    "        r = 0.5 * (bin_edges[1:] + bin_edges[:-1])\n",
    "        dr = bin_edges[1] - bin_edges[0]\n",
    "        rho = len(indices['O']) / cell_vol\n",
    "        shell_vol = 4 * np.pi * r**2 * dr\n",
    "        gr = (rdf_sum / rdf_count) / (len(indices['Al']) * shell_vol * rho)\n",
    "        pd.DataFrame({'r': r, 'g_r': gr}).to_csv(output_dir / f\"{label}_rdf_Al_O.csv\", index=False)\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        plt.plot(r, gr, color='blue', lw=2)\n",
    "        plt.title(f\"RDF Al-O: {label}\"); plt.xlabel(\"r (Å)\"); plt.ylabel(\"g(r)\"); plt.grid(True)\n",
    "        plt.savefig(output_dir / f\"{label}_rdf_Al_O.png\"); plt.close()\n",
    "\n",
    "    print(f\"   -> Finished {label}\")\n",
    "\n",
    "def main_analysis():\n",
    "    base_dir = Path(\"/home/jovyan/Kaori/MD/LiB_2/structure/Al_Na_F_OH\")\n",
    "    analysis_dir = base_dir / \"analysis_results\"\n",
    "    analysis_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    for target in [ \"Al_Oxide\"]:\n",
    "        for temp in [300, 400, 500, 600, 750, 900]:\n",
    "            traj_file = base_dir / f\"{target}_md_{temp}K.traj\"\n",
    "            if traj_file.exists():\n",
    "                analyze_md_results(traj_file, analysis_dir, f\"{target}_{temp}K\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c7e431-cdb0-4acc-a11f-0ccf887abc77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a03cc28a-61cc-4b9b-a241-cbe545788ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:196: SyntaxWarning: invalid escape sequence '\\A'\n",
      "<>:196: SyntaxWarning: invalid escape sequence '\\A'\n",
      "/tmp/ipykernel_26002/2771888322.py:196: SyntaxWarning: invalid escape sequence '\\A'\n",
      "  plt.xlabel(\"Time (ps)\"); plt.ylabel(\"MSD ($\\AA^2$)\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing: Al_Metal_md_300K.traj\n",
      "  -> Total Al: 996, Surface: 130, Bulk: 866\n",
      "   -> Finished Al_Metal_300K\n",
      "Analyzing: Al_Metal_md_400K.traj\n",
      "  -> Total Al: 996, Surface: 118, Bulk: 878\n",
      "   -> Finished Al_Metal_400K\n",
      "Analyzing: Al_Metal_md_500K.traj\n",
      "  -> Total Al: 996, Surface: 92, Bulk: 904\n",
      "   -> Finished Al_Metal_500K\n",
      "Analyzing: Al_Oxide_md_300K.traj\n",
      "  -> Total Al: 608, Surface: 65, Bulk: 543\n",
      "   -> Finished Al_Oxide_300K\n",
      "Analyzing: Al_Oxide_md_400K.traj\n",
      "  -> Total Al: 608, Surface: 60, Bulk: 548\n",
      "   -> Finished Al_Oxide_400K\n",
      "Analyzing: Al_Oxide_md_500K.traj\n",
      "  -> Total Al: 608, Surface: 62, Bulk: 546\n",
      "   -> Finished Al_Oxide_500K\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from ase.io.trajectory import Trajectory\n",
    "from ase.geometry import get_distances  # 直接インポート\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 全体のフォントサイズ設定\n",
    "plt.rcParams.update({\n",
    "    'font.size': 14, \n",
    "    'axes.labelsize': 16, \n",
    "    'xtick.labelsize': 14, \n",
    "    'ytick.labelsize': 14,\n",
    "    'legend.fontsize': 12\n",
    "})\n",
    "\n",
    "# --- RDFを手動で計算する関数 ---\n",
    "def compute_manual_rdf(atoms, indices1, indices2, rmax=6.0, nbins=100):\n",
    "    if len(indices1) == 0 or len(indices2) == 0:\n",
    "        return np.zeros(nbins), np.linspace(0, rmax, nbins+1)\n",
    "    \n",
    "    # 1次元配列であることを保証\n",
    "    idx1 = indices1.flatten()\n",
    "    idx2 = indices2.flatten()\n",
    "    \n",
    "    p1 = atoms.positions[idx1]\n",
    "    p2 = atoms.positions[idx2]\n",
    "\n",
    "    # 距離の計算\n",
    "    _, dists = get_distances(p1, p2, cell=atoms.cell, pbc=atoms.pbc)\n",
    "    \n",
    "    # 自己相関排除 (同じ原子ID同士の距離0を除外)\n",
    "    valid_dists = dists[dists > 0.01] if np.array_equal(idx1, idx2) else dists\n",
    "    \n",
    "    hist, bin_edges = np.histogram(valid_dists, range=(0, rmax), bins=nbins)\n",
    "    return hist, bin_edges\n",
    "\n",
    "def analyze_md_results(traj_path, output_dir, label):\n",
    "    print(f\"Analyzing: {traj_path.name}\")\n",
    "    try:\n",
    "        traj = Trajectory(traj_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\"); return\n",
    "\n",
    "    if len(traj) == 0: return\n",
    "\n",
    "    # --- 基本情報の取得 ---\n",
    "    initial_atoms = traj[0] # 初期構造\n",
    "    final_atoms = traj[-1]\n",
    "    cell_vol = final_atoms.get_volume()\n",
    "    cell_diag = final_atoms.get_cell().diagonal()\n",
    "    symbols = np.array(final_atoms.get_chemical_symbols())\n",
    "    \n",
    "    indices = {s: np.where(symbols == s)[0] for s in ['Al', 'O', 'Li', 'H','F']}\n",
    "    \n",
    "    # --- 表面/内部 Alの分類 (初期配置のZ座標で判定) ---\n",
    "    surface_al_indices = []\n",
    "    bulk_al_indices = []\n",
    "    if len(indices['Al']) > 0:\n",
    "        al_positions = initial_atoms.positions[indices['Al']]\n",
    "        z_max = np.max(al_positions[:, 2])\n",
    "        # 最表面から 4.0 Angstrom 以内を「表面」と定義\n",
    "        surface_mask = al_positions[:, 2] > (z_max - 4.0)\n",
    "        surface_al_indices = indices['Al'][surface_mask]\n",
    "        bulk_al_indices = indices['Al'][~surface_mask]\n",
    "\n",
    "    print(f\"  -> Total Al: {len(indices['Al'])}, Surface: {len(surface_al_indices)}, Bulk: {len(bulk_al_indices)}\")\n",
    "\n",
    "    # --- データ蓄積用リスト ---\n",
    "    time_points = []   # 時間 (ps)\n",
    "    \n",
    "    # 配位数関連\n",
    "    cn_avg_list = []      # 平均配位数\n",
    "    reacted_al_list = []  # 反応した(CN>=1) Alの数\n",
    "    \n",
    "    # MSD関連\n",
    "    msd_total_list = []\n",
    "    msd_surface_list = []\n",
    "    msd_bulk_list = []\n",
    "    \n",
    "    # 分子生成関連 (H2)\n",
    "    h2_count_list = []\n",
    "\n",
    "    # RDF用\n",
    "    rdf_rmax = 6.0\n",
    "    rdf_nbins = 100\n",
    "    rdf_sum = np.zeros(rdf_nbins)\n",
    "    rdf_count = 0\n",
    "    start_rdf_frame = int(len(traj) * 0.5)\n",
    "\n",
    "    # 初期位置の保存 (flattenで1次元化を保証)\n",
    "    idx_al_total = indices['Al'].flatten()\n",
    "    idx_al_surface = surface_al_indices.flatten() if len(surface_al_indices) > 0 else np.array([])\n",
    "    idx_al_bulk = bulk_al_indices.flatten() if len(bulk_al_indices) > 0 else np.array([])\n",
    "    \n",
    "    initial_pos_total = initial_atoms.positions[idx_al_total] if len(idx_al_total) > 0 else None\n",
    "    initial_pos_surface = initial_atoms.positions[idx_al_surface] if len(idx_al_surface) > 0 else None\n",
    "    initial_pos_bulk = initial_atoms.positions[idx_al_bulk] if len(idx_al_bulk) > 0 else None\n",
    "\n",
    "    # 時間計算の設定\n",
    "    # 例: 40000 stepsで40ps。trajに80フレームある場合、1フレーム=0.5ps\n",
    "    total_sim_time_ps = 40.0 # シミュレーション総時間 (ps) ※適宜変更してください\n",
    "    dt_ps = total_sim_time_ps / max(len(traj), 1)\n",
    "\n",
    "    for i, atoms in enumerate(traj):\n",
    "        current_time = i * dt_ps\n",
    "        time_points.append(current_time)\n",
    "\n",
    "        # 1. 配位数解析 (Al-O) - 【修正箇所】\n",
    "        current_cn_avg = 0\n",
    "        current_reacted_count = 0\n",
    "        \n",
    "        idx_al = indices['Al'].flatten()\n",
    "        idx_o = indices['O'].flatten()\n",
    "\n",
    "        if len(idx_al) > 0 and len(idx_o) > 0:\n",
    "            # ase.geometry.get_distances で計算 (戻り値はフラットな配列)\n",
    "            p1 = atoms.positions[idx_al]\n",
    "            p2 = atoms.positions[idx_o]\n",
    "            _, d_len = get_distances(p1, p2, cell=atoms.cell, pbc=atoms.pbc)\n",
    "            \n",
    "            # (N_Al, N_O) の行列に整形\n",
    "            d_matrix = d_len.reshape(len(idx_al), len(idx_o))\n",
    "            \n",
    "            # 各Al原子ごとのOの数 (2.5A以内)\n",
    "            cn_per_atom = np.sum(d_matrix < 2.5, axis=1)\n",
    "            \n",
    "            current_cn_avg = np.mean(cn_per_atom)\n",
    "            current_reacted_count = np.sum(cn_per_atom >= 1) # 1つ以上酸素がついているAlの数\n",
    "\n",
    "        cn_avg_list.append(current_cn_avg)\n",
    "        reacted_al_list.append(current_reacted_count)\n",
    "\n",
    "        # 2. MSD計算 (Total, Surface, Bulk)\n",
    "        def calc_msd(current_atoms_pos, init_pos):\n",
    "            if init_pos is None or len(init_pos) == 0: return 0\n",
    "            diff = current_atoms_pos - init_pos\n",
    "            return np.mean(np.sum(diff**2, axis=1))\n",
    "\n",
    "        if len(idx_al_total) > 0:\n",
    "            msd_total_list.append(calc_msd(atoms.positions[idx_al_total], initial_pos_total))\n",
    "        else:\n",
    "            msd_total_list.append(0)\n",
    "            \n",
    "        if len(idx_al_surface) > 0:\n",
    "            msd_surface_list.append(calc_msd(atoms.positions[idx_al_surface], initial_pos_surface))\n",
    "        else:\n",
    "            msd_surface_list.append(0)\n",
    "\n",
    "        if len(idx_al_bulk) > 0:\n",
    "            msd_bulk_list.append(calc_msd(atoms.positions[idx_al_bulk], initial_pos_bulk))\n",
    "        else:\n",
    "            msd_bulk_list.append(0)\n",
    "\n",
    "        # 3. 水素分子(H2)検出\n",
    "        h2_count = 0\n",
    "        idx_h = indices['H'].flatten()\n",
    "        if len(idx_h) > 1:\n",
    "            p_h = atoms.positions[idx_h]\n",
    "            _, h_dists = get_distances(p_h, p_h, cell=atoms.cell, pbc=atoms.pbc)\n",
    "            # 自己距離(0)を除外\n",
    "            valid_h = h_dists[h_dists > 0.01]\n",
    "            # ペア数なので2で割る\n",
    "            h2_count = np.sum(valid_h < 0.85) // 2 \n",
    "        h2_count_list.append(h2_count)\n",
    "\n",
    "        # 4. RDF積算\n",
    "        if i >= start_rdf_frame:\n",
    "            hist, edges = compute_manual_rdf(atoms, indices['Al'], indices['O'], rmax=rdf_rmax, nbins=rdf_nbins)\n",
    "            rdf_sum += hist\n",
    "            rdf_count += 1\n",
    "            bin_edges = edges\n",
    "\n",
    "    # --- CSV出力 1: 時系列データ (Trends) ---\n",
    "    df_trends = pd.DataFrame({\n",
    "        'Time_ps': time_points,\n",
    "        'CN_Avg': cn_avg_list,\n",
    "        'Reacted_Al_Count': reacted_al_list,\n",
    "        'H2_Count': h2_count_list,\n",
    "        'MSD_Total': msd_total_list,\n",
    "        'MSD_Surface': msd_surface_list,\n",
    "        'MSD_Bulk': msd_bulk_list\n",
    "    })\n",
    "    df_trends.to_csv(output_dir / f\"{label}_trends.csv\", index=False)\n",
    "\n",
    "    # --- グラフ描画 (Time軸) ---\n",
    "    \n",
    "    # Plot 1: MSD (Surface vs Bulk)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(time_points, msd_surface_list, label='Surface Al', color='red', lw=2)\n",
    "    plt.plot(time_points, msd_bulk_list, label='Bulk Al', color='blue', linestyle='--', lw=1)\n",
    "    plt.plot(time_points, msd_total_list, label='Total Al', color='gray', alpha=0.5)\n",
    "    plt.xlabel(\"Time (ps)\"); plt.ylabel(\"MSD ($\\AA^2$)\")\n",
    "    plt.title(f\"MSD Analysis: {label}\")\n",
    "    plt.legend(); plt.grid(True)\n",
    "    plt.savefig(output_dir / f\"{label}_msd_detailed.png\"); plt.close()\n",
    "\n",
    "    # Plot 2: Reaction Progress (Reacted Count & H2)\n",
    "    fig, ax1 = plt.subplots(figsize=(8, 6))\n",
    "    ax2 = ax1.twinx()\n",
    "    ax1.plot(time_points, reacted_al_list, 'g-', label='Reacted Al Count (CN>=1)', lw=2)\n",
    "    ax2.plot(time_points, h2_count_list, 'm--', label='H2 Molecule Count', lw=2)\n",
    "    ax1.set_xlabel(\"Time (ps)\")\n",
    "    ax1.set_ylabel(\"Count (Al atoms)\", color='g')\n",
    "    ax2.set_ylabel(\"Count (H2 molecules)\", color='m')\n",
    "    lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "    ax1.legend(lines1 + lines2, labels1 + labels2, loc='upper left')\n",
    "    plt.title(f\"Reaction Progress: {label}\")\n",
    "    plt.savefig(output_dir / f\"{label}_reaction.png\"); plt.close()\n",
    "\n",
    "    # Plot 3: Density Profile\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    density_data = {}\n",
    "    bins_z = np.linspace(0, cell_diag[2], 101)\n",
    "    bin_centers_z = 0.5 * (bins_z[1:] + bins_z[:-1])\n",
    "    density_data['Z_axis'] = bin_centers_z\n",
    "    for spec, idx in indices.items():\n",
    "        idx_flat = idx.flatten()\n",
    "        if len(idx_flat) > 0:\n",
    "            hist_vals, _ = np.histogram(final_atoms.positions[idx_flat, 2], bins=bins_z)\n",
    "            density_data[spec] = hist_vals\n",
    "            plt.plot(bin_centers_z, hist_vals, label=spec, lw=2)\n",
    "    pd.DataFrame(density_data).to_csv(output_dir / f\"{label}_density.csv\", index=False)\n",
    "    plt.title(f\"Density: {label}\"); plt.xlabel(\"Z (Å)\"); plt.legend()\n",
    "    plt.savefig(output_dir / f\"{label}_density.png\"); plt.close()\n",
    "\n",
    "    # Plot 4: RDF\n",
    "    if rdf_count > 0:\n",
    "        r = 0.5 * (bin_edges[1:] + bin_edges[:-1])\n",
    "        dr = bin_edges[1] - bin_edges[0]\n",
    "        rho = len(indices['O']) / cell_vol\n",
    "        shell_vol = 4 * np.pi * r**2 * dr\n",
    "        gr = (rdf_sum / rdf_count) / (len(indices['Al']) * shell_vol * rho)\n",
    "        pd.DataFrame({'r': r, 'g_r': gr}).to_csv(output_dir / f\"{label}_rdf_Al_O.csv\", index=False)\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        plt.plot(r, gr, color='blue', lw=2)\n",
    "        plt.title(f\"RDF Al-O: {label}\"); plt.xlabel(\"r (Å)\"); plt.ylabel(\"g(r)\"); plt.grid(True)\n",
    "        plt.savefig(output_dir / f\"{label}_rdf_Al_O.png\"); plt.close()\n",
    "\n",
    "    print(f\"   -> Finished {label}\")\n",
    "\n",
    "def main_analysis():\n",
    "    base_dir = Path(\"/home/jovyan/Kaori/MD/LiB_2/structure/Al_LiOH_v8\")\n",
    "    analysis_dir = base_dir / \"analysis_results\"\n",
    "    analysis_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    for target in [\"Al_Metal\", \"Al_Oxide\"]:\n",
    "        for temp in [300, 400, 500, 600, 750, 900]:\n",
    "            traj_file = base_dir / f\"{target}_md_{temp}K.traj\"\n",
    "            if traj_file.exists():\n",
    "                analyze_md_results(traj_file, analysis_dir, f\"{target}_{temp}K\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4e1eef-479c-4b2d-a8ff-b699e1749898",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45e44ec-7d95-4b12-93da-8557c72e9dc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16cdff7d-68ea-49b2-a84d-7ae14a28cb0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing: Al_Metal_md_300K.traj\n",
      "  -> Total Al: 996, Surface: 93, Bulk: 903\n",
      "   -> Finished Al_Metal_300K\n",
      "Analyzing: Al_Metal_md_400K.traj\n",
      "  -> Total Al: 996, Surface: 74, Bulk: 922\n",
      "   -> Finished Al_Metal_400K\n",
      "Analyzing: Al_Metal_md_500K.traj\n",
      "  -> Total Al: 996, Surface: 51, Bulk: 945\n",
      "   -> Finished Al_Metal_500K\n",
      "Analyzing: Al_Metal_md_600K.traj\n",
      "  -> Total Al: 996, Surface: 52, Bulk: 944\n",
      "   -> Finished Al_Metal_600K\n",
      "Analyzing: Al_Metal_md_750K.traj\n",
      "  -> Total Al: 996, Surface: 46, Bulk: 950\n",
      "   -> Finished Al_Metal_750K\n",
      "Analyzing: Al_Metal_md_900K.traj\n",
      "  -> Total Al: 996, Surface: 2, Bulk: 994\n",
      "   -> Finished Al_Metal_900K\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from ase.io.trajectory import Trajectory\n",
    "from ase.geometry import get_distances  # 直接インポート\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 全体のフォントサイズ設定\n",
    "plt.rcParams.update({\n",
    "    'font.size': 14, \n",
    "    'axes.labelsize': 16, \n",
    "    'xtick.labelsize': 14, \n",
    "    'ytick.labelsize': 14,\n",
    "    'legend.fontsize': 12\n",
    "})\n",
    "\n",
    "# --- RDFを手動で計算する関数 ---\n",
    "def compute_manual_rdf(atoms, indices1, indices2, rmax=6.0, nbins=100):\n",
    "    if len(indices1) == 0 or len(indices2) == 0:\n",
    "        return np.zeros(nbins), np.linspace(0, rmax, nbins+1)\n",
    "    \n",
    "    # 1次元配列であることを保証\n",
    "    idx1 = indices1.flatten()\n",
    "    idx2 = indices2.flatten()\n",
    "    \n",
    "    p1 = atoms.positions[idx1]\n",
    "    p2 = atoms.positions[idx2]\n",
    "\n",
    "    # 距離の計算\n",
    "    _, dists = get_distances(p1, p2, cell=atoms.cell, pbc=atoms.pbc)\n",
    "    \n",
    "    # 自己相関排除 (同じ原子ID同士の距離0を除外)\n",
    "    valid_dists = dists[dists > 0.01] if np.array_equal(idx1, idx2) else dists\n",
    "    \n",
    "    hist, bin_edges = np.histogram(valid_dists, range=(0, rmax), bins=nbins)\n",
    "    return hist, bin_edges\n",
    "\n",
    "def analyze_md_results(traj_path, output_dir, label):\n",
    "    print(f\"Analyzing: {traj_path.name}\")\n",
    "    try:\n",
    "        traj = Trajectory(traj_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\"); return\n",
    "\n",
    "    if len(traj) == 0: return\n",
    "\n",
    "    # --- 基本情報の取得 ---\n",
    "    initial_atoms = traj[0] # 初期構造\n",
    "    final_atoms = traj[-1]\n",
    "    cell_vol = final_atoms.get_volume()\n",
    "    cell_diag = final_atoms.get_cell().diagonal()\n",
    "    symbols = np.array(final_atoms.get_chemical_symbols())\n",
    "    \n",
    "    indices = {s: np.where(symbols == s)[0] for s in ['Al', 'O', 'Li', 'H','F']}\n",
    "    \n",
    "    # --- 表面/内部 Alの分類 (初期配置のZ座標で判定) ---\n",
    "    surface_al_indices = []\n",
    "    bulk_al_indices = []\n",
    "    if len(indices['Al']) > 0:\n",
    "        al_positions = initial_atoms.positions[indices['Al']]\n",
    "        z_max = np.max(al_positions[:, 2])\n",
    "        # 最表面から 4.0 Angstrom 以内を「表面」と定義\n",
    "        surface_mask = al_positions[:, 2] > (z_max - 4.0)\n",
    "        surface_al_indices = indices['Al'][surface_mask]\n",
    "        bulk_al_indices = indices['Al'][~surface_mask]\n",
    "\n",
    "    print(f\"  -> Total Al: {len(indices['Al'])}, Surface: {len(surface_al_indices)}, Bulk: {len(bulk_al_indices)}\")\n",
    "\n",
    "    # --- データ蓄積用リスト ---\n",
    "    time_points = []   # 時間 (ps)\n",
    "    \n",
    "    # 配位数関連\n",
    "    cn_avg_list = []      # 平均配位数\n",
    "    reacted_al_list = []  # 反応した(CN>=1) Alの数\n",
    "    \n",
    "    # MSD関連\n",
    "    msd_total_list = []\n",
    "    msd_surface_list = []\n",
    "    msd_bulk_list = []\n",
    "    \n",
    "    # 分子生成関連 (H2)\n",
    "    h2_count_list = []\n",
    "\n",
    "    # RDF用\n",
    "    rdf_rmax = 6.0\n",
    "    rdf_nbins = 100\n",
    "    rdf_sum = np.zeros(rdf_nbins)\n",
    "    rdf_count = 0\n",
    "    start_rdf_frame = int(len(traj) * 0.5)\n",
    "\n",
    "    # 初期位置の保存 (flattenで1次元化を保証)\n",
    "    idx_al_total = indices['Al'].flatten()\n",
    "    idx_al_surface = surface_al_indices.flatten() if len(surface_al_indices) > 0 else np.array([])\n",
    "    idx_al_bulk = bulk_al_indices.flatten() if len(bulk_al_indices) > 0 else np.array([])\n",
    "    \n",
    "    initial_pos_total = initial_atoms.positions[idx_al_total] if len(idx_al_total) > 0 else None\n",
    "    initial_pos_surface = initial_atoms.positions[idx_al_surface] if len(idx_al_surface) > 0 else None\n",
    "    initial_pos_bulk = initial_atoms.positions[idx_al_bulk] if len(idx_al_bulk) > 0 else None\n",
    "\n",
    "    # 時間計算の設定\n",
    "    # 例: 40000 stepsで40ps。trajに80フレームある場合、1フレーム=0.5ps\n",
    "    total_sim_time_ps = 40.0 # シミュレーション総時間 (ps) ※適宜変更してください\n",
    "    dt_ps = total_sim_time_ps / max(len(traj), 1)\n",
    "\n",
    "    for i, atoms in enumerate(traj):\n",
    "        current_time = i * dt_ps\n",
    "        time_points.append(current_time)\n",
    "\n",
    "        # 1. 配位数解析 (Al-O) - 【修正箇所】\n",
    "        current_cn_avg = 0\n",
    "        current_reacted_count = 0\n",
    "        \n",
    "        idx_al = indices['Al'].flatten()\n",
    "        idx_o = indices['O'].flatten()\n",
    "\n",
    "        if len(idx_al) > 0 and len(idx_o) > 0:\n",
    "            # ase.geometry.get_distances で計算 (戻り値はフラットな配列)\n",
    "            p1 = atoms.positions[idx_al]\n",
    "            p2 = atoms.positions[idx_o]\n",
    "            _, d_len = get_distances(p1, p2, cell=atoms.cell, pbc=atoms.pbc)\n",
    "            \n",
    "            # (N_Al, N_O) の行列に整形\n",
    "            d_matrix = d_len.reshape(len(idx_al), len(idx_o))\n",
    "            \n",
    "            # 各Al原子ごとのOの数 (2.5A以内)\n",
    "            cn_per_atom = np.sum(d_matrix < 2.5, axis=1)\n",
    "            \n",
    "            current_cn_avg = np.mean(cn_per_atom)\n",
    "            current_reacted_count = np.sum(cn_per_atom >= 1) # 1つ以上酸素がついているAlの数\n",
    "\n",
    "        cn_avg_list.append(current_cn_avg)\n",
    "        reacted_al_list.append(current_reacted_count)\n",
    "\n",
    "        # 2. MSD計算 (Total, Surface, Bulk)\n",
    "        def calc_msd(current_atoms_pos, init_pos):\n",
    "            if init_pos is None or len(init_pos) == 0: return 0\n",
    "            diff = current_atoms_pos - init_pos\n",
    "            return np.mean(np.sum(diff**2, axis=1))\n",
    "\n",
    "        if len(idx_al_total) > 0:\n",
    "            msd_total_list.append(calc_msd(atoms.positions[idx_al_total], initial_pos_total))\n",
    "        else:\n",
    "            msd_total_list.append(0)\n",
    "            \n",
    "        if len(idx_al_surface) > 0:\n",
    "            msd_surface_list.append(calc_msd(atoms.positions[idx_al_surface], initial_pos_surface))\n",
    "        else:\n",
    "            msd_surface_list.append(0)\n",
    "\n",
    "        if len(idx_al_bulk) > 0:\n",
    "            msd_bulk_list.append(calc_msd(atoms.positions[idx_al_bulk], initial_pos_bulk))\n",
    "        else:\n",
    "            msd_bulk_list.append(0)\n",
    "\n",
    "        # 3. 水素分子(H2)検出\n",
    "        h2_count = 0\n",
    "        idx_h = indices['H'].flatten()\n",
    "        if len(idx_h) > 1:\n",
    "            p_h = atoms.positions[idx_h]\n",
    "            _, h_dists = get_distances(p_h, p_h, cell=atoms.cell, pbc=atoms.pbc)\n",
    "            # 自己距離(0)を除外\n",
    "            valid_h = h_dists[h_dists > 0.01]\n",
    "            # ペア数なので2で割る\n",
    "            h2_count = np.sum(valid_h < 0.85) // 2 \n",
    "        h2_count_list.append(h2_count)\n",
    "\n",
    "        # 4. RDF積算\n",
    "        if i >= start_rdf_frame:\n",
    "            hist, edges = compute_manual_rdf(atoms, indices['Al'], indices['O'], rmax=rdf_rmax, nbins=rdf_nbins)\n",
    "            rdf_sum += hist\n",
    "            rdf_count += 1\n",
    "            bin_edges = edges\n",
    "\n",
    "    # --- CSV出力 1: 時系列データ (Trends) ---\n",
    "    df_trends = pd.DataFrame({\n",
    "        'Time_ps': time_points,\n",
    "        'CN_Avg': cn_avg_list,\n",
    "        'Reacted_Al_Count': reacted_al_list,\n",
    "        'H2_Count': h2_count_list,\n",
    "        'MSD_Total': msd_total_list,\n",
    "        'MSD_Surface': msd_surface_list,\n",
    "        'MSD_Bulk': msd_bulk_list\n",
    "    })\n",
    "    df_trends.to_csv(output_dir / f\"{label}_trends.csv\", index=False)\n",
    "\n",
    "    # --- グラフ描画 (Time軸) ---\n",
    "    \n",
    "    # Plot 1: MSD (Surface vs Bulk)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(time_points, msd_surface_list, label='Surface Al', color='red', lw=2)\n",
    "    plt.plot(time_points, msd_bulk_list, label='Bulk Al', color='blue', linestyle='--', lw=1)\n",
    "    plt.plot(time_points, msd_total_list, label='Total Al', color='gray', alpha=0.5)\n",
    "    plt.xlabel(\"Time (ps)\"); plt.ylabel(\"MSD ($\\AA^2$)\")\n",
    "    plt.title(f\"MSD Analysis: {label}\")\n",
    "    plt.legend(); plt.grid(True)\n",
    "    plt.savefig(output_dir / f\"{label}_msd_detailed.png\"); plt.close()\n",
    "\n",
    "    # Plot 2: Reaction Progress (Reacted Count & H2)\n",
    "    fig, ax1 = plt.subplots(figsize=(8, 6))\n",
    "    ax2 = ax1.twinx()\n",
    "    ax1.plot(time_points, reacted_al_list, 'g-', label='Reacted Al Count (CN>=1)', lw=2)\n",
    "    ax2.plot(time_points, h2_count_list, 'm--', label='H2 Molecule Count', lw=2)\n",
    "    ax1.set_xlabel(\"Time (ps)\")\n",
    "    ax1.set_ylabel(\"Count (Al atoms)\", color='g')\n",
    "    ax2.set_ylabel(\"Count (H2 molecules)\", color='m')\n",
    "    lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "    ax1.legend(lines1 + lines2, labels1 + labels2, loc='upper left')\n",
    "    plt.title(f\"Reaction Progress: {label}\")\n",
    "    plt.savefig(output_dir / f\"{label}_reaction.png\"); plt.close()\n",
    "\n",
    "    # Plot 3: Density Profile\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    density_data = {}\n",
    "    bins_z = np.linspace(0, cell_diag[2], 101)\n",
    "    bin_centers_z = 0.5 * (bins_z[1:] + bins_z[:-1])\n",
    "    density_data['Z_axis'] = bin_centers_z\n",
    "    for spec, idx in indices.items():\n",
    "        idx_flat = idx.flatten()\n",
    "        if len(idx_flat) > 0:\n",
    "            hist_vals, _ = np.histogram(final_atoms.positions[idx_flat, 2], bins=bins_z)\n",
    "            density_data[spec] = hist_vals\n",
    "            plt.plot(bin_centers_z, hist_vals, label=spec, lw=2)\n",
    "    pd.DataFrame(density_data).to_csv(output_dir / f\"{label}_density.csv\", index=False)\n",
    "    plt.title(f\"Density: {label}\"); plt.xlabel(\"Z (Å)\"); plt.legend()\n",
    "    plt.savefig(output_dir / f\"{label}_density.png\"); plt.close()\n",
    "\n",
    "    # Plot 4: RDF\n",
    "    if rdf_count > 0:\n",
    "        r = 0.5 * (bin_edges[1:] + bin_edges[:-1])\n",
    "        dr = bin_edges[1] - bin_edges[0]\n",
    "        rho = len(indices['O']) / cell_vol\n",
    "        shell_vol = 4 * np.pi * r**2 * dr\n",
    "        gr = (rdf_sum / rdf_count) / (len(indices['Al']) * shell_vol * rho)\n",
    "        pd.DataFrame({'r': r, 'g_r': gr}).to_csv(output_dir / f\"{label}_rdf_Al_O.csv\", index=False)\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        plt.plot(r, gr, color='blue', lw=2)\n",
    "        plt.title(f\"RDF Al-O: {label}\"); plt.xlabel(\"r (Å)\"); plt.ylabel(\"g(r)\"); plt.grid(True)\n",
    "        plt.savefig(output_dir / f\"{label}_rdf_Al_O.png\"); plt.close()\n",
    "\n",
    "    print(f\"   -> Finished {label}\")\n",
    "\n",
    "def main_analysis():\n",
    "    files=[\"Al_LiOH_v8\",\"Al_Li_F_OH\",\"Al_Li_F\",\"Al_Na_F_OH\"]\n",
    "    for file in files:\n",
    "        base_dir = Path(f\"/home/jovyan/Kaori/MD/LiB_2/structure/{file}\")\n",
    "        analysis_dir = base_dir / \"analysis_results\"\n",
    "        analysis_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        for target in [\"Al_Metal\", \"Al_Oxide\"]:\n",
    "            for temp in [300, 400, 500, 600, 750, 900]:\n",
    "                traj_file = base_dir / f\"{target}_md_{temp}K.traj\"\n",
    "                if traj_file.exists():\n",
    "                    analyze_md_results(traj_file, analysis_dir, f\"{target}_{temp}K\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd596ccc-7eef-4248-9849-23830745fc72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing: Al_Metal_md_300K.traj\n",
      "   -> Finished Al_Metal_300K\n",
      "Analyzing: Al_Metal_md_400K.traj\n",
      "   -> Finished Al_Metal_400K\n",
      "Analyzing: Al_Metal_md_500K.traj\n",
      "   -> Finished Al_Metal_500K\n",
      "Analyzing: Al_Metal_md_600K.traj\n",
      "   -> Finished Al_Metal_600K\n",
      "Analyzing: Al_Metal_md_750K.traj\n",
      "   -> Finished Al_Metal_750K\n",
      "Analyzing: Al_Metal_md_900K.traj\n",
      "   -> Finished Al_Metal_900K\n",
      "Analyzing: Al_Oxide_md_300K.traj\n",
      "   -> Finished Al_Oxide_300K\n",
      "Analyzing: Al_Oxide_md_400K.traj\n",
      "   -> Finished Al_Oxide_400K\n",
      "Analyzing: Al_Oxide_md_500K.traj\n",
      "   -> Finished Al_Oxide_500K\n",
      "Analyzing: Al_Oxide_md_600K.traj\n",
      "   -> Finished Al_Oxide_600K\n",
      "Analyzing: Al_Oxide_md_750K.traj\n",
      "   -> Finished Al_Oxide_750K\n",
      "Analyzing: Al_Oxide_md_900K.traj\n",
      "   -> Finished Al_Oxide_900K\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from ase.io.trajectory import Trajectory\n",
    "from ase.geometry import get_distances\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import math\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- 1. フォントサイズ等の設定 (22pt) ---\n",
    "plt.rcParams.update({\n",
    "    'font.size': 22, \n",
    "    'axes.labelsize': 22, \n",
    "    'xtick.labelsize': 22, \n",
    "    'ytick.labelsize': 22,\n",
    "    'legend.fontsize': 18,\n",
    "    'figure.titlesize': 24\n",
    "})\n",
    "\n",
    "# --- RDFを手動で計算する関数 ---\n",
    "def compute_manual_rdf(atoms, indices1, indices2, rmax=6.0, nbins=100):\n",
    "    if len(indices1) == 0 or len(indices2) == 0:\n",
    "        return np.zeros(nbins), np.linspace(0, rmax, nbins+1)\n",
    "    \n",
    "    idx1 = indices1.flatten()\n",
    "    idx2 = indices2.flatten()\n",
    "    \n",
    "    p1 = atoms.positions[idx1]\n",
    "    p2 = atoms.positions[idx2]\n",
    "\n",
    "    # 距離計算\n",
    "    _, dists = get_distances(p1, p2, cell=atoms.cell, pbc=atoms.pbc)\n",
    "    \n",
    "    # 自己相関排除 (同じ原子ID同士の距離0を除外)\n",
    "    if np.array_equal(idx1, idx2):\n",
    "        valid_dists = dists[dists > 0.01]\n",
    "    else:\n",
    "        valid_dists = dists.flatten()\n",
    "    \n",
    "    hist, bin_edges = np.histogram(valid_dists, range=(0, rmax), bins=nbins)\n",
    "    return hist, bin_edges\n",
    "\n",
    "def analyze_md_results(traj_path, output_dir, label):\n",
    "    print(f\"Analyzing: {traj_path.name}\")\n",
    "    try:\n",
    "        traj = Trajectory(traj_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading traj: {e}\"); return\n",
    "\n",
    "    if len(traj) == 0: return\n",
    "\n",
    "    # --- 基本設定 ---\n",
    "    initial_atoms = traj[0]\n",
    "    final_atoms = traj[-1]\n",
    "    cell_vol = final_atoms.get_volume()\n",
    "    symbols = np.array(final_atoms.get_chemical_symbols())\n",
    "    \n",
    "    # 元素ごとのインデックス取得\n",
    "    indices = {s: np.where(symbols == s)[0] for s in ['Al', 'O', 'Li', 'H', 'F']}\n",
    "\n",
    "    # --- 解析ペアの設定 ---\n",
    "    # name: 表示名, ele1/ele2: 元素記号, cutoff: 結合判定距離(Å)\n",
    "    target_pairs = [\n",
    "        {'name': 'Al-F', 'ele1': 'Al', 'ele2': 'F', 'cutoff': 2.0},\n",
    "        {'name': 'Li-F', 'ele1': 'Li', 'ele2': 'F', 'cutoff': 2.0},\n",
    "        {'name': 'O-H',  'ele1': 'O',  'ele2': 'H', 'cutoff': 1.25}, # 水酸基等の共有結合\n",
    "        {'name': 'Al-O', 'ele1': 'Al', 'ele2': 'O', 'cutoff': 2.0}  # 既存\n",
    "    ]\n",
    "\n",
    "    # データ格納用辞書の初期化\n",
    "    results = {\n",
    "        'time': [],\n",
    "        'cn_data': {p['name']: [] for p in target_pairs}, # 平均配位数\n",
    "        'rdf_sum': {p['name']: np.zeros(100) for p in target_pairs},\n",
    "        'rdf_count': 0\n",
    "    }\n",
    "    \n",
    "    # RDF用パラメータ\n",
    "    rdf_rmax = 6.0\n",
    "    rdf_nbins = 100\n",
    "    start_rdf_frame = int(len(traj) * 0.5)\n",
    "    \n",
    "    # 時間設定 (例: 1step=1fsなど。ここでは仮に全40psとする)\n",
    "    total_sim_time_ps = 40.0 \n",
    "    dt_ps = total_sim_time_ps / max(len(traj), 1)\n",
    "\n",
    "    # --- メインループ ---\n",
    "    for i, atoms in enumerate(traj):\n",
    "        current_time = i * dt_ps\n",
    "        results['time'].append(current_time)\n",
    "\n",
    "        # 各ペアごとの結合数(CN)計算\n",
    "        for pair in target_pairs:\n",
    "            idx1 = indices.get(pair['ele1'], np.array([])).flatten()\n",
    "            idx2 = indices.get(pair['ele2'], np.array([])).flatten()\n",
    "            \n",
    "            cn_avg = 0\n",
    "            if len(idx1) > 0 and len(idx2) > 0:\n",
    "                p1 = atoms.positions[idx1]\n",
    "                p2 = atoms.positions[idx2]\n",
    "                _, d_len = get_distances(p1, p2, cell=atoms.cell, pbc=atoms.pbc)\n",
    "                \n",
    "                # 行列化 (N_ele1 x N_ele2)\n",
    "                d_matrix = d_len.reshape(len(idx1), len(idx2))\n",
    "                \n",
    "                # 同種原子の場合、対角成分(自分自身)を除外するための処理が必要だが、\n",
    "                # ここでは異種原子ペア(Al-F等)メインのため簡易実装\n",
    "                # カットオフ以内の数をカウント\n",
    "                cn_per_atom = np.sum(d_matrix < pair['cutoff'], axis=1)\n",
    "                \n",
    "                # ele1(例:Al) 1原子あたりの ele2(例:F) の平均数\n",
    "                cn_avg = np.mean(cn_per_atom)\n",
    "            \n",
    "            results['cn_data'][pair['name']].append(cn_avg)\n",
    "\n",
    "        # RDF積算 (後半フレームのみ)\n",
    "        if i >= start_rdf_frame:\n",
    "            results['rdf_count'] += 1\n",
    "            for pair in target_pairs:\n",
    "                idx1 = indices.get(pair['ele1'], np.array([]))\n",
    "                idx2 = indices.get(pair['ele2'], np.array([]))\n",
    "                hist, edges = compute_manual_rdf(atoms, idx1, idx2, rmax=rdf_rmax, nbins=rdf_nbins)\n",
    "                results['rdf_sum'][pair['name']] += hist\n",
    "                bin_edges = edges # すべて同じビン設定なので上書きでOK\n",
    "\n",
    "    # --- CSV出力 (時系列データ) ---\n",
    "    df_data = {'Time_ps': results['time']}\n",
    "    for name, data in results['cn_data'].items():\n",
    "        df_data[f'CN_Avg_{name}'] = data\n",
    "    pd.DataFrame(df_data).to_csv(output_dir / f\"{label}_bond_counts.csv\", index=False)\n",
    "\n",
    "\n",
    "    # --- グラフ作成 1: 結合数 (Bond Counts) ---\n",
    "    # レイアウト: 2列 x N行\n",
    "    n_plots = len(target_pairs)\n",
    "    n_cols = 2\n",
    "    n_rows = math.ceil(n_plots / n_cols)\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(16, 6 * n_rows), constrained_layout=True)\n",
    "    axes_flat = axes.flatten() if n_plots > 1 else [axes]\n",
    "\n",
    "    for j, pair in enumerate(target_pairs):\n",
    "        ax = axes_flat[j]\n",
    "        name = pair['name']\n",
    "        data = results['cn_data'][name]\n",
    "        time = results['time']\n",
    "        \n",
    "        ax.plot(time, data, lw=3, color='tab:blue')\n",
    "        ax.set_title(f\"{name} Bond Count (cut={pair['cutoff']}A)\")\n",
    "        ax.set_xlabel(\"Time (ps)\")\n",
    "        ax.set_ylabel(\"Avg CN\")\n",
    "        ax.grid(True)\n",
    "\n",
    "    # 余ったサブプロットを消す\n",
    "    for k in range(j+1, len(axes_flat)):\n",
    "        axes_flat[k].axis('off')\n",
    "        \n",
    "    plt.suptitle(f\"Bond Counts Trends: {label}\")\n",
    "    plt.savefig(output_dir / f\"{label}_bonds_summary.png\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    # --- グラフ作成 2: RDF ---\n",
    "    if results['rdf_count'] > 0:\n",
    "        fig_rdf, axes_rdf = plt.subplots(n_rows, n_cols, figsize=(16, 6 * n_rows), constrained_layout=True)\n",
    "        axes_rdf_flat = axes_rdf.flatten() if n_plots > 1 else [axes_rdf]\n",
    "        \n",
    "        r = 0.5 * (bin_edges[1:] + bin_edges[:-1])\n",
    "        dr = bin_edges[1] - bin_edges[0]\n",
    "        \n",
    "        rdf_df_data = {'r': r}\n",
    "\n",
    "        for j, pair in enumerate(target_pairs):\n",
    "            ax = axes_rdf_flat[j]\n",
    "            name = pair['name']\n",
    "            \n",
    "            idx1_len = len(indices.get(pair['ele1'], []))\n",
    "            idx2_len = len(indices.get(pair['ele2'], []))\n",
    "            \n",
    "            if idx1_len > 0 and idx2_len > 0:\n",
    "                # 密度計算 (ele2の数密度)\n",
    "                rho = idx2_len / cell_vol\n",
    "                shell_vol = 4 * np.pi * r**2 * dr\n",
    "                \n",
    "                # g(r) = (ヒストグラム平均) / (中心原子数 * シェル体積 * 密度)\n",
    "                gr = (results['rdf_sum'][name] / results['rdf_count']) / (idx1_len * shell_vol * rho)\n",
    "                \n",
    "                rdf_df_data[f'g_r_{name}'] = gr\n",
    "                \n",
    "                ax.plot(r, gr, lw=3, color='tab:red')\n",
    "                ax.set_title(f\"RDF: {name}\")\n",
    "                ax.set_xlabel(\"r (Å)\")\n",
    "                ax.set_ylabel(\"g(r)\")\n",
    "                ax.grid(True)\n",
    "            else:\n",
    "                ax.text(0.5, 0.5, \"No Data\", ha='center')\n",
    "\n",
    "        # 余ったサブプロットを消す\n",
    "        for k in range(j+1, len(axes_rdf_flat)):\n",
    "            axes_rdf_flat[k].axis('off')\n",
    "\n",
    "        pd.DataFrame(rdf_df_data).to_csv(output_dir / f\"{label}_rdf_summary.csv\", index=False)\n",
    "        plt.suptitle(f\"RDF Summary: {label}\")\n",
    "        plt.savefig(output_dir / f\"{label}_rdf_summary.png\")\n",
    "        plt.close()\n",
    "\n",
    "    print(f\"   -> Finished {label}\")\n",
    "\n",
    "def main_analysis():\n",
    "    base_dir = Path(\"/home/jovyan/Kaori/MD/LiB_2/structure/Al_Li_F_OH\")\n",
    "    analysis_dir = base_dir / \"analysis_results\"\n",
    "    analysis_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # 対象ファイル名パターン (必要に応じて変更してください)\n",
    "    # 例: Al_Metal_md_300K.traj など\n",
    "    targets = [\"Al_Metal\", \"Al_Oxide\"]\n",
    "    temps = [300, 400, 500, 600, 750, 900]\n",
    "\n",
    "    for target in targets:\n",
    "        for temp in temps:\n",
    "            traj_file = base_dir / f\"{target}_md_{temp}K.traj\"\n",
    "            if traj_file.exists():\n",
    "                analyze_md_results(traj_file, analysis_dir, f\"{target}_{temp}K\")\n",
    "            else:\n",
    "                print(f\"Skipping (not found): {traj_file.name}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb19d64-458a-49d1-834e-733a20837d0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "099a0dc4-9d77-44b9-b0cb-9d454e193eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 トレンド解析中...\n",
      "🌡️ 密度プロファイル解析中...\n",
      "🔍 RDF解析中...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def format_face_label(face):\n",
    "    \"\"\"ラベルを3桁に揃える (例: 1 -> 001)\"\"\"\n",
    "    s = str(face)\n",
    "    if s.isdigit():\n",
    "        return s.zfill(3)\n",
    "    return s\n",
    "\n",
    "def plot_nmc_integrated(csv_dir=\"analysis_csv\", output_dir=\"plots\"):\n",
    "    csv_dir, output_dir = Path(csv_dir), Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    def load_and_prepare(filename):\n",
    "        path = csv_dir / filename\n",
    "        if not path.exists(): return None\n",
    "        df = pd.read_csv(path)\n",
    "        if 'Face' in df.columns:\n",
    "            df['Face'] = df['Face'].apply(format_face_label)\n",
    "        return df\n",
    "\n",
    "    # フォント設定\n",
    "    plt.rcParams.update({'font.size': 10, 'axes.labelsize': 11, 'axes.titlesize': 12})\n",
    "\n",
    "    # 1. 反応トレンド (同じ結晶面を、異なる温度で並べる)\n",
    "    df_t = load_and_prepare(\"summary_trends.csv\")\n",
    "    if df_t is not None:\n",
    "        print(\"📊 トレンド解析中...\")\n",
    "        faces = sorted(df_t['Face'].unique())\n",
    "        for face in faces:\n",
    "            data_face = df_t[df_t['Face'] == face]\n",
    "            temps = sorted(data_face['Temp'].unique(), key=lambda x: float(re.sub(r'\\D', '', str(x))) if any(c.isdigit() for c in str(x)) else str(x))\n",
    "            \n",
    "            rows = math.ceil(len(temps) / 2)\n",
    "            fig, axes = plt.subplots(rows, 2, figsize=(12, 4 * rows), squeeze=False)\n",
    "            \n",
    "            for i, temp in enumerate(temps):\n",
    "                ax = axes.flatten()[i]\n",
    "                d = data_face[data_face['Temp'] == temp].sort_values('Frame')\n",
    "                ax.plot(d['Frame'], d['Leached_Li'], label='Leached Li', color='#1f77b4', lw=2)\n",
    "                ax.plot(d['Frame'], d['Intruded_H'], label='Intruded H', color='#d62728', lw=2)\n",
    "                \n",
    "                ax.set_title(f\"Face: {face} | Temp: {temp}K\")\n",
    "                ax.set_xlabel(\"Time (Frame)\")\n",
    "                ax.set_ylabel(\"Atom Count\")\n",
    "                ax.legend(loc='upper left')\n",
    "                ax.grid(True, alpha=0.3)\n",
    "            \n",
    "            for j in range(i + 1, len(axes.flatten())): axes.flatten()[j].axis('off')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(output_dir / f\"grid_trend_face_{face}.png\", dpi=300)\n",
    "            plt.close()\n",
    "\n",
    "    # 2. 密度プロファイル (同じ結晶面を、異なる温度で並べる)\n",
    "    df_d = load_and_prepare(\"summary_density.csv\")\n",
    "    if df_d is not None:\n",
    "        print(\"🌡️ 密度プロファイル解析中...\")\n",
    "        faces = sorted(df_d['Face'].unique())\n",
    "        for face in faces:\n",
    "            data_face = df_d[df_d['Face'] == face]\n",
    "            temps = sorted(data_face['Temp'].unique(), key=lambda x: float(re.sub(r'\\D', '', str(x))) if any(c.isdigit() for c in str(x)) else str(x))\n",
    "            \n",
    "            rows = math.ceil(len(temps) / 2)\n",
    "            fig, axes = plt.subplots(rows, 2, figsize=(12, 4 * rows), squeeze=False)\n",
    "            \n",
    "            for i, temp in enumerate(temps):\n",
    "                ax = axes.flatten()[i]\n",
    "                d = data_face[data_face['Temp'] == temp].sort_values('Z')\n",
    "                \n",
    "                colors = {'Li': '#1f77b4', 'H': '#d62728', 'O': '#7f7f7f'}\n",
    "                for s in ['Li', 'H', 'O']:\n",
    "                    ds = d[(d['Symbol'] == s) & (d['Density'] > 1e-4)]\n",
    "                    if not ds.empty:\n",
    "                        ax.fill_between(ds['Z'], ds['Density'], alpha=0.3, color=colors[s], label=s)\n",
    "                        ax.plot(ds['Z'], ds['Density'], color=colors[s], lw=1.5)\n",
    "                \n",
    "                ax.set_title(f\"Density Profile: {face} ({temp}K)\")\n",
    "                ax.set_xlabel(\"Z coordinate (Å)\")\n",
    "                ax.set_ylabel(\"Atomic Density\")\n",
    "                ax.legend(loc='upper right')\n",
    "                ax.grid(axis='y', alpha=0.2)\n",
    "                \n",
    "            for j in range(i + 1, len(axes.flatten())): axes.flatten()[j].axis('off')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(output_dir / f\"grid_density_face_{face}.png\", dpi=300)\n",
    "            plt.close()\n",
    "\n",
    "    # 3. RDF (同じ結晶面を、異なる温度で並べる)\n",
    "    df_r = load_and_prepare(\"summary_rdf.csv\")\n",
    "    if df_r is not None:\n",
    "        print(\"🔍 RDF解析中...\")\n",
    "        faces = sorted(df_r['Face'].unique())\n",
    "        for face in faces:\n",
    "            data_face = df_r[df_r['Face'] == face]\n",
    "            temps = sorted(data_face['Temp'].unique(), key=lambda x: float(re.sub(r'\\D', '', str(x))) if any(c.isdigit() for c in str(x)) else str(x))\n",
    "            \n",
    "            rows = math.ceil(len(temps) / 2)\n",
    "            fig, axes = plt.subplots(rows, 2, figsize=(12, 4 * rows), squeeze=False)\n",
    "            \n",
    "            for i, temp in enumerate(temps):\n",
    "                ax = axes.flatten()[i]\n",
    "                d = data_face[data_face['Temp'] == temp]\n",
    "                \n",
    "                for p, c in [('Li-LatticeO', '#1f77b4'), ('Li-WaterO', '#ff7f0e')]:\n",
    "                    dp = d[d['Pair'] == p].sort_values('r')\n",
    "                    if not dp.empty: ax.plot(dp['r'], dp['g_r'], label=p, color=c, lw=2)\n",
    "                \n",
    "                ax.axvline(2.1, color='gray', ls='--', alpha=0.6, label='2.1Å (Bond)')\n",
    "                ax.axvline(2.8, color='green', ls=':', alpha=0.6, label='2.8Å (Contact)')\n",
    "                \n",
    "                ax.set_title(f\"RDF: {face} ({temp}K)\")\n",
    "                ax.set_xlabel(\"Distance r (Å)\")\n",
    "                ax.set_ylabel(\"g(r)\")\n",
    "                ax.set_xlim(1.0, 5.0)\n",
    "                ax.set_ylim(0, None)\n",
    "                ax.legend()\n",
    "                ax.grid(True, alpha=0.2)\n",
    "                \n",
    "            for j in range(i + 1, len(axes.flatten())): axes.flatten()[j].axis('off')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(output_dir / f\"grid_rdf_face_{face}.png\", dpi=300)\n",
    "            plt.close()\n",
    "\n",
    "import re # 必要に応じて追加\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    plot_nmc_integrated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f566f158-aa66-4a00-8fac-e43129bd4d1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ee3509-f849-4a1b-9d03-fc5ab7699d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing: Al_Metal_md_300K.traj\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd  # 追加\n",
    "from ase.io.trajectory import Trajectory\n",
    "from ase.geometry import get_distances\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 全体のフォントサイズ設定\n",
    "plt.rcParams.update({\n",
    "    'font.size': 14, \n",
    "    'axes.labelsize': 16, \n",
    "    'xtick.labelsize': 14, \n",
    "    'ytick.labelsize': 14,\n",
    "    'legend.fontsize': 12\n",
    "})\n",
    "\n",
    "# --- RDFを手動で計算する関数 ---\n",
    "def compute_manual_rdf(atoms, indices1, indices2, rmax=6.0, nbins=100):\n",
    "    if len(indices1) == 0 or len(indices2) == 0:\n",
    "        return np.zeros(nbins), np.linspace(0, rmax, nbins+1)\n",
    "    \n",
    "    # 距離の計算 (PBC考慮)\n",
    "    dists = get_distances(atoms.positions[indices1], atoms.positions[indices2], \n",
    "                          cell=atoms.cell, pbc=atoms.pbc)[1]\n",
    "    \n",
    "    # 自己相関排除\n",
    "    valid_dists = dists[dists > 0.01] if np.array_equal(indices1, indices2) else dists.flatten()\n",
    "    \n",
    "    hist, bin_edges = np.histogram(valid_dists, range=(0, rmax), bins=nbins)\n",
    "    return hist, bin_edges\n",
    "\n",
    "def analyze_md_results(traj_path, output_dir, label):\n",
    "    print(f\"Analyzing: {traj_path.name}\")\n",
    "    try:\n",
    "        traj = Trajectory(traj_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\"); return\n",
    "\n",
    "    if len(traj) == 0: return\n",
    "\n",
    "    # 基本情報の取得\n",
    "    final_atoms = traj[-1]\n",
    "    cell_vol = final_atoms.get_volume()\n",
    "    cell_diag = final_atoms.get_cell().diagonal()\n",
    "    symbols = np.array(final_atoms.get_chemical_symbols())\n",
    "    \n",
    "    indices = {s: np.where(symbols == s)[0] for s in ['Al', 'O', 'Li', 'H','F']}\n",
    "    \n",
    "    # --- データ蓄積用 ---\n",
    "    rdf_rmax = 6.0\n",
    "    rdf_nbins = 100\n",
    "    rdf_sum = np.zeros(rdf_nbins)\n",
    "    rdf_count = 0\n",
    "    \n",
    "    # 時系列データ用リスト\n",
    "    time_steps = []\n",
    "    cn_list = []\n",
    "    msd_al_list = []\n",
    "    \n",
    "    initial_al_pos = traj[0].positions[indices['Al']]\n",
    "    \n",
    "    # 後半50%のフレームでRDFを平均化\n",
    "    start_rdf_frame = int(len(traj) * 0.5)\n",
    "\n",
    "    for i, atoms in enumerate(traj):\n",
    "        time_steps.append(i* 0.5) # ステップ数（または時間）\n",
    "        \n",
    "        # 1. 配位数計算 (Al-O, cutoff 2.5A)\n",
    "        cn_val = 0\n",
    "        if len(indices['Al']) > 0 and len(indices['O']) > 0:\n",
    "            d = get_distances(atoms.positions[indices['Al']], atoms.positions[indices['O']], \n",
    "                              cell=atoms.cell, pbc=atoms.pbc)[1]\n",
    "            cn_val = np.sum(d < 2.5) / len(indices['Al'])\n",
    "        cn_list.append(cn_val)\n",
    "\n",
    "        # 2. MSD計算 (Al)\n",
    "        msd_val = 0\n",
    "        if len(indices['Al']) > 0:\n",
    "            diff = atoms.positions[indices['Al']] - initial_al_pos\n",
    "            # PBC補正が必要な場合は別途処理が必要だが、ここでは簡易的に絶対座標変位とみなすか、unwrapped trajectory推奨\n",
    "            # 今回は元のコード準拠で計算\n",
    "            msd_val = np.mean(np.sum(diff**2, axis=1))\n",
    "        msd_al_list.append(msd_val)\n",
    "\n",
    "        # 3. RDF積算\n",
    "        if i >= start_rdf_frame:\n",
    "            hist, edges = compute_manual_rdf(atoms, indices['Al'], indices['O'], rmax=rdf_rmax, nbins=rdf_nbins)\n",
    "            rdf_sum += hist\n",
    "            rdf_count += 1\n",
    "            bin_edges = edges\n",
    "\n",
    "    # --- CSV出力 1: 時系列データ (Trends) ---\n",
    "    df_trends = pd.DataFrame({\n",
    "        'Step': time_steps,\n",
    "        'CN_Al_O': cn_list,\n",
    "        'MSD_Al': msd_al_list\n",
    "    })\n",
    "    df_trends.to_csv(output_dir / f\"{label}_trends.csv\", index=False)\n",
    "\n",
    "\n",
    "    # --- グラフ保存 & CSV出力 2: 密度プロファイル ---\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    density_data = {}\n",
    "    bins_z = np.linspace(0, cell_diag[2], 101) # ビン設定\n",
    "    bin_centers_z = 0.5 * (bins_z[1:] + bins_z[:-1])\n",
    "    density_data['Z_axis'] = bin_centers_z\n",
    "\n",
    "    for spec, idx in indices.items():\n",
    "        if len(idx) > 0:\n",
    "            # ヒストグラム計算\n",
    "            hist_vals, _ = np.histogram(final_atoms.positions[idx, 2], bins=bins_z)\n",
    "            density_data[spec] = hist_vals\n",
    "            \n",
    "            # プロット\n",
    "            plt.plot(bin_centers_z, hist_vals, label=spec, lw=2)\n",
    "            \n",
    "    # Density CSV保存\n",
    "    pd.DataFrame(density_data).to_csv(output_dir / f\"{label}_density.csv\", index=False)\n",
    "    \n",
    "    plt.title(f\"Density: {label}\"); plt.xlabel(\"Z (Å)\"); plt.legend()\n",
    "    plt.savefig(output_dir / f\"{label}_density.png\"); plt.close()\n",
    "\n",
    "\n",
    "    # --- グラフ保存 & CSV出力 3: RDF ---\n",
    "    if rdf_count > 0:\n",
    "        r = 0.5 * (bin_edges[1:] + bin_edges[:-1])\n",
    "        dr = bin_edges[1] - bin_edges[0]\n",
    "        rho = len(indices['O']) / cell_vol\n",
    "        shell_vol = 4 * np.pi * r**2 * dr\n",
    "        \n",
    "        # g(r) 計算\n",
    "        gr = (rdf_sum / rdf_count) / (len(indices['Al']) * shell_vol * rho)\n",
    "        \n",
    "        # RDF CSV保存\n",
    "        pd.DataFrame({'r': r, 'g_r': gr}).to_csv(output_dir / f\"{label}_rdf_Al_O.csv\", index=False)\n",
    "\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        plt.plot(r, gr, color='blue', lw=2)\n",
    "        plt.title(f\"RDF Al-O: {label}\"); plt.xlabel(\"r (Å)\"); plt.ylabel(\"g(r)\"); plt.grid(True)\n",
    "        plt.savefig(output_dir / f\"{label}_rdf_Al_O.png\"); plt.close()\n",
    "\n",
    "    # (3) 配位数とMSD (グラフのみ)\n",
    "    fig, ax1 = plt.subplots(figsize=(8, 5))\n",
    "    ax2 = ax1.twinx()\n",
    "    ax1.plot(cn_list, 'g-', label='Coord. Number')\n",
    "    ax2.plot(msd_al_list, 'r-', label='Al-MSD')\n",
    "    ax1.set_ylabel(\"CN (Al-O)\", color='g'); ax2.set_ylabel(\"MSD (Å^2)\", color='r')\n",
    "    plt.title(f\"Trends: {label}\"); plt.savefig(output_dir / f\"{label}_trends.png\"); plt.close()\n",
    "\n",
    "    print(f\"   -> Finished {label}\")\n",
    "\n",
    "def main_analysis():\n",
    "    base_dir = Path(\"/home/jovyan/Kaori/MD/LiB_2/structure/Al_LiOH_v4\")\n",
    "    analysis_dir = base_dir / \"analysis_results\"\n",
    "    analysis_dir.mkdir(parents=True, exist_ok=True)\n",
    "    for target in [\"Al_Metal\", \"Al_Oxide\"]:\n",
    "        for temp in [300, 400, 500, 600, 750, 900]:\n",
    "            traj_file = base_dir / f\"{target}_md_{temp}K.traj\"\n",
    "            if traj_file.exists():\n",
    "                analyze_md_results(traj_file, analysis_dir, f\"{target}_{temp}K\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ee939d5-5196-4537-b966-87e50a5f8a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Merging Trends ---\n",
      "Found 6 files. Merging...\n",
      "Successfully saved merged CSV to: /home/jovyan/Kaori/MD/LiB_2/structure/Al_LiOH_v8/analysis_results/all_trends_summary.csv\n",
      "Total rows: 408\n",
      "\n",
      "--- Merging Density Profiles ---\n",
      "Found 6 files. Merging...\n",
      "Successfully saved merged CSV to: /home/jovyan/Kaori/MD/LiB_2/structure/Al_LiOH_v8/analysis_results/all_density_summary.csv\n",
      "Total rows: 600\n",
      "\n",
      "--- Merging RDF Data ---\n",
      "Found 6 files. Merging...\n",
      "Successfully saved merged CSV to: /home/jovyan/Kaori/MD/LiB_2/structure/Al_LiOH_v8/analysis_results/all_rdf_summary.csv\n",
      "Total rows: 600\n",
      "--- Merging Trends ---\n",
      "Found 12 files. Merging...\n",
      "Successfully saved merged CSV to: /home/jovyan/Kaori/MD/LiB_2/structure/Al_Li_F_OH/analysis_results/all_trends_summary.csv\n",
      "Total rows: 960\n",
      "\n",
      "--- Merging Density Profiles ---\n",
      "Found 12 files. Merging...\n",
      "Successfully saved merged CSV to: /home/jovyan/Kaori/MD/LiB_2/structure/Al_Li_F_OH/analysis_results/all_density_summary.csv\n",
      "Total rows: 1200\n",
      "\n",
      "--- Merging RDF Data ---\n",
      "Found 12 files. Merging...\n",
      "Successfully saved merged CSV to: /home/jovyan/Kaori/MD/LiB_2/structure/Al_Li_F_OH/analysis_results/all_rdf_summary.csv\n",
      "Total rows: 1200\n",
      "--- Merging Trends ---\n",
      "Found 7 files. Merging...\n",
      "Successfully saved merged CSV to: /home/jovyan/Kaori/MD/LiB_2/structure/Al_Li_F/analysis_results/all_trends_summary.csv\n",
      "Total rows: 488\n",
      "\n",
      "--- Merging Density Profiles ---\n",
      "Found 7 files. Merging...\n",
      "Successfully saved merged CSV to: /home/jovyan/Kaori/MD/LiB_2/structure/Al_Li_F/analysis_results/all_density_summary.csv\n",
      "Total rows: 700\n",
      "\n",
      "--- Merging RDF Data ---\n",
      "Found 7 files. Merging...\n",
      "Successfully saved merged CSV to: /home/jovyan/Kaori/MD/LiB_2/structure/Al_Li_F/analysis_results/all_rdf_summary.csv\n",
      "Total rows: 700\n",
      "--- Merging Trends ---\n",
      "Found 12 files. Merging...\n",
      "Successfully saved merged CSV to: /home/jovyan/Kaori/MD/LiB_2/structure/Al_Na_F_OH/analysis_results/all_trends_summary.csv\n",
      "Total rows: 960\n",
      "\n",
      "--- Merging Density Profiles ---\n",
      "Found 12 files. Merging...\n",
      "Successfully saved merged CSV to: /home/jovyan/Kaori/MD/LiB_2/structure/Al_Na_F_OH/analysis_results/all_density_summary.csv\n",
      "Total rows: 1200\n",
      "\n",
      "--- Merging RDF Data ---\n",
      "Found 12 files. Merging...\n",
      "Successfully saved merged CSV to: /home/jovyan/Kaori/MD/LiB_2/structure/Al_Na_F_OH/analysis_results/all_rdf_summary.csv\n",
      "Total rows: 1200\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "def merge_csv_files(target_dir, file_pattern=\"*.csv\", output_name=\"merged_output.csv\"):\n",
    "    \"\"\"\n",
    "    指定ディレクトリ内のCSVを結合する関数\n",
    "    \n",
    "    Args:\n",
    "        target_dir (str or Path): 対象のフォルダパス\n",
    "        file_pattern (str): 読み込むファイルのパターン（例: \"*trends.csv\"）\n",
    "        output_name (str): 出力するファイル名\n",
    "    \"\"\"\n",
    "    dir_path = Path(target_dir)\n",
    "    \n",
    "    # マッチするファイルを探す\n",
    "    all_files = list(dir_path.glob(file_pattern))\n",
    "    \n",
    "    # 出力ファイル自体がすでにある場合、読み込み対象から除外する\n",
    "    all_files = [f for f in all_files if f.name != output_name]\n",
    "    \n",
    "    if not all_files:\n",
    "        print(f\"No files found matching '{file_pattern}' in {dir_path}\")\n",
    "        return\n",
    "\n",
    "    print(f\"Found {len(all_files)} files. Merging...\")\n",
    "\n",
    "    df_list = []\n",
    "    \n",
    "    for file in all_files:\n",
    "        try:\n",
    "            # CSVを読み込む\n",
    "            df = pd.read_csv(file)\n",
    "            \n",
    "            # どのファイルから来たデータかわかるように列を追加\n",
    "            # 例: \"Al_Metal_300K_trends.csv\" -> \"Al_Metal_300K_trends\"\n",
    "            df.insert(0, 'Source_File', file.stem)\n",
    "            \n",
    "            # ファイル名からターゲットと温度を抽出（必要であれば）\n",
    "            # ファイル名が \"Al_Metal_300K_...\" のような形式を想定\n",
    "            parts = file.stem.split('_')\n",
    "            if len(parts) >= 3:\n",
    "                # 簡易的な抽出ロジック（ファイル名形式に合わせて調整可）\n",
    "                # 例: Target=Al_Metal, Temp=300K\n",
    "                target_guess = f\"{parts[0]}_{parts[1]}\"\n",
    "                temp_guess = parts[2]\n",
    "                df.insert(1, 'Target', target_guess)\n",
    "                df.insert(2, 'Temp', temp_guess)\n",
    "            \n",
    "            df_list.append(df)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {file.name}: {e}\")\n",
    "\n",
    "    # 全データを結合\n",
    "    if df_list:\n",
    "        merged_df = pd.concat(df_list, ignore_index=True)\n",
    "        \n",
    "        # 保存\n",
    "        output_path = dir_path / output_name\n",
    "        merged_df.to_csv(output_path, index=False)\n",
    "        print(f\"Successfully saved merged CSV to: {output_path}\")\n",
    "        print(f\"Total rows: {len(merged_df)}\")\n",
    "    else:\n",
    "        print(\"No valid data to merge.\")\n",
    "\n",
    "def main():\n",
    "    # === 設定部分 ===\n",
    "    files=[\"Al_LiOH_v8\",\"Al_Li_F_OH\",\"Al_Li_F\",\"Al_Na_F_OH\"]\n",
    "    for file in files:\n",
    "        base_dir = Path(f\"/home/jovyan/Kaori/MD/LiB_2/structure/{file}/analysis_results\")\n",
    "        # base_dir = Path(\"/home/jovyan/Kaori/MD/LiB_2/structure/Al_Li_F/analysis_results\")\n",
    "    \n",
    "        # 1. トレンドデータ（MSD, CNの時系列）をまとめる場合\n",
    "        print(\"--- Merging Trends ---\")\n",
    "        merge_csv_files(base_dir, file_pattern=\"*trends.csv\", output_name=\"all_trends_summary.csv\")\n",
    "        \n",
    "        # 2. 密度プロファイルをまとめる場合\n",
    "        print(\"\\n--- Merging Density Profiles ---\")\n",
    "        merge_csv_files(base_dir, file_pattern=\"*density.csv\", output_name=\"all_density_summary.csv\")\n",
    "        \n",
    "        # 3. RDFをまとめる場合\n",
    "        print(\"\\n--- Merging RDF Data ---\")\n",
    "        merge_csv_files(base_dir, file_pattern=\"*rdf_Al_O.csv\", output_name=\"all_rdf_summary.csv\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf41411-e5f5-4bd3-a071-c55d3074106c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8af4f934-4cd2-46c2-bb45-a2e2f5d40724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Al_LiOH_v8...\n",
      "Al_LiOH_v8: 計算可能なデータが不足しています。\n",
      "\n",
      "Processing: Al_Li_F_OH...\n",
      "Al_Li_F_OH: 計算可能なデータが不足しています。\n",
      "\n",
      "Processing: Al_Li_F...\n",
      "--- 活性化エネルギー算出結果 ---\n",
      "  Condition    Target  Ea [kJ/mol]  R-squared Temp_Range  Time_ps\n",
      "0   Al_Li_F  Al_Metal         8.42     0.0756   600-900K     39.5\n",
      "結果を /home/jovyan/Kaori/MD/LiB_2/structure/Activation_Energy_Results/Al_Li_F.csv に保存しました。\n",
      "\n",
      "Processing: Al_Na_F_OH...\n",
      "--- 活性化エネルギー算出結果 ---\n",
      "    Condition    Target  Ea [kJ/mol]  R-squared Temp_Range  Time_ps\n",
      "0  Al_Na_F_OH  Al_Metal        38.46     0.8682   600-900K     39.5\n",
      "結果を /home/jovyan/Kaori/MD/LiB_2/structure/Activation_Energy_Results/Al_Na_F_OH.csv に保存しました。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# --- 設定 ---\n",
    "files = [\"Al_LiOH_v8\", \"Al_Li_F_OH\", \"Al_Li_F\", \"Al_Na_F_OH\"]\n",
    "base_path = Path(\"/home/jovyan/Kaori/MD/LiB_2/structure\")\n",
    "output_base_dir = Path(\"/home/jovyan/Kaori/MD/LiB_2/structure/Activation_Energy_Results\")\n",
    "output_base_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "R = 8.314  # 気体定数 [J/(mol*K)]\n",
    "t_target = 39.5\n",
    "temp_min_limit = 600  # 活性化エネルギー算出に使う最低温度\n",
    "\n",
    "def calculate_ea(df, target_name='Al_Metal', t_target=39.5, temp_min=600):\n",
    "    \"\"\"\n",
    "    アレニウスプロットから活性化エネルギーを算出する\n",
    "    \"\"\"\n",
    "    # 1. ターゲット（Al_Metal等）でフィルタリング\n",
    "    df_target = df[df['Target'] == target_name].copy()\n",
    "    if df_target.empty:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # 2. Temp列のクリーンアップ ('K' 除去)\n",
    "    if df_target['Temp'].dtype == object:\n",
    "        df_target['Temp'] = df_target['Temp'].astype(str).str.replace('K', '', regex=False).astype(float)\n",
    "\n",
    "    # 3. 各温度ごとに target_time (39.5ps) に最も近い MSD を抽出\n",
    "    extracted_points = []\n",
    "    unique_temps = sorted(df_target['Temp'].unique())\n",
    "    \n",
    "    for temp in unique_temps:\n",
    "        temp_subset = df_target[df_target['Temp'] == temp]\n",
    "        \n",
    "        # Time_ps が存在する列であることを確認\n",
    "        if 'Time_ps' not in temp_subset.columns:\n",
    "            continue\n",
    "            \n",
    "        # target_time に最も近い行を選択\n",
    "        idx = (temp_subset['Time_ps'] - t_target).abs().idxmin()\n",
    "        row = temp_subset.loc[idx]\n",
    "        \n",
    "        # 許容誤差範囲内(1.0ps)であれば採用\n",
    "        if abs(row['Time_ps'] - t_target) <= 1.0:\n",
    "            extracted_points.append({\n",
    "                'Temp': temp,\n",
    "                'MSD_at_t': row['MSD_Surface'] # 大文字小文字はCSVに合わせる\n",
    "            })\n",
    "    \n",
    "    analysis_df = pd.DataFrame(extracted_points)\n",
    "    if analysis_df.empty:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # 4. 活性化エネルギーの回帰分析 (高温域のみ)\n",
    "    subset = analysis_df[analysis_df['Temp'] >= temp_min].dropna()\n",
    "    \n",
    "    results = []\n",
    "    if len(subset) >= 2:\n",
    "        inv_t = 1.0 / subset['Temp']      # 1/T\n",
    "        ln_msd = np.log(subset['MSD_at_t']) # ln(MSD)\n",
    "        \n",
    "        # 線形回帰\n",
    "        slope, intercept, r_value, p_value, std_err = stats.linregress(inv_t, ln_msd)\n",
    "        \n",
    "        # Ea [J/mol] = -slope * R\n",
    "        ea_kj_mol = (-slope * R) / 1000.0\n",
    "        \n",
    "        results.append({\n",
    "            'Condition': file, # 外側のループの変数\n",
    "            'Target': target_name,\n",
    "            'Ea [kJ/mol]': round(ea_kj_mol, 2),\n",
    "            'R-squared': round(r_value**2, 4),\n",
    "            'Temp_Range': f\"{int(subset['Temp'].min())}-{int(subset['Temp'].max())}K\",\n",
    "            'Time_ps': t_target\n",
    "        })\n",
    "                \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# --- メインループ ---\n",
    "for file in files:\n",
    "    input_file = base_path / file / \"analysis_results\" / \"all_trends_summary.csv\"\n",
    "    output_file = output_base_dir / f\"{file}.csv\"\n",
    "    \n",
    "    if not input_file.exists():\n",
    "        # もし trends_summary に Time_ps がない場合は、all_trends.csv 等を確認\n",
    "        input_file = base_path / file / \"analysis_results\" / \"all_trends.csv\"\n",
    "        if not input_file.exists():\n",
    "            print(f\"Skip: {file} のデータが見つかりませんでした。\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"Processing: {file}...\")\n",
    "    df = pd.read_csv(input_file)\n",
    "    \n",
    "    # 実行\n",
    "    result_df = calculate_ea(df, target_name='Al_Metal', t_target=t_target, temp_min=temp_min_limit)\n",
    "    \n",
    "    if not result_df.empty:\n",
    "        print(\"--- 活性化エネルギー算出結果 ---\")\n",
    "        print(result_df)\n",
    "        result_df.to_csv(output_file, index=False)\n",
    "        print(f\"結果を {output_file} に保存しました。\\n\")\n",
    "    else:\n",
    "        print(f\"{file}: 計算可能なデータが不足しています。\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "126a0084-c8d6-4f19-9261-21ab4be6103c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from pathlib import Path\n",
    "\n",
    "# --- 設定 ---\n",
    "files = [\"Al_Li_F_OH\"]\n",
    " # \"Al_Li_F\", \"Al_Na_F_OH\",\"Al_LiOH_v8\", ]\n",
    "base_path = Path(\"/home/jovyan/Kaori/MD/LiB_2/structure\")\n",
    "output_base_dir = Path(\"/home/jovyan/Kaori/MD/LiB_2/structure/Activation_Energy_Results\")\n",
    "output_base_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "R = 8.314\n",
    "t_target = 39.5\n",
    "\n",
    "# 検討したい温度帯のリスト (min, max)\n",
    "temp_ranges = [\n",
    "    (300, 400),\n",
    "    (300, 500),# 全範囲\n",
    "    (600, 900), # 高温域のみ（前回）\n",
    "    (750, 900)  # 超高温域（格子崩壊が顕著な領域）\n",
    "]\n",
    "\n",
    "def analyze_ea_variations(df, file_name, t_target=39.5, target_name='Al_Metal'):\n",
    "    # 1. 前処理\n",
    "    df_target = df[df['Target'] == target_name].copy()\n",
    "    if df_target['Temp'].dtype == object:\n",
    "        df_target['Temp'] = df_target['Temp'].astype(str).str.replace('K', '', regex=False).astype(float)\n",
    "\n",
    "    # 2. 39.5psのデータを抽出\n",
    "    extracted = []\n",
    "    for temp in sorted(df_target['Temp'].unique()):\n",
    "        temp_subset = df_target[df_target['Temp'] == temp]\n",
    "        if 'Time_ps' not in temp_subset.columns: continue\n",
    "        \n",
    "        idx = (temp_subset['Time_ps'] - t_target).abs().idxmin()\n",
    "        row = temp_subset.loc[idx]\n",
    "        if abs(row['Time_ps'] - t_target) <= 1.0:\n",
    "            extracted.append({'Temp': temp, 'MSD': row['MSD_Surface']})\n",
    "    \n",
    "    analysis_df = pd.DataFrame(extracted)\n",
    "    if analysis_df.empty: return pd.DataFrame()\n",
    "\n",
    "    results = []\n",
    "    # 3. 各温度帯で計算\n",
    "    for t_min, t_max in temp_ranges:\n",
    "        subset = analysis_df[(analysis_df['Temp'] >= t_min) & (analysis_df['Temp'] <= t_max)].dropna()\n",
    "        \n",
    "        if len(subset) >= 2:\n",
    "            x = 1.0 / subset['Temp']\n",
    "            y = np.log(subset['MSD'])\n",
    "            slope, intercept, r_value, p_value, std_err = stats.linregress(x, y)\n",
    "            \n",
    "            results.append({\n",
    "                'Condition': file_name,\n",
    "                'Range': f\"{t_min}-{t_max}K\",\n",
    "                'Ea [kJ/mol]': round((-slope * R) / 1000.0, 2),\n",
    "                'R-squared': round(r_value**2, 4),\n",
    "                'Points': len(subset)\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# --- 実行 ---\n",
    "all_comparison = []\n",
    "for file in files:\n",
    "    input_file = base_path / file / \"analysis_results\" / \"all_trends_summary.csv\"\n",
    "    if not input_file.exists():\n",
    "        input_file = base_path / file / \"analysis_results\" / \"all_trends.csv\"\n",
    "        if not input_file.exists(): continue\n",
    "    \n",
    "    df = pd.read_csv(input_file)\n",
    "    res = analyze_ea_variations(df, file)\n",
    "    if not res.empty:\n",
    "        print(f\"--- Analysis for {file} ---\")\n",
    "        print(res)\n",
    "        all_comparison.append(res)\n",
    "\n",
    "# 全データの比較表を保存\n",
    "if all_comparison:\n",
    "    summary_df = pd.concat(all_comparison)\n",
    "    summary_df.to_csv(output_base_dir / \"Ea_Range_Comparison.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2094b589-56e5-45d2-be01-2a7027a7bb26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Debugging Al_Li_F_OH ---\n",
      "1. Target 'Al_Metal' filtered: 480 rows found.\n",
      "2. Available Temperatures: [np.float64(300.0), np.float64(400.0), np.float64(500.0), np.float64(600.0), np.float64(750.0), np.float64(900.0)]\n",
      "3. Using MSD column: 'MSD_Surface'\n",
      "4. Extracting data near 39.5 ps...\n",
      "   - 300.0K: Found at 39.493670886075954 ps (MSD: nan)\n",
      "   - 400.0K: Found at 39.493670886075954 ps (MSD: nan)\n",
      "   - 500.0K: Found at 39.493670886075954 ps (MSD: nan)\n",
      "   - 600.0K: Found at 39.493670886075954 ps (MSD: nan)\n",
      "   - 750.0K: Found at 39.493670886075954 ps (MSD: nan)\n",
      "   - 900.0K: Found at 39.493670886075954 ps (MSD: nan)\n",
      "5. Skipped Range 300-400K: Not enough points (0)\n",
      "5. Skipped Range 300-500K: Not enough points (0)\n",
      "5. Skipped Range 600-900K: Not enough points (0)\n",
      "5. Skipped Range 750-900K: Not enough points (0)\n",
      "\n",
      "[!] No results were generated. Check the debug messages above.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from pathlib import Path\n",
    "\n",
    "# --- 設定 ---\n",
    "files = [\"Al_Li_F_OH\"]\n",
    "base_path = Path(\"/home/jovyan/Kaori/MD/LiB_2/structure\")\n",
    "output_base_dir = base_path / \"Activation_Energy_Results\"\n",
    "output_base_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "R = 8.314\n",
    "t_target = 39.5\n",
    "\n",
    "# 検討したい温度帯のリスト\n",
    "temp_ranges = [\n",
    "    (300, 400),\n",
    "    (300, 500),\n",
    "    (600, 900),\n",
    "    (750, 900)\n",
    "]\n",
    "\n",
    "def analyze_ea_variations(df, file_name, t_target=39.5, target_name='Al_Metal'):\n",
    "    print(f\"\\n--- Debugging {file_name} ---\")\n",
    "    \n",
    "    # 1. ターゲットフィルタリングのチェック\n",
    "    df_target = df[df['Target'] == target_name].copy()\n",
    "    print(f\"1. Target '{target_name}' filtered: {len(df_target)} rows found.\")\n",
    "    if df_target.empty:\n",
    "        print(f\"   [!] Available Targets are: {df['Target'].unique()}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # 2. 温度のクリーンアップ\n",
    "    if df_target['Temp'].dtype == object:\n",
    "        df_target['Temp'] = df_target['Temp'].astype(str).str.replace('K', '', regex=False).astype(float)\n",
    "    \n",
    "    available_temps = sorted(df_target['Temp'].unique())\n",
    "    print(f\"2. Available Temperatures: {available_temps}\")\n",
    "\n",
    "    # 3. カラム名の確認\n",
    "    msd_col = None\n",
    "    for col in ['MSD_Surface', 'MSD_surface', 'msd_surface']:\n",
    "        if col in df_target.columns:\n",
    "            msd_col = col\n",
    "            break\n",
    "    if not msd_col:\n",
    "        print(f\"   [!] Error: MSD column not found. Columns: {df_target.columns.tolist()}\")\n",
    "        return pd.DataFrame()\n",
    "    print(f\"3. Using MSD column: '{msd_col}'\")\n",
    "\n",
    "    # 4. 39.5psのデータを抽出\n",
    "    extracted = []\n",
    "    print(f\"4. Extracting data near {t_target} ps...\")\n",
    "    for temp in available_temps:\n",
    "        temp_subset = df_target[df_target['Temp'] == temp]\n",
    "        \n",
    "        if 'Time_ps' not in temp_subset.columns:\n",
    "            print(f\"   [!] 'Time_ps' not found for Temp {temp}K\")\n",
    "            continue\n",
    "            \n",
    "        # 最も近い時間を選択\n",
    "        idx = (temp_subset['Time_ps'] - t_target).abs().idxmin()\n",
    "        row = temp_subset.loc[idx]\n",
    "        diff = abs(row['Time_ps'] - t_target)\n",
    "        \n",
    "        if diff <= 1.0:\n",
    "            extracted.append({'Temp': temp, 'MSD': row[msd_col], 'Actual_Time': row['Time_ps']})\n",
    "            print(f\"   - {temp}K: Found at {row['Time_ps']} ps (MSD: {row[msd_col]:.4f})\")\n",
    "        else:\n",
    "            print(f\"   - {temp}K: Skipped (Closest time {row['Time_ps']} ps is too far from {t_target})\")\n",
    "    \n",
    "    analysis_df = pd.DataFrame(extracted)\n",
    "    if analysis_df.empty:\n",
    "        print(\"   [!] No data extracted for analysis.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # 5. 回帰計算\n",
    "    results = []\n",
    "    for t_min, t_max in temp_ranges:\n",
    "        subset = analysis_df[(analysis_df['Temp'] >= t_min) & (analysis_df['Temp'] <= t_max)].dropna()\n",
    "        \n",
    "        if len(subset) >= 2:\n",
    "            x = 1.0 / subset['Temp']\n",
    "            y = np.log(subset['MSD'])\n",
    "            slope, intercept, r_value, p_value, std_err = stats.linregress(x, y)\n",
    "            \n",
    "            ea_kj = round((-slope * R) / 1000.0, 2)\n",
    "            results.append({\n",
    "                'Condition': file_name,\n",
    "                'Range': f\"{t_min}-{t_max}K\",\n",
    "                'Ea [kJ/mol]': ea_kj,\n",
    "                'R-squared': round(r_value**2, 4),\n",
    "                'Points': len(subset)\n",
    "            })\n",
    "            print(f\"5. Calculated Range {t_min}-{t_max}K: Ea={ea_kj}, R2={round(r_value**2, 4)}\")\n",
    "        else:\n",
    "            print(f\"5. Skipped Range {t_min}-{t_max}K: Not enough points ({len(subset)})\")\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# --- 実行セクション ---\n",
    "all_comparison = []\n",
    "for file in files:\n",
    "    # パス候補の確認\n",
    "    input_file = base_path / file / \"analysis_results\" / \"all_trends_summary.csv\"\n",
    "    if not input_file.exists():\n",
    "        input_file = base_path / file / \"analysis_results\" / \"all_trends.csv\"\n",
    "    \n",
    "    if not input_file.exists():\n",
    "        print(f\"\\n[!] Error: File not found for {file}\")\n",
    "        continue\n",
    "    \n",
    "    df = pd.read_csv(input_file)\n",
    "    res = analyze_ea_variations(df, file)\n",
    "    \n",
    "    if not res.empty:\n",
    "        all_comparison.append(res)\n",
    "\n",
    "if all_comparison:\n",
    "    summary_df = pd.concat(all_comparison)\n",
    "    summary_df.to_csv(output_base_dir / \"Ea_Debug_Comparison.csv\", index=False)\n",
    "    print(\"\\n--- Final Results ---\")\n",
    "    print(summary_df)\n",
    "else:\n",
    "    print(\"\\n[!] No results were generated. Check the debug messages above.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa7728e4-3f49-480d-a7cb-d348555010f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing Al_Li_F_OH ---\n",
      " [!] No valid data for Al_Metal with non-nan MSD.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from pathlib import Path\n",
    "\n",
    "# --- 設定 ---\n",
    "files = [\"Al_Li_F_OH\"]\n",
    "base_path = Path(\"/home/jovyan/Kaori/MD/LiB_2/structure\")\n",
    "output_base_dir = base_path / \"Activation_Energy_Results\"\n",
    "output_base_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "R = 8.314\n",
    "t_target = 39.5\n",
    "temp_ranges = [(300, 400), (300, 500), (600, 900), (750, 900)]\n",
    "\n",
    "def analyze_ea_variations(df, file_name, t_target=39.5, target_name='Al_Metal'):\n",
    "    print(f\"\\n--- Processing {file_name} ---\")\n",
    "    \n",
    "    # 1. 前処理：Tempの数値化とTarget絞り込み\n",
    "    df = df.copy()\n",
    "    if df['Temp'].dtype == object:\n",
    "        df['Temp'] = df['Temp'].astype(str).str.replace('K', '', regex=False).astype(float)\n",
    "    \n",
    "    # ターゲットで絞り込み、かつ MSD が nan でない行だけを残す\n",
    "    msd_col = 'MSD_Surface' if 'MSD_Surface' in df.columns else 'MSD_Total'\n",
    "    df_clean = df[(df['Target'] == target_name) & (df[msd_col].notna())].copy()\n",
    "    \n",
    "    if df_clean.empty:\n",
    "        print(f\" [!] No valid data for {target_name} with non-nan MSD.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # 2. 39.5psのデータを各温度で抽出\n",
    "    extracted = []\n",
    "    for temp in sorted(df_clean['Temp'].unique()):\n",
    "        temp_subset = df_clean[df_clean['Temp'] == temp]\n",
    "        \n",
    "        # 最も target_time に近い行を抽出\n",
    "        idx = (temp_subset['Time_ps'] - t_target).abs().idxmin()\n",
    "        row = temp_subset.loc[idx]\n",
    "        \n",
    "        if abs(row['Time_ps'] - t_target) <= 1.5: # 許容範囲を少し広めに設定\n",
    "            extracted.append({'Temp': float(temp), 'MSD': float(row[msd_col])})\n",
    "            print(f\"  - {temp}K: MSD={row[msd_col]:.4f} (at {row['Time_ps']:.2f}ps)\")\n",
    "\n",
    "    analysis_df = pd.DataFrame(extracted)\n",
    "    if len(analysis_df) < 2:\n",
    "        print(\" [!] Not enough temperature points to perform regression.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # 3. 各温度帯で計算\n",
    "    results = []\n",
    "    for t_min, t_max in temp_ranges:\n",
    "        subset = analysis_df[(analysis_df['Temp'] >= t_min) & (analysis_df['Temp'] <= t_max)]\n",
    "        \n",
    "        if len(subset) >= 2:\n",
    "            # log(0) を避けるため微小値を加算または 0 を除外\n",
    "            subset = subset[subset['MSD'] > 0]\n",
    "            if len(subset) < 2: continue\n",
    "            \n",
    "            x = 1.0 / subset['Temp']\n",
    "            y = np.log(subset['MSD'])\n",
    "            slope, intercept, r_value, p_value, std_err = stats.linregress(x, y)\n",
    "            \n",
    "            ea_kj = round((-slope * R) / 1000.0, 2)\n",
    "            results.append({\n",
    "                'Condition': file_name,\n",
    "                'Range': f\"{t_min}-{t_max}K\",\n",
    "                'Ea [kJ/mol]': ea_kj,\n",
    "                'R-squared': round(r_value**2, 4),\n",
    "                'Points': len(subset)\n",
    "            })\n",
    "            print(f\"  => {t_min}-{t_max}K: Ea={ea_kj} kJ/mol, R2={round(r_value**2, 4)}\")\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# --- 実行 ---\n",
    "all_res = []\n",
    "for file in files:\n",
    "    path = base_path / file / \"analysis_results\" / \"all_trends_summary.csv\"\n",
    "    if not path.exists():\n",
    "        path = base_path / file / \"analysis_results\" / \"all_trends_summary.csv\"\n",
    "    \n",
    "    if path.exists():\n",
    "        res = analyze_ea_variations(pd.read_csv(path), file)\n",
    "        if not res.empty: all_res.append(res)\n",
    "\n",
    "if all_res:\n",
    "    pd.concat(all_res).to_csv(output_base_dir / \"Ea_Final_Results.csv\", index=False)\n",
    "    print(\"\\n--- Success! Results saved to Activation_Energy_Results/Ea_Final_Results.csv ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13bc9722-5e94-486c-b9a8-7493c6cb5326",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'all_trends_summary (3).csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m stats\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# データの読み込み\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mall_trends_summary (3).csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdiagnose_and_calc_ea\u001b[39m(df, target_name, t_target\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m39.5\u001b[39m):\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m=== Diagnosis for Target: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.py313/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.py313/lib/python3.13/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.py313/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.py313/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/.py313/lib/python3.13/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'all_trends_summary (3).csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# データの読み込み\n",
    "df = pd.read_csv('all_trends_summary (3).csv')\n",
    "\n",
    "def diagnose_and_calc_ea(df, target_name, t_target=39.5):\n",
    "    print(f\"\\n=== Diagnosis for Target: {target_name} ===\")\n",
    "    \n",
    "    # 対象ターゲットの抽出\n",
    "    df_target = df[df['Target'] == target_name].copy()\n",
    "    if df_target.empty:\n",
    "        print(f\" [!] Error: Target '{target_name}' not found in CSV.\")\n",
    "        return\n",
    "\n",
    "    # MSDカラムの存在と有効チェック\n",
    "    msd_col = 'MSD_Surface'\n",
    "    non_null_msd = df_target[msd_col].count()\n",
    "    print(f\" - Total rows: {len(df_target)}\")\n",
    "    print(f\" - Valid (non-nan) MSD_Surface values: {non_null_msd}\")\n",
    "\n",
    "    if non_null_msd == 0:\n",
    "        print(f\" [!] Critical: MSD data is missing for {target_name}. Ea calculation is impossible.\")\n",
    "        return\n",
    "\n",
    "    # 温度の数値化\n",
    "    if df_target['Temp'].dtype == object:\n",
    "        df_target['Temp'] = df_target['Temp'].astype(str).str.replace('K', '', regex=False).astype(float)\n",
    "\n",
    "    # 39.5 ps 時点のデータ抽出\n",
    "    extracted = []\n",
    "    for temp in sorted(df_target['Temp'].unique()):\n",
    "        temp_subset = df_target[(df_target['Temp'] == temp) & (df_target[msd_col].notna())]\n",
    "        if temp_subset.empty: continue\n",
    "        \n",
    "        idx = (temp_subset['Time_ps'] - t_target).abs().idxmin()\n",
    "        row = temp_subset.loc[idx]\n",
    "        extracted.append({'Temp': float(temp), 'MSD': float(row[msd_col])})\n",
    "\n",
    "    # Ea計算\n",
    "    analysis_df = pd.DataFrame(extracted)\n",
    "    if len(analysis_df) >= 2:\n",
    "        # 高温域 (750-900K) のみ\n",
    "        subset = analysis_df[analysis_df['Temp'] >= 750]\n",
    "        if len(subset) >= 2:\n",
    "            slope, _, r_value, _, _ = stats.linregress(1.0/subset['Temp'], np.log(subset['MSD']))\n",
    "            print(f\" -> Ea (750-900K): {round((-slope * 8.314)/1000.0, 2)} kJ/mol (R2={round(r_value**2, 4)})\")\n",
    "\n",
    "# 実行\n",
    "diagnose_and_calc_ea(df, 'Al_Metal')\n",
    "diagnose_and_calc_ea(df, 'Al_Oxide')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5842b576-61dc-42fd-9b08-18ea6c58ff84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skip: Al_Metal_300K in Al_LiOH_v8 (All items exist)\n",
      "Skip: Al_Metal_400K in Al_LiOH_v8 (All items exist)\n",
      "Skip: Al_Metal_500K in Al_LiOH_v8 (All items exist)\n",
      "Skip: Al_Oxide_300K in Al_LiOH_v8 (All items exist)\n",
      "Skip: Al_Oxide_400K in Al_LiOH_v8 (All items exist)\n",
      "Skip: Al_Oxide_500K in Al_LiOH_v8 (All items exist)\n",
      "Processing missing items for: Al_Metal_300K\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 165\u001b[0m\n\u001b[1;32m    162\u001b[0m                     analyze_md_results(traj_file, analysis_dir, label, needs_trends, needs_rdf, needs_density)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 165\u001b[0m     \u001b[43mmain_analysis\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 162\u001b[0m, in \u001b[0;36mmain_analysis\u001b[0;34m()\u001b[0m\n\u001b[1;32m    160\u001b[0m traj_file \u001b[38;5;241m=\u001b[39m base_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_md_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtemp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mK.traj\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m traj_file\u001b[38;5;241m.\u001b[39mexists():\n\u001b[0;32m--> 162\u001b[0m     \u001b[43manalyze_md_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraj_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manalysis_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneeds_trends\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneeds_rdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneeds_density\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 105\u001b[0m, in \u001b[0;36manalyze_md_results\u001b[0;34m(traj_path, output_dir, label, needs_trends, needs_rdf, needs_density)\u001b[0m\n\u001b[1;32m    103\u001b[0m idx_h \u001b[38;5;241m=\u001b[39m indices[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mH\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(idx_h) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 105\u001b[0m     _, h_d \u001b[38;5;241m=\u001b[39m \u001b[43mget_distances\u001b[49m\u001b[43m(\u001b[49m\u001b[43matoms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpositions\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx_h\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matoms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpositions\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx_h\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43matoms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcell\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpbc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43matoms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpbc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m     h2_count_list\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39msum(h_d[h_d \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.01\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.85\u001b[39m) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.py313/lib/python3.13/site-packages/ase/geometry/geometry.py:387\u001b[0m, in \u001b[0;36mget_distances\u001b[0;34m(p1, p2, cell, pbc)\u001b[0m\n\u001b[1;32m    384\u001b[0m     p2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39matleast_2d(p2)\n\u001b[1;32m    385\u001b[0m     D \u001b[38;5;241m=\u001b[39m (p2[np\u001b[38;5;241m.\u001b[39mnewaxis, :, :] \u001b[38;5;241m-\u001b[39m p1[:, np\u001b[38;5;241m.\u001b[39mnewaxis, :])\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m))\n\u001b[0;32m--> 387\u001b[0m (D, ), (D_len, ) \u001b[38;5;241m=\u001b[39m \u001b[43mconditional_find_mic\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mD\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcell\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpbc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpbc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p2 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    390\u001b[0m     Dout \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((np1, np1, \u001b[38;5;241m3\u001b[39m))\n",
      "File \u001b[0;32m~/.py313/lib/python3.13/site-packages/ase/geometry/geometry.py:246\u001b[0m, in \u001b[0;36mconditional_find_mic\u001b[0;34m(vectors, cell, pbc)\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell or pbc must be both set or both be None\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cell \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 246\u001b[0m     mics \u001b[38;5;241m=\u001b[39m [\u001b[43mfind_mic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpbc\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m vectors]\n\u001b[1;32m    247\u001b[0m     vectors, vector_lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mmics)\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.py313/lib/python3.13/site-packages/ase/geometry/geometry.py:219\u001b[0m, in \u001b[0;36mfind_mic\u001b[0;34m(v, cell, pbc)\u001b[0m\n\u001b[1;32m    217\u001b[0m naive_find_mic_is_safe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m--> 219\u001b[0m     vmin, vlen \u001b[38;5;241m=\u001b[39m \u001b[43mnaive_find_mic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# naive find mic is safe only for the following condition\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (vlen \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mmin\u001b[39m(cell\u001b[38;5;241m.\u001b[39mlengths()))\u001b[38;5;241m.\u001b[39mall():\n",
      "File \u001b[0;32m~/.py313/lib/python3.13/site-packages/ase/geometry/geometry.py:165\u001b[0m, in \u001b[0;36mnaive_find_mic\u001b[0;34m(v, cell)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mnaive_find_mic\u001b[39m(v, cell):\n\u001b[1;32m    159\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Finds the minimum-image representation of vector(s) v.\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;124;03m    Safe to use for (pbc.all() and (norm(v_mic) < 0.5 * min(cell.lengths()))).\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;124;03m    Can otherwise fail for non-orthorhombic cells.\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;124;03m    Described in:\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03m    W. Smith, \"The Minimum Image Convention in Non-Cubic MD Cells\", 1989,\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;124;03m    http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.57.1696.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 165\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[43mCell\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcell\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaled_positions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m     f \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfloor(f \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\n\u001b[1;32m    167\u001b[0m     vmin \u001b[38;5;241m=\u001b[39m f \u001b[38;5;241m@\u001b[39m cell\n",
      "File \u001b[0;32m~/.py313/lib/python3.13/site-packages/ase/cell.py:263\u001b[0m, in \u001b[0;36mCell.scaled_positions\u001b[0;34m(self, positions)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mscaled_positions\u001b[39m(\u001b[38;5;28mself\u001b[39m, positions) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m    257\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Calculate scaled positions from Cartesian positions.\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \n\u001b[1;32m    259\u001b[0m \u001b[38;5;124;03m    The scaled positions are the positions given in the basis\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;124;03m    of the cell vectors.  For the purpose of defining the basis, cell\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;124;03m    vectors that are zero will be replaced by unit vectors as per\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;124;03m    :meth:`~ase.cell.Cell.complete`.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomplete\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpositions\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mT\n",
      "File \u001b[0;32m/usr/local/pyenv/versions/python313/lib/python3.13/site-packages/numpy/linalg/_linalg.py:410\u001b[0m, in \u001b[0;36msolve\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m    407\u001b[0m signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDD->D\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isComplexType(t) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdd->d\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m errstate(call\u001b[38;5;241m=\u001b[39m_raise_linalgerror_singular, invalid\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcall\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    409\u001b[0m               over\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m, divide\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m, under\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 410\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mgufunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap(r\u001b[38;5;241m.\u001b[39mastype(result_t, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from ase.io.trajectory import Trajectory\n",
    "from ase.geometry import get_distances  \n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 全体のフォントサイズ設定\n",
    "plt.rcParams.update({\n",
    "    'font.size': 22, \n",
    "    'axes.labelsize': 22, \n",
    "    'xtick.labelsize': 22, \n",
    "    'ytick.labelsize': 22,\n",
    "    'legend.fontsize': 22\n",
    "})\n",
    "\n",
    "def compute_manual_rdf(atoms, indices1, indices2, rmax=6.0, nbins=100):\n",
    "    if len(indices1) == 0 or len(indices2) == 0:\n",
    "        return np.zeros(nbins), np.linspace(0, rmax, nbins+1)\n",
    "    idx1, idx2 = indices1.flatten(), indices2.flatten()\n",
    "    p1, p2 = atoms.positions[idx1], atoms.positions[idx2]\n",
    "    _, dists = get_distances(p1, p2, cell=atoms.cell, pbc=atoms.pbc)\n",
    "    valid_dists = dists[dists > 0.01] if np.array_equal(idx1, idx2) else dists\n",
    "    hist, bin_edges = np.histogram(valid_dists, range=(0, rmax), bins=nbins)\n",
    "    return hist, bin_edges\n",
    "\n",
    "def analyze_md_results(traj_path, output_dir, label, needs_trends=True, needs_rdf=True, needs_density=True):\n",
    "    print(f\"Processing missing items for: {label}\")\n",
    "    try:\n",
    "        traj = Trajectory(traj_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading trajectory: {e}\"); return\n",
    "\n",
    "    initial_atoms = traj[0]\n",
    "    final_atoms = traj[-1]\n",
    "    cell_vol = final_atoms.get_volume()\n",
    "    cell_diag = final_atoms.get_cell().diagonal()\n",
    "    symbols = np.array(final_atoms.get_chemical_symbols())\n",
    "    indices = {s: np.where(symbols == s)[0] for s in ['Al', 'O', 'Li', 'H', 'F']}\n",
    "\n",
    "    # 表面/内部 Al分類\n",
    "    if len(indices['Al']) > 0:\n",
    "        al_pos = initial_atoms.positions[indices['Al']]\n",
    "        z_max = np.max(al_pos[:, 2])\n",
    "        surface_mask = al_pos[:, 2] > (z_max - 4.0)\n",
    "        idx_al_surface = indices['Al'][surface_mask].flatten()\n",
    "        idx_al_bulk = indices['Al'][~surface_mask].flatten()\n",
    "        idx_al_total = indices['Al'].flatten()\n",
    "    else:\n",
    "        idx_al_surface = idx_al_bulk = idx_al_total = np.array([])\n",
    "\n",
    "    # 1. 密度解析 (最終フレームのみで計算可能なため独立)\n",
    "    if needs_density:\n",
    "        density_data = {'Z_axis': np.linspace(0, cell_diag[2], 100)}\n",
    "        bins_z = np.linspace(0, cell_diag[2], 101)\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        for spec, idx in indices.items():\n",
    "            if len(idx.flatten()) > 0:\n",
    "                hist, _ = np.histogram(final_atoms.positions[idx.flatten(), 2], bins=bins_z)\n",
    "                density_data[spec] = hist\n",
    "                plt.plot(density_data['Z_axis'], hist, label=spec, lw=2)\n",
    "        pd.DataFrame(density_data).to_csv(output_dir / f\"{label}_density.csv\", index=False)\n",
    "        plt.title(f\"Density: {label}\"); plt.legend(); plt.savefig(output_dir / f\"{label}_density.png\"); plt.close()\n",
    "\n",
    "    # 2. 時系列解析 (Trends) および RDF (全フレーム走査が必要な項目)\n",
    "    if needs_trends or needs_rdf:\n",
    "        time_points, cn_avg_list, reacted_al_list, h2_count_list = [], [], [], []\n",
    "        msd_total_list, msd_surface_list, msd_bulk_list = [], [], []\n",
    "        \n",
    "        rdf_rmax, rdf_nbins = 6.0, 100\n",
    "        rdf_sum = np.zeros(rdf_nbins)\n",
    "        rdf_count = 0\n",
    "        start_rdf_frame = int(len(traj) * 0.5)\n",
    "        idx_reactants = np.concatenate([indices['O'].flatten(), indices['F'].flatten()])\n",
    "\n",
    "        initial_pos_total = initial_atoms.positions[idx_al_total] if len(idx_al_total) > 0 else None\n",
    "        initial_pos_surface = initial_atoms.positions[idx_al_surface] if len(idx_al_surface) > 0 else None\n",
    "        initial_pos_bulk = initial_atoms.positions[idx_al_bulk] if len(idx_al_bulk) > 0 else None\n",
    "        dt_ps = 40.0 / max(len(traj)-1, 1)\n",
    "\n",
    "        for i, atoms in enumerate(traj):\n",
    "            time_points.append(i * dt_ps)\n",
    "            if needs_trends:\n",
    "                # 配位数/反応数\n",
    "                if len(idx_al_total) > 0 and len(idx_reactants) > 0:\n",
    "                    _, d_len = get_distances(atoms.positions[idx_al_total], atoms.positions[idx_reactants], cell=atoms.cell, pbc=atoms.pbc)\n",
    "                    cn_per_atom = np.sum(d_len.reshape(len(idx_al_total), len(idx_reactants)) < 2.5, axis=1)\n",
    "                    cn_avg_list.append(np.mean(cn_per_atom))\n",
    "                    reacted_al_list.append(np.sum(cn_per_atom >= 1))\n",
    "                else:\n",
    "                    cn_avg_list.append(0); reacted_al_list.append(0)\n",
    "                \n",
    "                # MSD\n",
    "                def get_msd(pos, init): return np.mean(np.sum((pos - init)**2, axis=1)) if init is not None else 0\n",
    "                msd_total_list.append(get_msd(atoms.positions[idx_al_total], initial_pos_total))\n",
    "                msd_surface_list.append(get_msd(atoms.positions[idx_al_surface], initial_pos_surface))\n",
    "                msd_bulk_list.append(get_msd(atoms.positions[idx_al_bulk], initial_pos_bulk))\n",
    "\n",
    "                # H2検出\n",
    "                idx_h = indices['H'].flatten()\n",
    "                if len(idx_h) > 1:\n",
    "                    _, h_d = get_distances(atoms.positions[idx_h], atoms.positions[idx_h], cell=atoms.cell, pbc=atoms.pbc)\n",
    "                    h2_count_list.append(np.sum(h_d[h_d > 0.01] < 0.85) // 2)\n",
    "                else:\n",
    "                    h2_count_list.append(0)\n",
    "\n",
    "            if needs_rdf and i >= start_rdf_frame:\n",
    "                hist, edges = compute_manual_rdf(atoms, indices['Al'], idx_reactants, rmax=rdf_rmax, nbins=rdf_nbins)\n",
    "                rdf_sum += hist; rdf_count += 1; bin_edges = edges\n",
    "\n",
    "        if needs_trends:\n",
    "            df_trends = pd.DataFrame({'Time_ps': time_points, 'CN_Avg': cn_avg_list, 'Reacted_Al_Count': reacted_al_list, \n",
    "                                      'H2_Count': h2_count_list, 'MSD_Total': msd_total_list, 'MSD_Surface': msd_surface_list, 'MSD_Bulk': msd_bulk_list})\n",
    "            df_trends.to_csv(output_dir / f\"{label}_trends.csv\", index=False)\n",
    "            # グラフ描画\n",
    "            plt.figure(); plt.plot(time_points, msd_surface_list, label='Surface'); plt.plot(time_points, msd_bulk_list, label='Bulk')\n",
    "            plt.title(f\"MSD: {label}\"); plt.legend(); plt.savefig(output_dir / f\"{label}_msd_detailed.png\"); plt.close()\n",
    "\n",
    "        if needs_rdf and rdf_count > 0:\n",
    "            r = 0.5 * (bin_edges[1:] + bin_edges[:-1])\n",
    "            rho = len(idx_reactants) / cell_vol\n",
    "            gr = (rdf_sum / rdf_count) / (len(indices['Al']) * (4 * np.pi * r**2 * (bin_edges[1]-bin_edges[0])) * rho)\n",
    "            pd.DataFrame({'r': r, 'g_r': gr}).to_csv(output_dir / f\"{label}_rdf_Al_O.csv\", index=False)\n",
    "\n",
    "def main_analysis():\n",
    "    files = [\"Al_LiOH_v8\", \"Al_Li_F_OH\", \"Al_Li_F\", \"Al_Na_F_OH\"]\n",
    "    required_trends_cols = ['Time_ps', 'CN_Avg', 'Reacted_Al_Count', 'H2_Count', 'MSD_Total', 'MSD_Surface', 'MSD_Bulk']\n",
    "    \n",
    "    for file in files:\n",
    "        base_dir = Path(f\"/home/jovyan/Kaori/MD/LiB_2/structure/{file}\")\n",
    "        analysis_dir = base_dir / \"analysis_results\"\n",
    "        analysis_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        for target in [\"Al_Metal\", \"Al_Oxide\"]:\n",
    "            for temp in [300, 400, 500, 600, 750, 900]:\n",
    "                label = f\"{target}_{temp}K\"\n",
    "                needs_trends, needs_rdf, needs_density = True, True, True\n",
    "                \n",
    "                # --- 項目ごとのスキップ判定 ---\n",
    "                # 1. Trends CSVの項目チェック\n",
    "                trends_path = analysis_dir / f\"{label}_trends.csv\"\n",
    "                if trends_path.exists():\n",
    "                    try:\n",
    "                        df_tmp = pd.read_csv(trends_path)\n",
    "                        if all(col in df_tmp.columns for col in required_trends_cols):\n",
    "                            needs_trends = False\n",
    "                    except: pass\n",
    "                \n",
    "                # 2. RDF/Densityのファイル存在チェック\n",
    "                if (analysis_dir / f\"{label}_rdf_Al_O.csv\").exists(): needs_rdf = False\n",
    "                if (analysis_dir / f\"{label}_density.csv\").exists(): needs_density = False\n",
    "\n",
    "                if not (needs_trends or needs_rdf or needs_density):\n",
    "                    print(f\"Skip: {label} in {file} (All items exist)\")\n",
    "                    continue\n",
    "\n",
    "                traj_file = base_dir / f\"{target}_md_{temp}K.traj\"\n",
    "                if traj_file.exists():\n",
    "                    analyze_md_results(traj_file, analysis_dir, label, needs_trends, needs_rdf, needs_density)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d69bc88-db2d-4ff4-8e21-c3040113e234",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd17276c-5bae-48b6-8ac5-e66a1ad16d7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8bd5f6-5bb0-484b-9047-3e54aa99144f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b20f974-4381-49ac-a19e-9cf1190e7706",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0129942d-8667-4bd0-9f4a-429fd7db03b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7645bca5-f30c-44d2-bdcf-579bca44dae7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d47e42-427c-42f4-ab69-e78e97857ca0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a40c0b-9023-487e-83b5-b5935bf81250",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "1: Python 3.13",
   "language": "python",
   "name": "python313"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
