{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b997d95f-669a-49e4-82be-c516a05d6bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem      Size  Used Avail Use% Mounted on\n",
      "overlay          30G   14G   17G  45% /\n",
      "tmpfs            64M     0   64M   0% /dev\n",
      "tmpfs           3.9G     0  3.9G   0% /sys/fs/cgroup\n",
      "/dev/nvme1n1     98G   98G  202M 100% /home/jovyan\n",
      "/dev/nvme0n1p1   30G   14G   17G  45% /etc/hosts\n",
      "shm              64M  8.0K   64M   1% /dev/shm\n",
      "tmpfs           7.0G  4.0K  7.0G   1% /run/secrets/tokens\n",
      "tmpfs           3.9G     0  3.9G   0% /proc/acpi\n",
      "tmpfs           3.9G     0  3.9G   0% /sys/firmware\n",
      "128K\tNMC.ipynb\n",
      "236K\tNMC_MD.ipynb\n",
      "80K\tUntitled.ipynb\n",
      "8.0K\textracted_data_advanced.csv\n",
      "44K\textracted_data_final.csv\n",
      "96K\textracted_data_final_with_filenames-Copy1.csv\n",
      "96K\textracted_data_final_with_filenames.csv\n",
      "18G\toutput\n",
      "684K\tpressure.ipynb\n",
      "308K\tstructure.ipynb\n"
     ]
    }
   ],
   "source": [
    "!df -h\n",
    "!du -sh *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7eaef5ad-e1f5-4ad0-be23-c263f1875dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1673.5294117647059"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=(3300*2+800+1500)/17\n",
    "x+1150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0e3bdcc-c901-4edb-bac6-5ecc47e6caf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2406.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=6315/6\n",
    "y+1353.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5915c5c0-d2bf-4c6b-9f19-6fdb4d08bdcb",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1677304134.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[15], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    import jupyter-resource-usage\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import jupyter-resource-usage\n",
    "help(jupyter-resource-usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4153f935-bb68-491a-a8c0-d1988b1f85a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STEP 1: Trajectoryãƒ•ã‚¡ã‚¤ãƒ«ã®åˆ†æã¨æ•´ç†ã‚’é–‹å§‹ ---\n",
      "ğŸ” '/home/jovyan/Kaori/MD/LiB_2/structure/output' ã‹ã‚‰ 0 å€‹ã® .traj ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç™ºè¦‹ã€‚\n",
      " -> å‡¦ç†å¯¾è±¡ã®.trajãƒ•ã‚¡ã‚¤ãƒ«ãŒãªã„ãŸã‚ã€ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚\n",
      "\n",
      "--- STEP 2: ç•Œé¢ æ§‹ç¯‰ãƒ»ãƒˆãƒªãƒŸãƒ³ã‚°ãƒ»æœ€é©åŒ–ãƒ—ãƒ­ã‚»ã‚¹ã‚’é–‹å§‹ ---\n",
      "âœ… æœ€çµ‚æ§‹é€ ã®ä¿å­˜å…ˆ: '/home/jovyan/Kaori/MD/LiB_2/structure/output/final_interfaces'\n",
      "ğŸ” '/home/jovyan/Kaori/MD/LiB_2/structure/output' ã‹ã‚‰æœ€é©åŒ–æ¸ˆã¿è¡¨é¢ (*_final.xyz) ã‚’åˆ†é¡ä¸­...\n",
      "  - Alè¡¨é¢: 11å€‹,  æ­£æ¥µæè¡¨é¢: 86å€‹\n",
      "\n",
      "--- Al/NMCç•Œé¢ã®çµ„ã¿åˆã‚ã›å‡¦ç†ã‚’é–‹å§‹ ---\n",
      "\n",
      "--- å‡¦ç†é–‹å§‹: Al_110_(1, 1, 0) + NMC111_selective_Co_removal_110_(1, 1, 0) ---\n",
      "    1. ç•Œé¢ã‚’æ§‹ç¯‰ä¸­...\n",
      "    2. ç•Œé¢ã‚’ãƒˆãƒªãƒŸãƒ³ã‚°ä¸­ (å„ã‚¹ãƒ©ãƒ–åšã¿: 25.0 Ã…)...\n",
      "       -> 9 å€‹ã®åŸå­ã‚’å‰Šé™¤ã—ã¾ã™ã€‚\n",
      "    3. ãƒˆãƒªãƒŸãƒ³ã‚°å¾Œã®æ§‹é€ ã‚’æœ€é©åŒ–ä¸­...\n",
      "  -> Matlantisæœ€é©åŒ–é–‹å§‹ (Interface_Al_110_(1, 1, 0)_on_NMC111_selective_Co_removal_110_(1, 1, 0)_trimmed, fmax = 0.05) ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fedbe8f89cf948eabb664baee5229bc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> âœ”ï¸ æœ€é©åŒ–å®Œäº†ï¼ ã‚¨ãƒãƒ«ã‚®ãƒ¼: -2444.426 eV\n",
      "  -> ğŸ’¾ æœ€é©åŒ–å¾Œã®ä¸­é–“æ§‹é€ ã‚’ä¿å­˜ã—ã¾ã™: Interface_Al_110_(1, 1, 0)_on_NMC111_selective_Co_removal_110_(1, 1, 0)_trimmed.xyz\n",
      "    4. æœ€çµ‚æ§‹é€ ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ä¸­ -> Interface_Al_110_(1, 1, 0)_on_NMC111_selective_Co_removal_110_(1, 1, 0)_trimmed.cif\n",
      "\n",
      "--- å‡¦ç†é–‹å§‹: Al_110_(1, 1, 0) + NMC111_Co_MntoNi_40_110_(1, 1, 0) ---\n",
      "    1. ç•Œé¢ã‚’æ§‹ç¯‰ä¸­...\n",
      "    2. ç•Œé¢ã‚’ãƒˆãƒªãƒŸãƒ³ã‚°ä¸­ (å„ã‚¹ãƒ©ãƒ–åšã¿: 25.0 Ã…)...\n",
      "       -> 9 å€‹ã®åŸå­ã‚’å‰Šé™¤ã—ã¾ã™ã€‚\n",
      "    3. ãƒˆãƒªãƒŸãƒ³ã‚°å¾Œã®æ§‹é€ ã‚’æœ€é©åŒ–ä¸­...\n",
      "  -> Matlantisæœ€é©åŒ–é–‹å§‹ (Interface_Al_110_(1, 1, 0)_on_NMC111_Co_MntoNi_40_110_(1, 1, 0)_trimmed, fmax = 0.05) ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71f54458c6604512b05cb069a6825484",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> âœ”ï¸ æœ€é©åŒ–å®Œäº†ï¼ ã‚¨ãƒãƒ«ã‚®ãƒ¼: -2451.518 eV\n",
      "  -> ğŸ’¾ æœ€é©åŒ–å¾Œã®ä¸­é–“æ§‹é€ ã‚’ä¿å­˜ã—ã¾ã™: Interface_Al_110_(1, 1, 0)_on_NMC111_Co_MntoNi_40_110_(1, 1, 0)_trimmed.xyz\n",
      "    4. æœ€çµ‚æ§‹é€ ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ä¸­ -> Interface_Al_110_(1, 1, 0)_on_NMC111_Co_MntoNi_40_110_(1, 1, 0)_trimmed.cif\n",
      "\n",
      "--- å‡¦ç†é–‹å§‹: Al_110_(1, 1, 0) + NMC111_Co_MntoNi_40_012_(0, 1, 2) ---\n",
      "    1. ç•Œé¢ã‚’æ§‹ç¯‰ä¸­...\n",
      "    2. ç•Œé¢ã‚’ãƒˆãƒªãƒŸãƒ³ã‚°ä¸­ (å„ã‚¹ãƒ©ãƒ–åšã¿: 25.0 Ã…)...\n",
      "       -> 0 å€‹ã®åŸå­ã‚’å‰Šé™¤ã—ã¾ã™ã€‚\n",
      "    3. ãƒˆãƒªãƒŸãƒ³ã‚°å¾Œã®æ§‹é€ ã‚’æœ€é©åŒ–ä¸­...\n",
      "  -> Matlantisæœ€é©åŒ–é–‹å§‹ (Interface_Al_110_(1, 1, 0)_on_NMC111_Co_MntoNi_40_012_(0, 1, 2)_trimmed, fmax = 0.05) ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc3cba38475d4b98af30deac5f7406b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> âœ”ï¸ æœ€é©åŒ–å®Œäº†ï¼ ã‚¨ãƒãƒ«ã‚®ãƒ¼: -1556.047 eV\n",
      "  -> ğŸ’¾ æœ€é©åŒ–å¾Œã®ä¸­é–“æ§‹é€ ã‚’ä¿å­˜ã—ã¾ã™: Interface_Al_110_(1, 1, 0)_on_NMC111_Co_MntoNi_40_012_(0, 1, 2)_trimmed.xyz\n",
      "    4. æœ€çµ‚æ§‹é€ ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ä¸­ -> Interface_Al_110_(1, 1, 0)_on_NMC111_Co_MntoNi_40_012_(0, 1, 2)_trimmed.cif\n",
      "\n",
      "--- å‡¦ç†é–‹å§‹: Al_110_(1, 1, 0) + NMC111_pristine_010_(0, 1, 0) ---\n",
      "    1. ç•Œé¢ã‚’æ§‹ç¯‰ä¸­...\n",
      "    2. ç•Œé¢ã‚’ãƒˆãƒªãƒŸãƒ³ã‚°ä¸­ (å„ã‚¹ãƒ©ãƒ–åšã¿: 25.0 Ã…)...\n",
      "       -> 328 å€‹ã®åŸå­ã‚’å‰Šé™¤ã—ã¾ã™ã€‚\n",
      "    3. ãƒˆãƒªãƒŸãƒ³ã‚°å¾Œã®æ§‹é€ ã‚’æœ€é©åŒ–ä¸­...\n",
      "  -> Matlantisæœ€é©åŒ–é–‹å§‹ (Interface_Al_110_(1, 1, 0)_on_NMC111_pristine_010_(0, 1, 0)_trimmed, fmax = 0.05) ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33eeab8239ee4eca9ae250d8c51bfa73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Trajectoryãƒ•ã‚¡ã‚¤ãƒ«ã®æ•´ç†ã¨ã€ãã‚Œã«åŸºã¥ãç•Œé¢æ§‹ç¯‰ãƒ»æœ€é©åŒ–ã‚’è‡ªå‹•åŒ–ã™ã‚‹ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã€‚\n",
    "\n",
    "[æœ€çµ‚ç‰ˆ: æ§‹ç¯‰â†’ãƒˆãƒªãƒŸãƒ³ã‚°â†’æœ€é©åŒ–]\n",
    "- ç ´æã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ãªã©ã€ç‰¹å®šãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¦ã‚‚å…¨ä½“ãŒåœæ­¢ã›ãšã€\n",
    "  æ¬¡ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†ã‚’ç¶šè¡Œã—ã¾ã™ã€‚\n",
    "\n",
    "STEP 1: Trajectoryãƒ•ã‚¡ã‚¤ãƒ«ã®åˆ†æã¨ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—\n",
    "  - 0KBã®.trajãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆå¤±æ•—ã—ãŸè¨ˆç®—ï¼‰ã‚’å‰Šé™¤\n",
    "  - æ­£å¸¸ãª.trajãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆæœŸ/æœ€çµ‚æ§‹é€ ã®.xyzã«å¤‰æ›ã—ã€å…ƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤\n",
    "\n",
    "STEP 2: ç•Œé¢ã®æ§‹ç¯‰ã€ãƒˆãƒªãƒŸãƒ³ã‚°ã€æœ€é©åŒ–\n",
    "  - STEP 1ã§ç”Ÿæˆã•ã‚ŒãŸæœ€çµ‚æ§‹é€ (.xyz)ã‚’ç”¨ã„ã¦ç•Œé¢ã‚’æ§‹ç¯‰\n",
    "  - æ§‹ç¯‰ã—ãŸç•Œé¢ã‚’æŒ‡å®šã®åšã¿ï¼ˆ25Ã…/ã‚¹ãƒ©ãƒ–ï¼‰ã«ãƒˆãƒªãƒŸãƒ³ã‚°\n",
    "  - ãƒˆãƒªãƒŸãƒ³ã‚°å¾Œã®æ§‹é€ ã«å¯¾ã—ã¦Matlantisã§åŸå­ä½ç½®ã‚’æœ€é©åŒ–\n",
    "\"\"\"\n",
    "import os\n",
    "import itertools\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import nglview as nv\n",
    "\n",
    "# ASE\n",
    "from ase.io import read, write\n",
    "from ase.build import stack,cut\n",
    "\n",
    "# Matlantis / PFP\n",
    "from matlantis_features.atoms import MatlantisAtoms\n",
    "from matlantis_features.features.common.opt import FireLBFGSASEOptFeature\n",
    "from matlantis_features.utils.calculators import pfp_estimator_fn\n",
    "from pfp_api_client.pfp.estimator import EstimatorCalcMode\n",
    "\n",
    "# --- STEP 1: Trajectoryãƒ•ã‚¡ã‚¤ãƒ«ã®æ•´ç†ã‚¯ãƒ©ã‚¹ ---\n",
    "class TrajectoryCleanup:\n",
    "    \"\"\"\n",
    "    .trajãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†æã—ã€.xyzã«å¤‰æ›ã—ã¦ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã™ã‚‹ã‚¯ãƒ©ã‚¹ã€‚\n",
    "    \"\"\"\n",
    "    def __init__(self, directory):\n",
    "        self.directory = Path(directory)\n",
    "        print(\"--- STEP 1: Trajectoryãƒ•ã‚¡ã‚¤ãƒ«ã®åˆ†æã¨æ•´ç†ã‚’é–‹å§‹ ---\")\n",
    "        if not self.directory.is_dir():\n",
    "            print(f\"ğŸ›‘ ã‚¨ãƒ©ãƒ¼: ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª '{self.directory}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚\")\n",
    "            self.files_to_process = []\n",
    "        else:\n",
    "            self.files_to_process = list(self.directory.glob(\"*.traj\"))\n",
    "            print(f\"ğŸ” '{self.directory}' ã‹ã‚‰ {len(self.files_to_process)} å€‹ã® .traj ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç™ºè¦‹ã€‚\")\n",
    "\n",
    "    def process_file(self, traj_path):\n",
    "        \"\"\"\n",
    "        1ã¤ã®.trajãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã™ã‚‹ã€‚\n",
    "        [ä¿®æ­£] ã“ã®é–¢æ•°å…¨ä½“ã‚’try...exceptã§å›²ã¿ã€ã‚¨ãƒ©ãƒ¼è€æ€§ã‚’å‘ä¸Šã€‚\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã‚’ç¢ºèª\n",
    "            file_size = traj_path.stat().st_size\n",
    "            if file_size == 0:\n",
    "                print(f\"  -> ğŸ—‘ï¸  0KBãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¾ã™: {traj_path.name}\")\n",
    "                os.remove(traj_path)\n",
    "                return\n",
    "\n",
    "            # æ­£å¸¸ãªãƒ•ã‚¡ã‚¤ãƒ«ã¯å¤‰æ›\n",
    "            base_name = traj_path.stem\n",
    "            initial_xyz_path = self.directory / f\"{base_name}_initial.xyz\"\n",
    "            final_xyz_path = self.directory / f\"{base_name}_final.xyz\"\n",
    "\n",
    "            print(f\"  -> ğŸ”„ å¤‰æ›ä¸­: {traj_path.name}\")\n",
    "\n",
    "            # Trajectoryã‹ã‚‰åˆæœŸæ§‹é€ ã¨æœ€çµ‚æ§‹é€ ã‚’èª­ã¿è¾¼ã¿\n",
    "            atoms_list = read(traj_path, index=\":\")\n",
    "            if not atoms_list:\n",
    "                print(f\"  -> âŒ èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ï¼ˆç©ºã®Trajectoryï¼‰ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¾ã™: {traj_path.name}\")\n",
    "                os.remove(traj_path)\n",
    "                return\n",
    "\n",
    "            # .xyzãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜\n",
    "            write(str(initial_xyz_path), atoms_list[0])\n",
    "            write(str(final_xyz_path), atoms_list[-1])\n",
    "\n",
    "            # å…ƒã®.trajãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤\n",
    "            os.remove(traj_path)\n",
    "            print(f\"  -> âœ”ï¸ å¤‰æ›æˆåŠŸã€å…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¾ã—ãŸ: {traj_path.name}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            # äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã€ãƒ­ã‚°ã‚’å‡ºåŠ›ã—ã¦å‡¦ç†ã‚’ç¶šè¡Œ\n",
    "            print(f\"  -> âŒ é‡å¤§ãªã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸãŸã‚ã€ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ ({traj_path.name}): {e}\")\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"å…¨ã¦ã®å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ã«å¯¾ã—ã¦å‡¦ç†ã‚’å®Ÿè¡Œã™ã‚‹ã€‚\"\"\"\n",
    "        if not self.files_to_process:\n",
    "            print(\" -> å‡¦ç†å¯¾è±¡ã®.trajãƒ•ã‚¡ã‚¤ãƒ«ãŒãªã„ãŸã‚ã€ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚\")\n",
    "            return\n",
    "        for traj_file in self.files_to_process:\n",
    "            self.process_file(traj_file)\n",
    "        print(\"\\nâœ¨ STEP 1 å®Œäº†ã€‚\")\n",
    "\n",
    "\n",
    "# --- Matlantisæœ€é©åŒ–é–¢æ•° (å…±é€š) ---\n",
    "def run_matlantis_optimization(atoms, trajectory_path, fmax=0.05, name=\"structure\"):\n",
    "    print(f\"  -> Matlantisæœ€é©åŒ–é–‹å§‹ ({name}, fmax = {fmax}) ...\")\n",
    "    matlantis_atoms = MatlantisAtoms(atoms)\n",
    "    estimator_function = pfp_estimator_fn(\n",
    "        model_version='v7.0.0', calc_mode=EstimatorCalcMode.CRYSTAL_PLUS_D3\n",
    "    )\n",
    "    position_optimizer = FireLBFGSASEOptFeature(\n",
    "        estimator_fn=estimator_function, filter=False, trajectory=str(trajectory_path),\n",
    "        n_run=5000, fmax=fmax, show_progress_bar=True\n",
    "    )\n",
    "    try:\n",
    "        result = position_optimizer(matlantis_atoms)\n",
    "        optimized_atoms = result.atoms.ase_atoms\n",
    "        final_energy = result.output.energy_log[-1]\n",
    "        print(f\"  -> âœ”ï¸ æœ€é©åŒ–å®Œäº†ï¼ ã‚¨ãƒãƒ«ã‚®ãƒ¼: {final_energy:.3f} eV\")\n",
    "        # .xyzãƒ•ã‚¡ã‚¤ãƒ«ã§ã®ä¿å­˜ã¯ã“ã“ã§ç¶™ç¶š\n",
    "        xyz_save_path = Path(trajectory_path).with_suffix('.xyz')\n",
    "        print(f\"  -> ğŸ’¾ æœ€é©åŒ–å¾Œã®ä¸­é–“æ§‹é€ ã‚’ä¿å­˜ã—ã¾ã™: {xyz_save_path.name}\")\n",
    "        write(str(xyz_save_path), optimized_atoms)\n",
    "        return optimized_atoms  # â˜…å¤‰æ›´ç‚¹: æœ€é©åŒ–å¾Œã®æ§‹é€ ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’è¿”ã™\n",
    "    except Exception as e:\n",
    "        print(f\"  -> âŒ æœ€é©åŒ–ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}\")\n",
    "        return None  # â˜…å¤‰æ›´ç‚¹: å¤±æ•—ã—ãŸå ´åˆã¯Noneã‚’è¿”ã™\n",
    "\n",
    "# --- STEP 2: ç•Œé¢ã®æ§‹ç¯‰ãƒ»ãƒˆãƒªãƒŸãƒ³ã‚°ãƒ»æœ€é©åŒ–ã‚¯ãƒ©ã‚¹ ---\n",
    "class InterfaceOptimizer:\n",
    "    def __init__(self, surfaces_dir, interfaces_dir):\n",
    "        self.surfaces_dir = Path(surfaces_dir)\n",
    "        self.interfaces_dir = Path(interfaces_dir)\n",
    "        self.interfaces_dir.mkdir(parents=True, exist_ok=True)\n",
    "        print(f\"\\n--- STEP 2: ç•Œé¢ æ§‹ç¯‰ãƒ»ãƒˆãƒªãƒŸãƒ³ã‚°ãƒ»æœ€é©åŒ–ãƒ—ãƒ­ã‚»ã‚¹ã‚’é–‹å§‹ ---\")\n",
    "        print(f\"âœ… æœ€çµ‚æ§‹é€ ã®ä¿å­˜å…ˆ: '{self.interfaces_dir}'\")\n",
    "\n",
    "    def find_and_categorize_surfaces(self):\n",
    "        print(f\"ğŸ” '{self.surfaces_dir}' ã‹ã‚‰æœ€é©åŒ–æ¸ˆã¿è¡¨é¢ (*_final.xyz) ã‚’åˆ†é¡ä¸­...\")\n",
    "        if not self.surfaces_dir.is_dir():\n",
    "            print(f\"ğŸ›‘ ã‚¨ãƒ©ãƒ¼: è¡¨é¢ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª '{self.surfaces_dir}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚\")\n",
    "            return [], []\n",
    "        all_surfaces = list(self.surfaces_dir.glob(\"*_final.xyz\"))\n",
    "        al_surfaces = [p for p in all_surfaces if \"Al\" in p.stem]\n",
    "        cathode_surfaces = [p for p in all_surfaces if \"NMC\" in p.stem]\n",
    "        print(f\"  - Alè¡¨é¢: {len(al_surfaces)}å€‹,  æ­£æ¥µæè¡¨é¢: {len(cathode_surfaces)}å€‹\")\n",
    "        return al_surfaces, cathode_surfaces\n",
    "\n",
    "    def build_interface(self, slab1, slab2, target_xy=(12.0, 12.0), separation=2.0):\n",
    "        print(f\"    1. ç•Œé¢ã‚’æ§‹ç¯‰ä¸­...\")\n",
    "        # (ä»¥å‰ã®build_and_cut_interfaceã‹ã‚‰åŸå­å‰Šé™¤ã¨ã‚¹ã‚¿ãƒƒã‚¯éƒ¨åˆ†ã‚’æµç”¨)\n",
    "        position1 = slab1.get_positions()\n",
    "        position2 = slab2.get_positions()\n",
    "        indices_to_delete1 = np.where((position1[:, 0] >= target_xy[0]) | (position1[:, 1] >= target_xy[1]))[0]\n",
    "        indices_to_delete2 = np.where((position2[:, 0] >= target_xy[0]) | (position2[:, 1] >= target_xy[1]))[0]\n",
    "        cut_slab1, cut_slab2 = slab1.copy(), slab2.copy()\n",
    "        if len(indices_to_delete1) > 0: del cut_slab1[indices_to_delete1]\n",
    "        if len(indices_to_delete2) > 0: del cut_slab2[indices_to_delete2]\n",
    "        z1_max = cut_slab1.positions[:, 2].max()\n",
    "        z2_min = cut_slab2.positions[:, 2].min()\n",
    "        cut_slab2.positions[:, 2] += z1_max - z2_min + separation\n",
    "        interface = cut_slab1 + cut_slab2\n",
    "        interface.cell = [12, 12, 53]\n",
    "        return interface\n",
    "\n",
    "    def trim_interface(self, atoms, thickness_per_slab=25.0):\n",
    "        print(f\"    2. ç•Œé¢ã‚’ãƒˆãƒªãƒŸãƒ³ã‚°ä¸­ (å„ã‚¹ãƒ©ãƒ–åšã¿: {thickness_per_slab} Ã…)...\")\n",
    "        # ç•Œé¢ã®Zåº§æ¨™ã‚’æ¨å®š\n",
    "        al_indices = [a.index for a in atoms if a.symbol == 'Al']\n",
    "        nmc_indices = [a.index for a in atoms if a.symbol not in ['Al']]\n",
    "        if not al_indices or not nmc_indices: return None\n",
    "        al_pos = atoms.get_positions()[al_indices]\n",
    "        nmc_pos = atoms.get_positions()[nmc_indices]\n",
    "        if np.mean(al_pos[:, 2]) < np.mean(nmc_pos[:, 2]):\n",
    "            interface_z = (al_pos[:, 2].max() + nmc_pos[:, 2].min()) / 2\n",
    "        else:\n",
    "            interface_z = (nmc_pos[:, 2].max() + al_pos[:, 2].min()) / 2\n",
    "\n",
    "        # å‰Šé™¤ã™ã‚‹åŸå­ã‚’ç‰¹å®š\n",
    "        indices_to_delete = []\n",
    "        is_al_bottom = np.mean(al_pos[:, 2]) < np.mean(nmc_pos[:, 2])\n",
    "        for atom in atoms:\n",
    "            if is_al_bottom:\n",
    "                if atom.symbol == 'Al' and atom.z < interface_z - thickness_per_slab:\n",
    "                    indices_to_delete.append(atom.index)\n",
    "                elif atom.symbol != 'Al' and atom.z > interface_z + thickness_per_slab:\n",
    "                    indices_to_delete.append(atom.index)\n",
    "            else:\n",
    "                if atom.symbol != 'Al' and atom.z < interface_z - thickness_per_slab:\n",
    "                    indices_to_delete.append(atom.index)\n",
    "                elif atom.symbol == 'Al' and atom.z > interface_z + thickness_per_slab:\n",
    "                    indices_to_delete.append(atom.index)\n",
    "\n",
    "        print(f\"       -> {len(indices_to_delete)} å€‹ã®åŸå­ã‚’å‰Šé™¤ã—ã¾ã™ã€‚\")\n",
    "        if len(indices_to_delete) > 0:\n",
    "            del atoms[indices_to_delete]\n",
    "        return atoms\n",
    "\n",
    "    def create_trim_and_optimize(self, slab1_path, slab2_path):\n",
    "        slab1_name = slab1_path.stem.replace('_pos_opt_final', '').replace('_cell_opt_final', '')\n",
    "        slab2_name = slab2_path.stem.replace('_pos_opt_final', '').replace('_cell_opt_final', '')\n",
    "        interface_name = f\"Interface_{slab1_name}_on_{slab2_name}_trimmed\"\n",
    "        output_path = self.interfaces_dir / f\"{interface_name}.cif\"\n",
    "\n",
    "        if output_path.exists():\n",
    "            print(f\"âœ… æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚ã‚Šã€ã‚¹ã‚­ãƒƒãƒ—: {output_path.name}\")\n",
    "            return\n",
    "\n",
    "        print(f\"\\n--- å‡¦ç†é–‹å§‹: {slab1_name} + {slab2_name} ---\")\n",
    "        try:\n",
    "            # STEP 1: æ§‹ç¯‰\n",
    "            slab1, slab2 = read(slab1_path), read(slab2_path)\n",
    "            interface_built = self.build_interface(slab1, slab2)\n",
    "\n",
    "            # STEP 2: ãƒˆãƒªãƒŸãƒ³ã‚°\n",
    "            interface_trimmed = self.trim_interface(interface_built, thickness_per_slab=25.0)\n",
    "            if interface_trimmed is None:\n",
    "                print(\"   -> âŒ ãƒˆãƒªãƒŸãƒ³ã‚°ã«å¤±æ•—ã—ãŸãŸã‚ã€ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚\")\n",
    "                return\n",
    "\n",
    "            # STEP 3: æœ€é©åŒ–\n",
    "            print(f\"    3. ãƒˆãƒªãƒŸãƒ³ã‚°å¾Œã®æ§‹é€ ã‚’æœ€é©åŒ–ä¸­...\")\n",
    "            traj_path = self.interfaces_dir / f\"{interface_name}.traj\"\n",
    "            optimized_structure = run_matlantis_optimization(interface_trimmed, traj_path, fmax=0.05, name=interface_name)\n",
    "\n",
    "            # STEP 4: ä¿å­˜\n",
    "            if optimized_structure:\n",
    "                optimized_structure.center(vacuum=15.0, axis=2)\n",
    "                optimized_structure.pbc = (True, True, False)\n",
    "                print(f\"    4. æœ€çµ‚æ§‹é€ ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ä¸­ -> {output_path.name}\")\n",
    "                write(str(output_path), optimized_structure)\n",
    "            else:\n",
    "                print(\"   -> âŒ æœ€é©åŒ–ã«å¤±æ•—ã—ãŸãŸã‚ã€ãƒ•ã‚¡ã‚¤ãƒ«ã¯ä¿å­˜ã•ã‚Œã¾ã›ã‚“ã€‚\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  -> âŒ ã“ã®ç•Œé¢ã®ä½œæˆä¸­ã«é‡å¤§ãªã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}\")\n",
    "\n",
    "    def run(self):\n",
    "        al_slabs, cathode_slabs = self.find_and_categorize_surfaces()\n",
    "        if not al_slabs or not cathode_slabs:\n",
    "            print(\" -> Alè¡¨é¢ã¾ãŸã¯æ­£æ¥µæè¡¨é¢ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒä¸è¶³ã—ã¦ã„ã‚‹ãŸã‚ã€ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚\")\n",
    "            return\n",
    "\n",
    "        print(\"\\n--- Al/NMCç•Œé¢ã®çµ„ã¿åˆã‚ã›å‡¦ç†ã‚’é–‹å§‹ ---\")\n",
    "        for al_path in al_slabs:\n",
    "            for cathode_path in cathode_slabs:\n",
    "                self.create_trim_and_optimize(al_path, cathode_path)\n",
    "\n",
    "        print(\"\\nâœ¨ STEP 2 å…¨ã¦ã®å‡¦ç†ãŒå®Œäº†ã€‚\")\n",
    "\n",
    "\n",
    "def show_results_viewer(results_dir):\n",
    "    print(f\"\\n--- ğŸ”¬ çµæœãƒ“ãƒ¥ãƒ¼ãƒ¯ãƒ¼: '{results_dir}' ---\")\n",
    "    files = sorted(list(Path(results_dir).glob(\"*.cif\")))\n",
    "    if not files:\n",
    "        print(\"è¡¨ç¤ºã§ãã‚‹æ§‹é€ ãŒã‚ã‚Šã¾ã›ã‚“ã€‚\")\n",
    "        return\n",
    "    options = {\"-- é¸æŠã—ã¦ãã ã•ã„ --\": None}\n",
    "    options.update({p.name: p for p in files})\n",
    "    widgets.interact(\n",
    "        lambda file_path: display(nv.show_ase(read(file_path)) if file_path else None),\n",
    "        file_path=widgets.Dropdown(options=options, description='Interface:', layout={'width': 'max-content'})\n",
    "    )\n",
    "\n",
    "# --- ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œéƒ¨ ---\n",
    "if __name__ == \"__main__\":\n",
    "    # ===== è¨­å®šé …ç›® =====\n",
    "    # 1. Trajectoryãƒ•ã‚¡ã‚¤ãƒ«ãŒä¿å­˜ã•ã‚Œã¦ã„ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª\n",
    "    OPTIMIZATION_OUTPUT_DIR = \"/home/jovyan/Kaori/MD/LiB_2/structure/output\"\n",
    "\n",
    "    # 2. æœ€çµ‚çš„ãªç•Œé¢æ§‹é€ ã®ä¿å­˜å…ˆ\n",
    "    INTERFACES_DIR = \"/home/jovyan/Kaori/MD/LiB_2/structure/output/final_interfaces2\"\n",
    "    # ====================\n",
    "\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    # STEP 1: ãƒ¡ãƒ¢ãƒªç®¡ç† (traj -> xyzå¤‰æ› & å‰Šé™¤)\n",
    "    cleanup = TrajectoryCleanup(OPTIMIZATION_OUTPUT_DIR)\n",
    "    cleanup.run()\n",
    "\n",
    "    # STEP 2: ç•Œé¢ã®æ§‹ç¯‰ã€ãƒˆãƒªãƒŸãƒ³ã‚°ã€æœ€é©åŒ–ã‚’ä¸€æ‹¬å®Ÿè¡Œ\n",
    "    interface_opt = InterfaceOptimizer(surfaces_dir=OPTIMIZATION_OUTPUT_DIR, interfaces_dir=INTERFACES_DIR)\n",
    "    interface_opt.run()\n",
    "\n",
    "    print(\"\\n\\nâœ¨ å…¨ã¦ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãŒå®Œäº†ã—ã¾ã—ãŸã€‚ âœ¨\")\n",
    "\n",
    "    # çµæœã®è¡¨ç¤º\n",
    "    show_results_viewer(INTERFACES_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1178e8ef-c13b-4460-8241-bf7ca7df0e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STEP 1: Trajectoryãƒ•ã‚¡ã‚¤ãƒ«ã®æ•´ç†ã¯ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ ---\n",
      "\n",
      "--- STEP 2: ç•Œé¢ æ§‹ç¯‰ãƒ»ãƒˆãƒªãƒŸãƒ³ã‚°ãƒ»æœ€é©åŒ–ãƒ—ãƒ­ã‚»ã‚¹ã‚’é–‹å§‹ ---\n",
      "âœ… æœ€çµ‚æ§‹é€ ã®ä¿å­˜å…ˆ: '/home/jovyan/Kaori/MD/LiB_2/structure/output/final_interfaces'\n",
      "ğŸ” '/home/jovyan/Kaori/MD/LiB_2/structure/output' ã‹ã‚‰æ­£æ¥µæè¡¨é¢ (*_final.xyz) ã‚’åˆ†é¡ä¸­...\n",
      "... æŒ‡å®šã•ã‚ŒãŸAlå´ãƒ•ã‚¡ã‚¤ãƒ« (AlF3, Al2O3) ã®ã¿å¯¾è±¡ã¨ã—ã¾ã™...\n",
      "  -> âœ… å¯¾è±¡ã«è¿½åŠ : AlF3_only.xyz\n",
      "  -> âœ… å¯¾è±¡ã«è¿½åŠ : Al2O3_only.xyz\n",
      "  - Alè¡¨é¢ (æŒ‡å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿): 2å€‹,  æ­£æ¥µæè¡¨é¢: 86å€‹\n",
      "\n",
      "--- Al/NMCç•Œé¢ã®çµ„ã¿åˆã‚ã›å‡¦ç†ã‚’é–‹å§‹ ---\n",
      "\n",
      "--- å‡¦ç†é–‹å§‹: AlF3_only + NMC111_selective_Co_removal_110_(1, 1, 0) ---\n",
      "    1. ç•Œé¢ã‚’æ§‹ç¯‰ä¸­...\n",
      "    2. ç•Œé¢ã‚’ãƒˆãƒªãƒŸãƒ³ã‚°ä¸­ (å„ã‚¹ãƒ©ãƒ–åšã¿: 25.0 Ã…)...\n",
      "        -> 9 å€‹ã®åŸå­ã‚’å‰Šé™¤ã—ã¾ã™ã€‚\n",
      "    3. ãƒˆãƒªãƒŸãƒ³ã‚°å¾Œã®æ§‹é€ ã‚’æœ€é©åŒ–ä¸­...\n",
      "  -> Matlantisæœ€é©åŒ–é–‹å§‹ (Interface_AlF3_only_on_NMC111_selective_Co_removal_110_(1, 1, 0)_trimmed, fmax = 0.05) ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e69823ef91e14b9ab3beade274e7c67c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 242\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;66;03m# cleanup = TrajectoryCleanup(OPTIMIZATION_OUTPUT_DIR)\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;66;03m# cleanup.run()\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;66;03m# =================\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \n\u001b[1;32m    240\u001b[0m \u001b[38;5;66;03m# STEP 2: ç•Œé¢ã®æ§‹ç¯‰ã€ãƒˆãƒªãƒŸãƒ³ã‚°ã€æœ€é©åŒ–ã‚’ä¸€æ‹¬å®Ÿè¡Œ\u001b[39;00m\n\u001b[1;32m    241\u001b[0m interface_opt \u001b[38;5;241m=\u001b[39m InterfaceOptimizer(surfaces_dir\u001b[38;5;241m=\u001b[39mOPTIMIZATION_OUTPUT_DIR, interfaces_dir\u001b[38;5;241m=\u001b[39mINTERFACES_DIR)\n\u001b[0;32m--> 242\u001b[0m \u001b[43minterface_opt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mâœ¨ å…¨ã¦ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãŒå®Œäº†ã—ã¾ã—ãŸã€‚ âœ¨\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    246\u001b[0m \u001b[38;5;66;03m# çµæœã®è¡¨ç¤º\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[1], line 197\u001b[0m, in \u001b[0;36mInterfaceOptimizer.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m al_path \u001b[38;5;129;01min\u001b[39;00m al_slabs:\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m cathode_path \u001b[38;5;129;01min\u001b[39;00m cathode_slabs:\n\u001b[0;32m--> 197\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_trim_and_optimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mal_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcathode_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mâœ¨ STEP 2 å…¨ã¦ã®å‡¦ç†ãŒå®Œäº†ã€‚\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 176\u001b[0m, in \u001b[0;36mInterfaceOptimizer.create_trim_and_optimize\u001b[0;34m(self, slab1_path, slab2_path)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    3. ãƒˆãƒªãƒŸãƒ³ã‚°å¾Œã®æ§‹é€ ã‚’æœ€é©åŒ–ä¸­...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    175\u001b[0m traj_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterfaces_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minterface_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.traj\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 176\u001b[0m optimized_structure \u001b[38;5;241m=\u001b[39m \u001b[43mrun_matlantis_optimization\u001b[49m\u001b[43m(\u001b[49m\u001b[43minterface_trimmed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraj_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.05\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterface_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m optimized_structure:\n\u001b[1;32m    179\u001b[0m     optimized_structure\u001b[38;5;241m.\u001b[39mcenter(vacuum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15.0\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 47\u001b[0m, in \u001b[0;36mrun_matlantis_optimization\u001b[0;34m(atoms, trajectory_path, fmax, name)\u001b[0m\n\u001b[1;32m     42\u001b[0m position_optimizer \u001b[38;5;241m=\u001b[39m FireLBFGSASEOptFeature(\n\u001b[1;32m     43\u001b[0m     estimator_fn\u001b[38;5;241m=\u001b[39mestimator_function, \u001b[38;5;28mfilter\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, trajectory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(trajectory_path),\n\u001b[1;32m     44\u001b[0m     n_run\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5000\u001b[39m, fmax\u001b[38;5;241m=\u001b[39mfmax, show_progress_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     45\u001b[0m )\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 47\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mposition_optimizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatlantis_atoms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m     optimized_atoms \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39matoms\u001b[38;5;241m.\u001b[39mase_atoms\n\u001b[1;32m     49\u001b[0m     final_energy \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39moutput\u001b[38;5;241m.\u001b[39menergy_log[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/.py311/lib/python3.11/site-packages/matlantis_features/features/base.py:131\u001b[0m, in \u001b[0;36mFeatureBaseCaller.call_decorate.<locals>.decorated\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m args_list \u001b[38;5;241m=\u001b[39m [copy_to_child_conversion(arg) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args]\n\u001b[1;32m    130\u001b[0m kwargs_new \u001b[38;5;241m=\u001b[39m {k: copy_to_child_conversion(v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m--> 131\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mderived_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs_new\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/.py311/lib/python3.11/site-packages/matlantis_features/features/common/opt.py:284\u001b[0m, in \u001b[0;36mASEOptFeature.__call__\u001b[0;34m(self, atoms)\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m extn, interval \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattach_methods:\n\u001b[1;32m    283\u001b[0m         opt\u001b[38;5;241m.\u001b[39mattach(extn, interval\u001b[38;5;241m=\u001b[39minterval)\n\u001b[0;32m--> 284\u001b[0m \u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_run\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfmax\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m converged \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbool\u001b[39m(opt\u001b[38;5;241m.\u001b[39mconverged())\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pbar \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.py311/lib/python3.11/site-packages/ase/optimize/optimize.py:417\u001b[0m, in \u001b[0;36mOptimizer.run\u001b[0;34m(self, fmax, steps)\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run optimizer.\u001b[39;00m\n\u001b[1;32m    403\u001b[0m \n\u001b[1;32m    404\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;124;03m    True if the forces on atoms are converged.\u001b[39;00m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmax \u001b[38;5;241m=\u001b[39m fmax\n\u001b[0;32m--> 417\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDynamics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.py311/lib/python3.11/site-packages/ase/optimize/optimize.py:286\u001b[0m, in \u001b[0;36mDynamics.run\u001b[0;34m(self, steps)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, steps\u001b[38;5;241m=\u001b[39mDEFAULT_MAX_STEPS):\n\u001b[1;32m    269\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Run dynamics algorithm.\u001b[39;00m\n\u001b[1;32m    270\u001b[0m \n\u001b[1;32m    271\u001b[0m \u001b[38;5;124;03m    This method will return when the forces on all individual\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;124;03m        True if the forces on atoms are converged.\u001b[39;00m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 286\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconverged\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mDynamics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mirun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mpass\u001b[39;49;00m\n\u001b[1;32m    288\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m converged\n",
      "File \u001b[0;32m~/.py311/lib/python3.11/site-packages/ase/optimize/optimize.py:257\u001b[0m, in \u001b[0;36mDynamics.irun\u001b[0;34m(self, steps)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;66;03m# run the algorithm until converged or max_steps reached\u001b[39;00m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_converged \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnsteps \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_steps:\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;66;03m# compute the next step\u001b[39;00m\n\u001b[0;32m--> 257\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    258\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnsteps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# log the step\u001b[39;00m\n",
      "File \u001b[0;32m~/.py311/lib/python3.11/site-packages/matlantis_features/ase_ext/optimize/fire_lbfgs.py:132\u001b[0m, in \u001b[0;36mFIRELBFGS.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    131\u001b[0m atoms: Atoms \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39matoms\n\u001b[0;32m--> 132\u001b[0m energy \u001b[38;5;241m=\u001b[39m \u001b[43matoms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_potential_energy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m fmax \u001b[38;5;241m=\u001b[39m _get_fmax(atoms)\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt, FIRE):\n",
      "File \u001b[0;32m~/.py311/lib/python3.11/site-packages/ase/atoms.py:772\u001b[0m, in \u001b[0;36mAtoms.get_potential_energy\u001b[0;34m(self, force_consistent, apply_constraint)\u001b[0m\n\u001b[1;32m    769\u001b[0m     energy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_calc\u001b[38;5;241m.\u001b[39mget_potential_energy(\n\u001b[1;32m    770\u001b[0m         \u001b[38;5;28mself\u001b[39m, force_consistent\u001b[38;5;241m=\u001b[39mforce_consistent)\n\u001b[1;32m    771\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 772\u001b[0m     energy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_calc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_potential_energy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    773\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m apply_constraint:\n\u001b[1;32m    774\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m constraint \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconstraints:\n",
      "File \u001b[0;32m~/.py311/lib/python3.11/site-packages/ase/calculators/abc.py:26\u001b[0m, in \u001b[0;36mGetPropertiesMixin.get_potential_energy\u001b[0;34m(self, atoms, force_consistent)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124menergy\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_property\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matoms\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.py311/lib/python3.11/site-packages/ase/calculators/calculator.py:515\u001b[0m, in \u001b[0;36mBaseCalculator.get_property\u001b[0;34m(self, name, atoms, allow_calculation)\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_cache:\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39matoms \u001b[38;5;241m=\u001b[39m atoms\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m--> 515\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculate\u001b[49m\u001b[43m(\u001b[49m\u001b[43matoms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem_changes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults:\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;66;03m# For some reason the calculator was not able to do what we want,\u001b[39;00m\n\u001b[1;32m    519\u001b[0m     \u001b[38;5;66;03m# and that is OK.\u001b[39;00m\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PropertyNotImplementedError(\n\u001b[1;32m    521\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m not present in this \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcalculation\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name)\n\u001b[1;32m    522\u001b[0m     )\n",
      "File \u001b[0;32m~/.py311/lib/python3.11/site-packages/pfp_api_client/pfp/calculators/ase_calculator.py:131\u001b[0m, in \u001b[0;36mASECalculator.calculate\u001b[0;34m(self, atoms, properties, system_changes)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;66;03m# check that we were not interrupted by SIGINT\u001b[39;00m\n\u001b[1;32m    130\u001b[0m     InterruptWatcher\u001b[38;5;241m.\u001b[39massert_not_interrupted()\n\u001b[0;32m--> 131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_calculate\u001b[49m\u001b[43m(\u001b[49m\u001b[43matoms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproperties\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem_changes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconcurrency_checker\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.py311/lib/python3.11/site-packages/pfp_api_client/pfp/calculators/ase_calculator.py:183\u001b[0m, in \u001b[0;36mASECalculator._calculate\u001b[0;34m(self, atoms, properties, system_changes)\u001b[0m\n\u001b[1;32m    180\u001b[0m coordinates \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39matoms\u001b[38;5;241m.\u001b[39mget_positions()\n\u001b[1;32m    181\u001b[0m properties_estimator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreverse_convert_properties(_properties)\n\u001b[0;32m--> 183\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mEstimatorSystem\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproperties\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproperties_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoordinates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoordinates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcell\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcell_array\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m        \u001b[49m\u001b[43matomic_numbers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43matomic_numbers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpbc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpbc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;66;03m# NOTE (himkt): to make compatible with ``SinglePointCalculator``.\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/.py311/lib/python3.11/site-packages/pfp_api_client/pfp/estimator.py:900\u001b[0m, in \u001b[0;36mEstimator.estimate\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    891\u001b[0m     application_context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    892\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapplication_context\n\u001b[1;32m    893\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapplication_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    897\u001b[0m         )\n\u001b[1;32m    898\u001b[0m     )\n\u001b[1;32m    899\u001b[0m     metadata\u001b[38;5;241m.\u001b[39mappend((METADATA_APPLICATION_CONTEXT, application_context\u001b[38;5;241m.\u001b[39mlower()))\n\u001b[0;32m--> 900\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstub\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEstimate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    903\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_calc_mode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a valid calculation mode. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    904\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValid calculation modes are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(mode\u001b[38;5;241m.\u001b[39mname\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mmode\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mEstimatorCalcMode)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    905\u001b[0m     )\n",
      "File \u001b[0;32m~/.py311/lib/python3.11/site-packages/grpc/_interceptor.py:277\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    270\u001b[0m     request: Any,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    275\u001b[0m     compression: Optional[grpc\u001b[38;5;241m.\u001b[39mCompression] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    276\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 277\u001b[0m     response, ignored_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/.py311/lib/python3.11/site-packages/grpc/_interceptor.py:329\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._with_call\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _FailureOutcome(exception, sys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m--> 329\u001b[0m call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interceptor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintercept_unary_unary\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontinuation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclient_call_details\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m call\u001b[38;5;241m.\u001b[39mresult(), call\n",
      "File \u001b[0;32m~/.py311/lib/python3.11/site-packages/pfp_api_client/utils/error_handler_client_interceptor.py:24\u001b[0m, in \u001b[0;36mErrorHandlerClientInterceptor.intercept_unary_unary\u001b[0;34m(self, continuation, client_call_details, request)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mintercept_unary_unary\u001b[39m(\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     19\u001b[0m     continuation: Callable[[grpc\u001b[38;5;241m.\u001b[39mClientCallDetails, Message], Any],\n\u001b[1;32m     20\u001b[0m     client_call_details: grpc\u001b[38;5;241m.\u001b[39mClientCallDetails,\n\u001b[1;32m     21\u001b[0m     request: Message,\n\u001b[1;32m     22\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[grpc\u001b[38;5;241m.\u001b[39mCall, grpc\u001b[38;5;241m.\u001b[39mFuture]:\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_response(\n\u001b[0;32m---> 24\u001b[0m         client_call_details, \u001b[43mcontinuation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient_call_details\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m     )\n",
      "File \u001b[0;32m~/.py311/lib/python3.11/site-packages/grpc/_interceptor.py:315\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._with_call.<locals>.continuation\u001b[0;34m(new_details, request)\u001b[0m\n\u001b[1;32m    306\u001b[0m (\n\u001b[1;32m    307\u001b[0m     new_method,\n\u001b[1;32m    308\u001b[0m     new_timeout,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    312\u001b[0m     new_compression,\n\u001b[1;32m    313\u001b[0m ) \u001b[38;5;241m=\u001b[39m _unwrap_client_call_details(new_details, client_call_details)\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 315\u001b[0m     response, call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_thunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_method\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_credentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_wait_for_ready\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_compression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _UnaryOutcome(response, call)\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m rpc_error:\n",
      "File \u001b[0;32m~/.py311/lib/python3.11/site-packages/grpc/_interceptor.py:343\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.with_call\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwith_call\u001b[39m(\n\u001b[1;32m    335\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    336\u001b[0m     request: Any,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    341\u001b[0m     compression: Optional[grpc\u001b[38;5;241m.\u001b[39mCompression] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    342\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Any, grpc\u001b[38;5;241m.\u001b[39mCall]:\n\u001b[0;32m--> 343\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.py311/lib/python3.11/site-packages/grpc/_interceptor.py:329\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._with_call\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _FailureOutcome(exception, sys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m--> 329\u001b[0m call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interceptor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintercept_unary_unary\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontinuation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclient_call_details\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m call\u001b[38;5;241m.\u001b[39mresult(), call\n",
      "File \u001b[0;32m~/.py311/lib/python3.11/site-packages/pfp_api_client/utils/retry_client_interceptor.py:53\u001b[0m, in \u001b[0;36mRetryClientInterceptor.intercept_unary_unary\u001b[0;34m(self, continuation, client_call_details, request)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mf\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[grpc\u001b[38;5;241m.\u001b[39mCall, grpc\u001b[38;5;241m.\u001b[39mFuture]:\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m continuation(client_call_details, request)\n\u001b[0;32m---> 53\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient_call_details\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.py311/lib/python3.11/site-packages/pfp_api_client/utils/retry_client_interceptor.py:64\u001b[0m, in \u001b[0;36mRetryClientInterceptor._retry\u001b[0;34m(self, client_call_details, f)\u001b[0m\n\u001b[1;32m     62\u001b[0m errors: Dict[StatusCode, \u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m     code \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mcode()\n\u001b[1;32m     66\u001b[0m     rate_limit_exceeded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.py311/lib/python3.11/site-packages/pfp_api_client/utils/retry_client_interceptor.py:51\u001b[0m, in \u001b[0;36mRetryClientInterceptor.intercept_unary_unary.<locals>.f\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mf\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[grpc\u001b[38;5;241m.\u001b[39mCall, grpc\u001b[38;5;241m.\u001b[39mFuture]:\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontinuation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient_call_details\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.py311/lib/python3.11/site-packages/grpc/_interceptor.py:315\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._with_call.<locals>.continuation\u001b[0;34m(new_details, request)\u001b[0m\n\u001b[1;32m    306\u001b[0m (\n\u001b[1;32m    307\u001b[0m     new_method,\n\u001b[1;32m    308\u001b[0m     new_timeout,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    312\u001b[0m     new_compression,\n\u001b[1;32m    313\u001b[0m ) \u001b[38;5;241m=\u001b[39m _unwrap_client_call_details(new_details, client_call_details)\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 315\u001b[0m     response, call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_thunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_method\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_credentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_wait_for_ready\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_compression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _UnaryOutcome(response, call)\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m rpc_error:\n",
      "File \u001b[0;32m~/.py311/lib/python3.11/site-packages/grpc/_channel.py:1195\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.with_call\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1183\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwith_call\u001b[39m(\n\u001b[1;32m   1184\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1185\u001b[0m     request: Any,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1190\u001b[0m     compression: Optional[grpc\u001b[38;5;241m.\u001b[39mCompression] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1191\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Any, grpc\u001b[38;5;241m.\u001b[39mCall]:\n\u001b[1;32m   1192\u001b[0m     (\n\u001b[1;32m   1193\u001b[0m         state,\n\u001b[1;32m   1194\u001b[0m         call,\n\u001b[0;32m-> 1195\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_blocking\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompression\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1198\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _end_unary_response_blocking(state, call, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/.py311/lib/python3.11/site-packages/grpc/_channel.py:1162\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._blocking\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1145\u001b[0m state\u001b[38;5;241m.\u001b[39mtarget \u001b[38;5;241m=\u001b[39m _common\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_target)\n\u001b[1;32m   1146\u001b[0m call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_channel\u001b[38;5;241m.\u001b[39msegregated_call(\n\u001b[1;32m   1147\u001b[0m     cygrpc\u001b[38;5;241m.\u001b[39mPropagationConstants\u001b[38;5;241m.\u001b[39mGRPC_PROPAGATE_DEFAULTS,\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1160\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_registered_call_handle,\n\u001b[1;32m   1161\u001b[0m )\n\u001b[0;32m-> 1162\u001b[0m event \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1163\u001b[0m _handle_event(event, state, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_deserializer)\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m state, call\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:388\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc.SegregatedCall.next_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:211\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:205\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:78\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._latent_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:62\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._internal_latent_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:58\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._interpret_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/tag.pyx.pxi:71\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._BatchOperationTag.event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/operation.pyx.pxi:138\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc.ReceiveInitialMetadataOperation.un_c\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/metadata.pyx.pxi:69\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._metadata\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/metadata.pyx.pxi:70\u001b[0m, in \u001b[0;36mgenexpr\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/metadata.pyx.pxi:64\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._metadatum\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m<string>:1\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(_cls, key, value)\u001b[0m\n",
      "File \u001b[0;32m~/.py311/lib/python3.11/site-packages/pfp_api_client/pfp/utils/interrupt_watcher.py:18\u001b[0m, in \u001b[0;36mInterruptWatcher.set_interrupt_flag\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m     15\u001b[0m InterruptWatcher\u001b[38;5;241m.\u001b[39minterrupted_evt\u001b[38;5;241m.\u001b[39mset()\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# perform the default action, i.e., trigger a KeyboardInterrupt\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# exception in the main thread\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[43msignal\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault_int_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[43msignum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Trajectoryãƒ•ã‚¡ã‚¤ãƒ«ã®æ•´ç†ã¨ã€ãã‚Œã«åŸºã¥ãç•Œé¢æ§‹ç¯‰ãƒ»æœ€é©åŒ–ã‚’è‡ªå‹•åŒ–ã™ã‚‹ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã€‚\n",
    "\n",
    "[è¿½åŠ å®Ÿè¡Œç‰ˆ]\n",
    "- AlF3ã¨Al2O3ã®ã¿ã‚’Alå´è¡¨é¢ã¨ã—ã¦æ‰±ã„ã€è¿½åŠ ã§ç•Œé¢æ§‹ç¯‰ã¨æœ€é©åŒ–ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚\n",
    "- STEP1ã®Trajectoryãƒ•ã‚¡ã‚¤ãƒ«æ•´ç†ã¯ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚\n",
    "\"\"\"\n",
    "import os\n",
    "import itertools\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import nglview as nv\n",
    "\n",
    "# ASE\n",
    "from ase.io import read, write\n",
    "from ase.build import stack,cut\n",
    "\n",
    "# Matlantis / PFP\n",
    "from matlantis_features.atoms import MatlantisAtoms\n",
    "from matlantis_features.features.common.opt import FireLBFGSASEOptFeature\n",
    "from matlantis_features.utils.calculators import pfp_estimator_fn\n",
    "from pfp_api_client.pfp.estimator import EstimatorCalcMode\n",
    "\n",
    "# --- STEP 1: Trajectoryãƒ•ã‚¡ã‚¤ãƒ«ã®æ•´ç†ã‚¯ãƒ©ã‚¹ (ä»Šå›ã¯ä½¿ç”¨ã—ãªã„) ---\n",
    "class TrajectoryCleanup:\n",
    "    def __init__(self, directory):\n",
    "        print(\"--- STEP 1: Trajectoryãƒ•ã‚¡ã‚¤ãƒ«ã®åˆ†æã¨æ•´ç† (ã‚¹ã‚­ãƒƒãƒ—) ---\")\n",
    "    def run(self):\n",
    "        pass\n",
    "\n",
    "# --- Matlantisæœ€é©åŒ–é–¢æ•° (å…±é€š) ---\n",
    "\n",
    "def run_matlantis_optimization(atoms, trajectory_path, fmax=0.05, name=\"structure\"):\n",
    "    print(f\"  -> Matlantisæœ€é©åŒ–é–‹å§‹ ({name}, fmax = {fmax}) ...\")\n",
    "    matlantis_atoms = MatlantisAtoms(atoms)\n",
    "    estimator_function = pfp_estimator_fn(\n",
    "        model_version='v7.0.0', calc_mode=EstimatorCalcMode.CRYSTAL_PLUS_D3\n",
    "    )\n",
    "    position_optimizer = FireLBFGSASEOptFeature(\n",
    "        estimator_fn=estimator_function, filter=False, trajectory=str(trajectory_path),\n",
    "        n_run=5000, fmax=fmax, show_progress_bar=True\n",
    "    )\n",
    "    try:\n",
    "        result = position_optimizer(matlantis_atoms)\n",
    "        optimized_atoms = result.atoms.ase_atoms\n",
    "        final_energy = result.output.energy_log[-1]\n",
    "        print(f\"  -> âœ”ï¸ æœ€é©åŒ–å®Œäº†ï¼ ã‚¨ãƒãƒ«ã‚®ãƒ¼: {final_energy:.3f} eV\")\n",
    "        xyz_save_path = Path(trajectory_path).with_suffix('.xyz')\n",
    "        print(f\"  -> ğŸ’¾ æœ€é©åŒ–å¾Œã®ä¸­é–“æ§‹é€ ã‚’ä¿å­˜ã—ã¾ã™: {xyz_save_path.name}\")\n",
    "        write(str(xyz_save_path), optimized_atoms)\n",
    "        return optimized_atoms\n",
    "    except Exception as e:\n",
    "        print(f\"  -> âŒ æœ€é©åŒ–ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}\")\n",
    "        return None\n",
    "\n",
    "# --- STEP 2: ç•Œé¢ã®æ§‹ç¯‰ãƒ»ãƒˆãƒªãƒŸãƒ³ã‚°ãƒ»æœ€é©åŒ–ã‚¯ãƒ©ã‚¹ ---\n",
    "class InterfaceOptimizer:\n",
    "    def __init__(self, surfaces_dir, interfaces_dir):\n",
    "        self.surfaces_dir = Path(surfaces_dir)\n",
    "        self.interfaces_dir = Path(interfaces_dir)\n",
    "        self.interfaces_dir.mkdir(parents=True, exist_ok=True)\n",
    "        print(f\"\\n--- STEP 2: ç•Œé¢ æ§‹ç¯‰ãƒ»ãƒˆãƒªãƒŸãƒ³ã‚°ãƒ»æœ€é©åŒ–ãƒ—ãƒ­ã‚»ã‚¹ã‚’é–‹å§‹ ---\")\n",
    "        print(f\"âœ… æœ€çµ‚æ§‹é€ ã®ä¿å­˜å…ˆ: '{self.interfaces_dir}'\")\n",
    "\n",
    "    def find_and_categorize_surfaces(self):\n",
    "        \"\"\"\n",
    "        [å¤‰æ›´] æŒ‡å®šã•ã‚ŒãŸAlF3ã¨Al2O3ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ã‚’Alå´ã¨ã—ã¦å–å¾—ã—ã€\n",
    "               æ­£æ¥µå´ãƒ•ã‚¡ã‚¤ãƒ«ã¯å¾“æ¥é€šã‚Šæ¤œç´¢ã™ã‚‹ã€‚\n",
    "        \"\"\"\n",
    "        print(f\"ğŸ” '{self.surfaces_dir}' ã‹ã‚‰æ­£æ¥µæè¡¨é¢ (*_final.xyz) ã‚’åˆ†é¡ä¸­...\")\n",
    "        if not self.surfaces_dir.is_dir():\n",
    "            print(f\"ğŸ›‘ ã‚¨ãƒ©ãƒ¼: è¡¨é¢ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª '{self.surfaces_dir}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚\")\n",
    "            return [], []\n",
    "\n",
    "        # æ­£æ¥µæãƒ•ã‚¡ã‚¤ãƒ«ã¯å¾“æ¥é€šã‚Šæ¤œç´¢\n",
    "        all_surfaces = list(self.surfaces_dir.glob(\"*_final.xyz\"))\n",
    "        cathode_surfaces = [p for p in all_surfaces if \"NMC\" in p.stem]\n",
    "\n",
    "        # ===== ã“ã“ã‹ã‚‰ãŒå¤‰æ›´ç‚¹ =====\n",
    "        # Alå´ã¯æŒ‡å®šã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ã«é™å®š\n",
    "        print(\"... æŒ‡å®šã•ã‚ŒãŸAlå´ãƒ•ã‚¡ã‚¤ãƒ« (AlF3, Al2O3) ã®ã¿å¯¾è±¡ã¨ã—ã¾ã™...\")\n",
    "        al_surfaces = []\n",
    "        additional_al_files_paths = [\n",
    "            Path(\"/home/jovyan/Kaori/MD/LiB_2/AlF3_only.xyz\"),\n",
    "            Path(\"/home/jovyan/Kaori/MD/LiB_2/Al2O3_only.xyz\")\n",
    "        ]\n",
    "        \n",
    "        for file_path in additional_al_files_paths:\n",
    "            if file_path.exists():\n",
    "                al_surfaces.append(file_path)\n",
    "                print(f\"  -> âœ… å¯¾è±¡ã«è¿½åŠ : {file_path.name}\")\n",
    "            else:\n",
    "                print(f\"  -> âš ï¸  è­¦å‘Š: æŒ‡å®šã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_path}\")\n",
    "        # ===== å¤‰æ›´ç‚¹ã“ã“ã¾ã§ =====\n",
    "\n",
    "        print(f\"  - Alè¡¨é¢ (æŒ‡å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿): {len(al_surfaces)}å€‹,  æ­£æ¥µæè¡¨é¢: {len(cathode_surfaces)}å€‹\")\n",
    "        return al_surfaces, cathode_surfaces\n",
    "\n",
    "    def build_interface(self, slab1, slab2, target_xy=(12.0, 12.0), separation=2.0):\n",
    "        print(f\"    1. ç•Œé¢ã‚’æ§‹ç¯‰ä¸­...\")\n",
    "        position1 = slab1.get_positions()\n",
    "        position2 = slab2.get_positions()\n",
    "        indices_to_delete1 = np.where((position1[:, 0] >= target_xy[0]) | (position1[:, 1] >= target_xy[1]))[0]\n",
    "        indices_to_delete2 = np.where((position2[:, 0] >= target_xy[0]) | (position2[:, 1] >= target_xy[1]))[0]\n",
    "        cut_slab1, cut_slab2 = slab1.copy(), slab2.copy()\n",
    "        if len(indices_to_delete1) > 0: del cut_slab1[indices_to_delete1]\n",
    "        if len(indices_to_delete2) > 0: del cut_slab2[indices_to_delete2]\n",
    "        z1_max = cut_slab1.positions[:, 2].max()\n",
    "        z2_min = cut_slab2.positions[:, 2].min()\n",
    "        cut_slab2.positions[:, 2] += z1_max - z2_min + separation\n",
    "        interface = cut_slab1 + cut_slab2\n",
    "        interface.cell = [12, 12, 53]\n",
    "        return interface\n",
    "\n",
    "    def trim_interface(self, atoms, thickness_per_slab=25.0):\n",
    "        print(f\"    2. ç•Œé¢ã‚’ãƒˆãƒªãƒŸãƒ³ã‚°ä¸­ (å„ã‚¹ãƒ©ãƒ–åšã¿: {thickness_per_slab} Ã…)...\")\n",
    "        al_indices = [a.index for a in atoms if a.symbol in ['Al', 'F']] # Alã¨Fã‚’Alå´ã¨ã¿ãªã™\n",
    "        nmc_indices = [a.index for a in atoms if a.symbol not in ['Al', 'F']]\n",
    "        if not al_indices or not nmc_indices:\n",
    "            print(\"     -> è­¦å‘Š: Alå´ã¾ãŸã¯NMCå´ã®åŸå­ãŒè¦‹ã¤ã‹ã‚‰ãšã€ãƒˆãƒªãƒŸãƒ³ã‚°ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚\")\n",
    "            return atoms\n",
    "\n",
    "        al_pos = atoms.get_positions()[al_indices]\n",
    "        nmc_pos = atoms.get_positions()[nmc_indices]\n",
    "        \n",
    "        if np.mean(al_pos[:, 2]) < np.mean(nmc_pos[:, 2]):\n",
    "            interface_z = (al_pos[:, 2].max() + nmc_pos[:, 2].min()) / 2\n",
    "            is_al_bottom = True\n",
    "        else:\n",
    "            interface_z = (nmc_pos[:, 2].max() + al_pos[:, 2].min()) / 2\n",
    "            is_al_bottom = False\n",
    "\n",
    "        indices_to_delete = []\n",
    "        for atom in atoms:\n",
    "            is_al_side = atom.symbol in ['Al', 'F']\n",
    "            if is_al_bottom:\n",
    "                if is_al_side and atom.z < interface_z - thickness_per_slab:\n",
    "                    indices_to_delete.append(atom.index)\n",
    "                elif not is_al_side and atom.z > interface_z + thickness_per_slab:\n",
    "                    indices_to_delete.append(atom.index)\n",
    "            else:\n",
    "                if not is_al_side and atom.z < interface_z - thickness_per_slab:\n",
    "                    indices_to_delete.append(atom.index)\n",
    "                elif is_al_side and atom.z > interface_z + thickness_per_slab:\n",
    "                    indices_to_delete.append(atom.index)\n",
    "\n",
    "        print(f\"        -> {len(indices_to_delete)} å€‹ã®åŸå­ã‚’å‰Šé™¤ã—ã¾ã™ã€‚\")\n",
    "        if len(indices_to_delete) > 0:\n",
    "            del atoms[indices_to_delete]\n",
    "        return atoms\n",
    "\n",
    "    def create_trim_and_optimize(self, slab1_path, slab2_path):\n",
    "        slab1_name = slab1_path.stem.replace('_pos_opt_final', '').replace('_cell_opt_final', '')\n",
    "        slab2_name = slab2_path.stem.replace('_pos_opt_final', '').replace('_cell_opt_final', '')\n",
    "        interface_name = f\"Interface_{slab1_name}_on_{slab2_name}_trimmed\"\n",
    "        output_path = self.interfaces_dir / f\"{interface_name}.cif\"\n",
    "\n",
    "        if output_path.exists():\n",
    "            print(f\"âœ… æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚ã‚Šã€ã‚¹ã‚­ãƒƒãƒ—: {output_path.name}\")\n",
    "            return\n",
    "\n",
    "        print(f\"\\n--- å‡¦ç†é–‹å§‹: {slab1_name} + {slab2_name} ---\")\n",
    "        try:\n",
    "            slab1, slab2 = read(str(slab1_path)), read(str(slab2_path))\n",
    "            interface_built = self.build_interface(slab1, slab2)\n",
    "            interface_trimmed = self.trim_interface(interface_built, thickness_per_slab=25.0)\n",
    "            if interface_trimmed is None:\n",
    "                print(\"    -> âŒ ãƒˆãƒªãƒŸãƒ³ã‚°ã«å¤±æ•—ã—ãŸãŸã‚ã€ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚\")\n",
    "                return\n",
    "\n",
    "            print(f\"    3. ãƒˆãƒªãƒŸãƒ³ã‚°å¾Œã®æ§‹é€ ã‚’æœ€é©åŒ–ä¸­...\")\n",
    "            traj_path = self.interfaces_dir / f\"{interface_name}.traj\"\n",
    "            optimized_structure = run_matlantis_optimization(interface_trimmed, traj_path, fmax=0.05, name=interface_name)\n",
    "\n",
    "            if optimized_structure:\n",
    "                optimized_structure.center(vacuum=15.0, axis=2)\n",
    "                optimized_structure.pbc = (True, True, False)\n",
    "                print(f\"    4. æœ€çµ‚æ§‹é€ ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ä¸­ -> {output_path.name}\")\n",
    "                write(str(output_path), optimized_structure)\n",
    "            else:\n",
    "                print(\"    -> âŒ æœ€é©åŒ–ã«å¤±æ•—ã—ãŸãŸã‚ã€ãƒ•ã‚¡ã‚¤ãƒ«ã¯ä¿å­˜ã•ã‚Œã¾ã›ã‚“ã€‚\")\n",
    "        except Exception as e:\n",
    "            print(f\"  -> âŒ ã“ã®ç•Œé¢ã®ä½œæˆä¸­ã«é‡å¤§ãªã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}\")\n",
    "\n",
    "    def run(self):\n",
    "        al_slabs, cathode_slabs = self.find_and_categorize_surfaces()\n",
    "        if not al_slabs or not cathode_slabs:\n",
    "            print(\" -> Alè¡¨é¢ã¾ãŸã¯æ­£æ¥µæè¡¨é¢ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒä¸è¶³ã—ã¦ã„ã‚‹ãŸã‚ã€ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚\")\n",
    "            return\n",
    "\n",
    "        print(\"\\n--- Al/NMCç•Œé¢ã®çµ„ã¿åˆã‚ã›å‡¦ç†ã‚’é–‹å§‹ ---\")\n",
    "        for al_path in al_slabs:\n",
    "            for cathode_path in cathode_slabs:\n",
    "                self.create_trim_and_optimize(al_path, cathode_path)\n",
    "        print(\"\\nâœ¨ STEP 2 å…¨ã¦ã®å‡¦ç†ãŒå®Œäº†ã€‚\")\n",
    "\n",
    "def show_results_viewer(results_dir):\n",
    "    print(f\"\\n--- ğŸ”¬ çµæœãƒ“ãƒ¥ãƒ¼ãƒ¯ãƒ¼: '{results_dir}' ---\")\n",
    "    files = sorted(list(Path(results_dir).glob(\"*.cif\")))\n",
    "    if not files:\n",
    "        print(\"è¡¨ç¤ºã§ãã‚‹æ§‹é€ ãŒã‚ã‚Šã¾ã›ã‚“ã€‚\")\n",
    "        return\n",
    "    \n",
    "    options = {\"-- é¸æŠã—ã¦ãã ã•ã„ --\": None}\n",
    "    options.update({p.name: str(p) for p in files})\n",
    "\n",
    "    def view_structure(file_path):\n",
    "        if file_path:\n",
    "            try:\n",
    "                atoms = read(file_path)\n",
    "                view = nv.show_ase(atoms)\n",
    "                display(view)\n",
    "            except Exception as e:\n",
    "                print(f\"ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã¾ãŸã¯è¡¨ç¤ºä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}\")\n",
    "\n",
    "    widgets.interact(\n",
    "        view_structure,\n",
    "        file_path=widgets.Dropdown(options=options, description='Interface:', layout={'width': 'max-content'})\n",
    "    )\n",
    "\n",
    "# --- ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œéƒ¨ ---\n",
    "if __name__ == \"__main__\":\n",
    "    # ===== è¨­å®šé …ç›® =====\n",
    "    OPTIMIZATION_OUTPUT_DIR = \"/home/jovyan/Kaori/MD/LiB_2/structure/output\"\n",
    "    INTERFACES_DIR = \"/home/jovyan/Kaori/MD/LiB_2/structure/output/final_interfaces\"\n",
    "    # ====================\n",
    "\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    # ===== å¤‰æ›´ç‚¹ =====\n",
    "    # STEP 1: ä»Šå›ã¯ä¸è¦ãªãŸã‚å®Ÿè¡Œã—ãªã„\n",
    "    print(\"--- STEP 1: Trajectoryãƒ•ã‚¡ã‚¤ãƒ«ã®æ•´ç†ã¯ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ ---\")\n",
    "    # cleanup = TrajectoryCleanup(OPTIMIZATION_OUTPUT_DIR)\n",
    "    # cleanup.run()\n",
    "    # =================\n",
    "\n",
    "    # STEP 2: ç•Œé¢ã®æ§‹ç¯‰ã€ãƒˆãƒªãƒŸãƒ³ã‚°ã€æœ€é©åŒ–ã‚’ä¸€æ‹¬å®Ÿè¡Œ\n",
    "    interface_opt = InterfaceOptimizer(surfaces_dir=OPTIMIZATION_OUTPUT_DIR, interfaces_dir=INTERFACES_DIR)\n",
    "    interface_opt.run()\n",
    "\n",
    "    print(\"\\n\\nâœ¨ å…¨ã¦ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãŒå®Œäº†ã—ã¾ã—ãŸã€‚ âœ¨\")\n",
    "\n",
    "    # çµæœã®è¡¨ç¤º\n",
    "    show_results_viewer(INTERFACES_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34227a50-dbff-4fba-85ee-95c9798068c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Interface Construction, Trimming, and Optimization ---\n",
      "Aluminum Slab: 'Al555.xyz'\n",
      "NMC Slabs from: '/home/jovyan/Kaori/MD/LiB_2/structure/output/cif_files/cif_files'\n",
      "Output Directory: '/home/jovyan/Kaori/MD/LiB_2/structure/output/final_interfaces_Al_NMC'\n",
      "\n",
      "ğŸ” Searching for input structure files...\n",
      "  - Found 1 Al slab: Al555.xyz\n",
      "  - Found 17 NMC slabs.\n",
      "\n",
      "--- Processing combination: Al555 + NMC_Co_decrease_001_surface ---\n",
      "    1. Building interface structure...\n",
      "      -> Stacking slab 4 times to reach ~30.0 Ã…...\n",
      "      -> Created slab with final thickness: 34.40 Ã….\n",
      "    2. Trimming interface (target per slab: 30.0 Ã…)...\n",
      "        -> Deleting 75 atoms outside the target thickness.\n",
      "    3. Optimizing atomic positions...\n",
      "  -> Starting Matlantis optimization for Interface_Al555_on_NMC_Co_decrease_001_surface (fmax = 0.05)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1903b1e122c473182ebd6ae76bca422",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> âŒ An error occurred during optimization: Invalid input value is detected: coordinates (positions) contains infinite values.\n",
      "=== When reporting an error, please also share the data below: ===\n",
      "----------------------------------------------------------------------------\n",
      "time: 2025-10-14T08:27:37.020177+00:00\n",
      "pid: 27\n",
      "code: INVALID_ARGUMENT\n",
      "method: /pfp.Estimator/Estimate\n",
      "details: Invalid=20input=20value=20is=20detected:=20coordinates=20(position=\n",
      "s)=20contains=20infinite=20values.\n",
      "exc: <_InactiveRpcError=20of=20RPC=20that=20terminated=20with:\n",
      "=09status=20=3D=20StatusCode.INVALID_ARGUMENT\n",
      "=09details=20=3D=20\"Invalid=20input=20value=20is=20detected:=20coordinates=\n",
      "=20(positions)=20contains=20infinite=20values.\"\n",
      "=09debug_error_string=20=3D=20\"UNKNOWN:Error=20received=20from=20peer=20=20=\n",
      "{grpc_status:3,=20grpc_message:\"Invalid=20input=20value=20is=20detected:=20=\n",
      "coordinates=20(positions)=20contains=20infinite=20values.\"}\"\n",
      ">\n",
      "notebook_id: ez65y7njhez5t7bp\n",
      "metadata: [('client-process-id',=20'27'),=20('n_atoms',=20'1961'),=20('mode=\n",
      "l_version',=20'v7.0.0'),=20('calc_mode',=20'4'),=20('method_type',=20'pfvm_=\n",
      "d3_pfvm'),=20('client-side-priority',=20'100'),=20('client_version',=20'1.2=\n",
      "4.0'),=20('x-request-id',=20'ez65y7njhez5t7bp-1760430457003-27-140412184799=\n",
      "040'),=20('execution-context',=20'notebook'),=20('application-context',=20'=\n",
      "pfp-no-context')]\n",
      "remote: pfp-api.pfp-system.svc.cluster.local:5000\n",
      "----------------------------------------------------------------------------\n",
      "    -> âŒ Optimization failed, structure not saved.\n",
      "\n",
      "--- Processing combination: Al555 + NMC_Co_decrease_010_surface ---\n",
      "    1. Building interface structure...\n",
      "      -> Stacking slab 4 times to reach ~30.0 Ã…...\n",
      "      -> Created slab with final thickness: 34.40 Ã….\n",
      "    2. Trimming interface (target per slab: 30.0 Ã…)...\n",
      "        -> Deleting 267 atoms outside the target thickness.\n",
      "    3. Optimizing atomic positions...\n",
      "  -> Starting Matlantis optimization for Interface_Al555_on_NMC_Co_decrease_010_surface (fmax = 0.05)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c2c295dba794651a4bd726c9cc09a8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> âŒ An error occurred during optimization: Invalid input value is detected: coordinates (positions) contains infinite values.\n",
      "=== When reporting an error, please also share the data below: ===\n",
      "----------------------------------------------------------------------------\n",
      "time: 2025-10-14T08:27:56.642476+00:00\n",
      "pid: 27\n",
      "code: INVALID_ARGUMENT\n",
      "method: /pfp.Estimator/Estimate\n",
      "details: Invalid=20input=20value=20is=20detected:=20coordinates=20(position=\n",
      "s)=20contains=20infinite=20values.\n",
      "exc: <_InactiveRpcError=20of=20RPC=20that=20terminated=20with:\n",
      "=09status=20=3D=20StatusCode.INVALID_ARGUMENT\n",
      "=09details=20=3D=20\"Invalid=20input=20value=20is=20detected:=20coordinates=\n",
      "=20(positions)=20contains=20infinite=20values.\"\n",
      "=09debug_error_string=20=3D=20\"UNKNOWN:Error=20received=20from=20peer=20=20=\n",
      "{grpc_message:\"Invalid=20input=20value=20is=20detected:=20coordinates=20(po=\n",
      "sitions)=20contains=20infinite=20values.\",=20grpc_status:3}\"\n",
      ">\n",
      "notebook_id: ez65y7njhez5t7bp\n",
      "metadata: [('client-process-id',=20'27'),=20('n_atoms',=20'1769'),=20('mode=\n",
      "l_version',=20'v7.0.0'),=20('calc_mode',=20'4'),=20('method_type',=20'pfvm_=\n",
      "d3_pfvm'),=20('client-side-priority',=20'100'),=20('client_version',=20'1.2=\n",
      "4.0'),=20('x-request-id',=20'ez65y7njhez5t7bp-1760430476633-27-140412184799=\n",
      "040'),=20('execution-context',=20'notebook'),=20('application-context',=20'=\n",
      "pfp-no-context')]\n",
      "remote: pfp-api.pfp-system.svc.cluster.local:5000\n",
      "----------------------------------------------------------------------------\n",
      "    -> âŒ Optimization failed, structure not saved.\n",
      "\n",
      "--- Processing combination: Al555 + NMC_Co_decrease_012_surface ---\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 269\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# Initialize and run the interface optimization workflow\u001b[39;00m\n\u001b[1;32m    264\u001b[0m interface_optimizer \u001b[38;5;241m=\u001b[39m InterfaceOptimizer(\n\u001b[1;32m    265\u001b[0m     al_cif_path\u001b[38;5;241m=\u001b[39mAL_CIF_PATH,\n\u001b[1;32m    266\u001b[0m     nmc_cif_dir\u001b[38;5;241m=\u001b[39mNMC_CIF_DIR,\n\u001b[1;32m    267\u001b[0m     interfaces_dir\u001b[38;5;241m=\u001b[39mINTERFACES_DIR\n\u001b[1;32m    268\u001b[0m )\n\u001b[0;32m--> 269\u001b[0m \u001b[43minterface_optimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;66;03m# Display the results\u001b[39;00m\n\u001b[1;32m    272\u001b[0m show_results_viewer(INTERFACES_DIR)\n",
      "Cell \u001b[0;32mIn[1], line 218\u001b[0m, in \u001b[0;36mInterfaceOptimizer.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m al_path \u001b[38;5;129;01min\u001b[39;00m al_slabs:\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m nmc_path \u001b[38;5;129;01min\u001b[39;00m cathode_slabs:\n\u001b[0;32m--> 218\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_interface\u001b[49m\u001b[43m(\u001b[49m\u001b[43mal_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnmc_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mâœ¨ All interface processing is complete. âœ¨\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 177\u001b[0m, in \u001b[0;36mInterfaceOptimizer.process_interface\u001b[0;34m(self, al_path, nmc_path)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     al_slab \u001b[38;5;241m=\u001b[39m read(al_path)\n\u001b[0;32m--> 177\u001b[0m     nmc_slab \u001b[38;5;241m=\u001b[39m \u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnmc_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;66;03m# Step 1: Build and Trim\u001b[39;00m\n\u001b[1;32m    180\u001b[0m     interface_built \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_interface(al_slab, nmc_slab)\n",
      "File \u001b[0;32m~/.py311/lib/python3.11/site-packages/ase/io/formats.py:794\u001b[0m, in \u001b[0;36mread\u001b[0;34m(filename, index, format, parallel, do_not_split_by_at_sign, **kwargs)\u001b[0m\n\u001b[1;32m    791\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(_iread(filename, index, \u001b[38;5;28mformat\u001b[39m, io, parallel\u001b[38;5;241m=\u001b[39mparallel,\n\u001b[1;32m    792\u001b[0m                        \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n\u001b[1;32m    793\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 794\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_iread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mslice\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mparallel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparallel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.py311/lib/python3.11/site-packages/ase/parallel.py:292\u001b[0m, in \u001b[0;36mparallel_generator.<locals>.new_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(generator)\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mnew_generator\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    288\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (world\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m    289\u001b[0m         args \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mserial\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m    290\u001b[0m             \u001b[38;5;129;01mnot\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparallel\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)):\n\u001b[1;32m    291\u001b[0m         \u001b[38;5;66;03m# Disable:\u001b[39;00m\n\u001b[0;32m--> 292\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\n\u001b[1;32m    294\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/.py311/lib/python3.11/site-packages/ase/io/formats.py:860\u001b[0m, in \u001b[0;36m_iread\u001b[0;34m(filename, index, format, io, parallel, full_output, **kwargs)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;66;03m# Make sure fd is closed in case loop doesn't finish:\u001b[39;00m\n\u001b[1;32m    859\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 860\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdct\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdct\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdct\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43matoms\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdct\u001b[49m\u001b[43m}\u001b[49m\n",
      "File \u001b[0;32m~/.py311/lib/python3.11/site-packages/ase/io/formats.py:618\u001b[0m, in \u001b[0;36mwrap_read_function\u001b[0;34m(read, filename, index, **kwargs)\u001b[0m\n\u001b[1;32m    616\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m read(filename, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    617\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 618\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.py311/lib/python3.11/site-packages/ase/io/cif.py:661\u001b[0m, in \u001b[0;36mread_cif\u001b[0;34m(fileobj, index, store_tags, primitive_cell, subtrans_included, fractional_occupancies, reader)\u001b[0m\n\u001b[1;32m    650\u001b[0m g \u001b[38;5;241m=\u001b[39m iread_cif(\n\u001b[1;32m    651\u001b[0m     fileobj,\n\u001b[1;32m    652\u001b[0m     index,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    657\u001b[0m     reader,\n\u001b[1;32m    658\u001b[0m )\n\u001b[1;32m    659\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(index, (\u001b[38;5;28mslice\u001b[39m, \u001b[38;5;28mstr\u001b[39m)):\n\u001b[1;32m    660\u001b[0m     \u001b[38;5;66;03m# Return list of atoms\u001b[39;00m\n\u001b[0;32m--> 661\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    663\u001b[0m     \u001b[38;5;66;03m# Return single atoms object\u001b[39;00m\n\u001b[1;32m    664\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(g)\n",
      "File \u001b[0;32m~/.py311/lib/python3.11/site-packages/ase/io/cif.py:590\u001b[0m, in \u001b[0;36miread_cif\u001b[0;34m(fileobj, index, store_tags, primitive_cell, subtrans_included, fractional_occupancies, reader)\u001b[0m\n\u001b[1;32m    587\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m block\u001b[38;5;241m.\u001b[39mhas_structure():\n\u001b[1;32m    588\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 590\u001b[0m     atoms \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_atoms\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstore_tags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprimitive_cell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    592\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubtrans_included\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfractional_occupancies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfractional_occupancies\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    594\u001b[0m     images\u001b[38;5;241m.\u001b[39mappend(atoms)\n\u001b[1;32m    596\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m index \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m~/.py311/lib/python3.11/site-packages/ase/io/cif.py:486\u001b[0m, in \u001b[0;36mCIFBlock.get_atoms\u001b[0;34m(self, store_tags, primitive_cell, subtrans_included, fractional_occupancies)\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cell\u001b[38;5;241m.\u001b[39mrank \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m    485\u001b[0m     spacegroup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_spacegroup(subtrans_included)\n\u001b[0;32m--> 486\u001b[0m     atoms \u001b[38;5;241m=\u001b[39m \u001b[43mcrystal\u001b[49m\u001b[43m(\u001b[49m\u001b[43munsymmetrized_structure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mspacegroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspacegroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m                    \u001b[49m\u001b[43msetting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspacegroup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m                    \u001b[49m\u001b[43moccupancies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moccupancies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mprimitive_cell\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprimitive_cell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    493\u001b[0m     atoms \u001b[38;5;241m=\u001b[39m unsymmetrized_structure\n",
      "File \u001b[0;32m~/.py311/lib/python3.11/site-packages/ase/spacegroup/xtal.py:149\u001b[0m, in \u001b[0;36mcrystal\u001b[0;34m(symbols, basis, occupancies, spacegroup, setting, cell, cellpar, ab_normal, a_direction, size, onduplicates, symprec, pbc, primitive_cell, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m                 occ\u001b[38;5;241m.\u001b[39mupdate({symbols[index_dist]: occupancies[index_dist]})\n\u001b[1;32m    147\u001b[0m         occupancies_dict[\u001b[38;5;28mstr\u001b[39m(index)] \u001b[38;5;241m=\u001b[39m occ\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m--> 149\u001b[0m sites, kinds \u001b[38;5;241m=\u001b[39m \u001b[43msg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mequivalent_sites\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbasis_coords\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43monduplicates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43monduplicates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43msymprec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msymprec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;66;03m# this is needed to handle deuterium masses\u001b[39;00m\n\u001b[1;32m    154\u001b[0m masses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.py311/lib/python3.11/site-packages/ase/spacegroup/spacegroup.py:475\u001b[0m, in \u001b[0;36mSpacegroup.equivalent_sites\u001b[0;34m(self, scaled_positions, onduplicates, symprec, occupancies)\u001b[0m\n\u001b[1;32m    473\u001b[0m diff \u001b[38;5;241m=\u001b[39m pos \u001b[38;5;241m-\u001b[39m positions0\n\u001b[1;32m    474\u001b[0m diff \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrint(diff)\n\u001b[0;32m--> 475\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43many\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mabs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdiff\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msymprec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    476\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m onduplicates \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeep\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    477\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/.py311/lib/python3.11/site-packages/numpy/core/fromnumeric.py:2412\u001b[0m, in \u001b[0;36many\u001b[0;34m(a, axis, out, keepdims, where)\u001b[0m\n\u001b[1;32m   2322\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_any_dispatcher)\n\u001b[1;32m   2323\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21many\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue, \u001b[38;5;241m*\u001b[39m, where\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue):\n\u001b[1;32m   2324\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2325\u001b[0m \u001b[38;5;124;03m    Test whether any array element along a given axis evaluates to True.\u001b[39;00m\n\u001b[1;32m   2326\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2410\u001b[0m \n\u001b[1;32m   2411\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2412\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogical_or\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43many\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2413\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.py311/lib/python3.11/site-packages/numpy/core/fromnumeric.py:71\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m         \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     62\u001b[0m         \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     67\u001b[0m         \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[1;32m     68\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m---> 71\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_wrapreduction\u001b[39m(obj, ufunc, method, axis, dtype, out, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     72\u001b[0m     passkwargs \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m     73\u001b[0m                   \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39m_NoValue}\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(obj) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mu\u001b[38;5;241m.\u001b[39mndarray:\n",
      "File \u001b[0;32m~/.py311/lib/python3.11/site-packages/pfp_api_client/pfp/utils/interrupt_watcher.py:18\u001b[0m, in \u001b[0;36mInterruptWatcher.set_interrupt_flag\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m     15\u001b[0m InterruptWatcher\u001b[38;5;241m.\u001b[39minterrupted_evt\u001b[38;5;241m.\u001b[39mset()\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# perform the default action, i.e., trigger a KeyboardInterrupt\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# exception in the main thread\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[43msignal\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault_int_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[43msignum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Interface construction and optimization for Al/NMC systems from CIF files.\n",
    "\n",
    "Key Features:\n",
    "- Stacks the Al slab in the z-direction to achieve a desired thickness (~30 Ã…).\n",
    "- Trims the final interface so both Al and NMC layers are ~30 Ã… thick.\n",
    "- Removes the vacuum layer after optimization to create a fully periodic model.\n",
    "- Uses CIF files as input for both Al and NMC structures.\n",
    "\"\"\"\n",
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import nglview as nv\n",
    "\n",
    "# ASE (Atomic Simulation Environment)\n",
    "from ase.io import read, write\n",
    "from ase.build import stack\n",
    "\n",
    "# Matlantis / PFP\n",
    "from matlantis_features.atoms import MatlantisAtoms\n",
    "from matlantis_features.features.common.opt import FireLBFGSASEOptFeature\n",
    "from matlantis_features.utils.calculators import pfp_estimator_fn\n",
    "from pfp_api_client.pfp.estimator import EstimatorCalcMode\n",
    "\n",
    "# --- Matlantis Optimization Function (Unchanged) ---\n",
    "def run_matlantis_optimization(atoms, trajectory_path, fmax=0.05, name=\"structure\"):\n",
    "    \"\"\"Runs a geometry optimization using Matlantis.\"\"\"\n",
    "    print(f\"  -> Starting Matlantis optimization for {name} (fmax = {fmax})...\")\n",
    "    matlantis_atoms = MatlantisAtoms(atoms)\n",
    "    estimator_function = pfp_estimator_fn(\n",
    "        model_version='v7.0.0', calc_mode=EstimatorCalcMode.CRYSTAL_PLUS_D3\n",
    "    )\n",
    "    position_optimizer = FireLBFGSASEOptFeature(\n",
    "        estimator_fn=estimator_function, filter=False, trajectory=str(trajectory_path),\n",
    "        n_run=5000, fmax=fmax, show_progress_bar=True\n",
    "    )\n",
    "    try:\n",
    "        result = position_optimizer(matlantis_atoms)\n",
    "        optimized_atoms = result.atoms.ase_atoms\n",
    "        final_energy = result.output.energy_log[-1]\n",
    "        print(f\"  -> âœ”ï¸ Optimization complete! Final Energy: {final_energy:.3f} eV\")\n",
    "        xyz_save_path = Path(trajectory_path).with_suffix('.xyz')\n",
    "        print(f\"  -> ğŸ’¾ Saving intermediate optimized structure to: {xyz_save_path.name}\")\n",
    "        write(str(xyz_save_path), optimized_atoms)\n",
    "        return optimized_atoms\n",
    "    except Exception as e:\n",
    "        print(f\"  -> âŒ An error occurred during optimization: {e}\")\n",
    "        return None\n",
    "\n",
    "# --- Interface Construction Class ---\n",
    "class InterfaceOptimizer:\n",
    "    def __init__(self, al_cif_path, nmc_cif_dir, interfaces_dir):\n",
    "        self.al_cif_path = Path(al_cif_path)\n",
    "        self.nmc_cif_dir = Path(nmc_cif_dir)\n",
    "        self.interfaces_dir = Path(interfaces_dir)\n",
    "        self.interfaces_dir.mkdir(parents=True, exist_ok=True)\n",
    "        print(\"\\n--- Interface Construction, Trimming, and Optimization ---\")\n",
    "        print(f\"Aluminum Slab: '{self.al_cif_path.name}'\")\n",
    "        print(f\"NMC Slabs from: '{self.nmc_cif_dir}'\")\n",
    "        print(f\"Output Directory: '{self.interfaces_dir}'\")\n",
    "\n",
    "    def find_surfaces(self):\n",
    "        \"\"\"Finds the input Al and NMC CIF files.\"\"\"\n",
    "        print(\"\\nğŸ” Searching for input structure files...\")\n",
    "        # Find Al slab\n",
    "        if not self.al_cif_path.is_file():\n",
    "            print(f\"ğŸ›‘ Error: Aluminum CIF file not found at '{self.al_cif_path}'\")\n",
    "            al_slabs = []\n",
    "        else:\n",
    "            al_slabs = [self.al_cif_path]\n",
    "            print(f\"  - Found 1 Al slab: {self.al_cif_path.name}\")\n",
    "\n",
    "        # Find NMC slabs\n",
    "        if not self.nmc_cif_dir.is_dir():\n",
    "            print(f\"ğŸ›‘ Error: NMC directory not found at '{self.nmc_cif_dir}'\")\n",
    "            cathode_slabs = []\n",
    "        else:\n",
    "            cathode_slabs = sorted(list(self.nmc_cif_dir.glob(\"NMC*.cif\")))\n",
    "            print(f\"  - Found {len(cathode_slabs)} NMC slabs.\")\n",
    "        \n",
    "        return al_slabs, cathode_slabs\n",
    "\n",
    "    def _stack_slab_to_thickness(self, atoms, target_thickness=30.0):\n",
    "        \"\"\"Stacks a unit cell in the z-direction to reach a target thickness.\"\"\"\n",
    "        z_coords = atoms.get_positions()[:, 2]\n",
    "        cell_thickness = z_coords.max() - z_coords.min()\n",
    "        if cell_thickness <= 0: return atoms # Avoid division by zero\n",
    "\n",
    "        num_repeats = int(np.ceil(target_thickness / cell_thickness))\n",
    "        if num_repeats <= 1:\n",
    "            return atoms\n",
    "\n",
    "        print(f\"      -> Stacking slab {num_repeats} times to reach ~{target_thickness} Ã…...\")\n",
    "        stacked_slab = atoms.copy()\n",
    "        for _ in range(num_repeats - 1):\n",
    "            stacked_slab = stack(stacked_slab, atoms, axis=2)\n",
    "        \n",
    "        final_thickness = stacked_slab.get_positions()[:, 2].max() - stacked_slab.get_positions()[:, 2].min()\n",
    "        print(f\"      -> Created slab with final thickness: {final_thickness:.2f} Ã….\")\n",
    "        return stacked_slab\n",
    "\n",
    "    def build_interface(self, al_slab, nmc_slab, separation=2.0):\n",
    "        \"\"\"Builds the interface by stacking and aligning the two slabs.\"\"\"\n",
    "        print(\"    1. Building interface structure...\")\n",
    "        \n",
    "        # Stack the Al slab to be thicker\n",
    "        thick_al_slab = self._stack_slab_to_thickness(al_slab, target_thickness=30.0)\n",
    "\n",
    "        # Align and stack the slabs\n",
    "        z_al_max = thick_al_slab.positions[:, 2].max()\n",
    "        z_nmc_min = nmc_slab.positions[:, 2].min()\n",
    "        nmc_slab.positions[:, 2] += z_al_max - z_nmc_min + separation\n",
    "        \n",
    "        interface = thick_al_slab + nmc_slab\n",
    "        # Set a temporary large cell for optimization\n",
    "        interface.cell[2, 2] = 100.0\n",
    "        interface.center(vacuum=15.0, axis=2)\n",
    "        return interface\n",
    "\n",
    "    def trim_interface(self, atoms, thickness_per_slab=30.0):\n",
    "        \"\"\"Trims the interface to the desired thickness for each material.\"\"\"\n",
    "        print(f\"    2. Trimming interface (target per slab: {thickness_per_slab} Ã…)...\")\n",
    "        al_indices = [a.index for a in atoms if a.symbol == 'Al']\n",
    "        nmc_indices = [a.index for a in atoms if a.symbol != 'Al']\n",
    "\n",
    "        if not al_indices or not nmc_indices:\n",
    "            print(\"       -> âš ï¸ Warning: Could not find both Al and NMC atoms. Skipping trim.\")\n",
    "            return atoms\n",
    "\n",
    "        al_pos = atoms.get_positions()[al_indices]\n",
    "        nmc_pos = atoms.get_positions()[nmc_indices]\n",
    "        \n",
    "        # Determine interface position and which slab is on the bottom\n",
    "        if np.mean(al_pos[:, 2]) < np.mean(nmc_pos[:, 2]):\n",
    "            interface_z = (al_pos[:, 2].max() + nmc_pos[:, 2].min()) / 2.0\n",
    "            is_al_bottom = True\n",
    "        else:\n",
    "            interface_z = (nmc_pos[:, 2].max() + al_pos[:, 2].min()) / 2.0\n",
    "            is_al_bottom = False\n",
    "\n",
    "        indices_to_delete = []\n",
    "        for atom in atoms:\n",
    "            is_al_atom = atom.symbol == 'Al'\n",
    "            if is_al_bottom:\n",
    "                if is_al_atom and atom.z < (interface_z - thickness_per_slab):\n",
    "                    indices_to_delete.append(atom.index)\n",
    "                elif not is_al_atom and atom.z > (interface_z + thickness_per_slab):\n",
    "                    indices_to_delete.append(atom.index)\n",
    "            else: # NMC is on the bottom\n",
    "                if not is_al_atom and atom.z < (interface_z - thickness_per_slab):\n",
    "                    indices_to_delete.append(atom.index)\n",
    "                elif is_al_atom and atom.z > (interface_z + thickness_per_slab):\n",
    "                    indices_to_delete.append(atom.index)\n",
    "        \n",
    "        print(f\"        -> Deleting {len(indices_to_delete)} atoms outside the target thickness.\")\n",
    "        if indices_to_delete:\n",
    "            del atoms[indices_to_delete]\n",
    "        return atoms\n",
    "\n",
    "    def process_interface(self, al_path, nmc_path):\n",
    "        \"\"\"The main workflow for one pair of Al and NMC slabs.\"\"\"\n",
    "        al_name = al_path.stem\n",
    "        nmc_name = nmc_path.stem\n",
    "        interface_name = f\"Interface_{al_name}_on_{nmc_name}\"\n",
    "        output_path = self.interfaces_dir / f\"{interface_name}.cif\"\n",
    "\n",
    "        if output_path.exists():\n",
    "            print(f\"âœ… Output file already exists, skipping: {output_path.name}\")\n",
    "            return\n",
    "\n",
    "        print(f\"\\n--- Processing combination: {al_name} + {nmc_name} ---\")\n",
    "        try:\n",
    "            al_slab = read(al_path)\n",
    "            nmc_slab = read(nmc_path)\n",
    "            \n",
    "            # Step 1: Build and Trim\n",
    "            interface_built = self.build_interface(al_slab, nmc_slab)\n",
    "            interface_trimmed = self.trim_interface(interface_built, thickness_per_slab=30.0)\n",
    "\n",
    "            # Step 2: Optimize\n",
    "            print(\"    3. Optimizing atomic positions...\")\n",
    "            traj_path = self.interfaces_dir / f\"{interface_name}_opt.traj\"\n",
    "            optimized_atoms = run_matlantis_optimization(interface_trimmed, traj_path, name=interface_name)\n",
    "\n",
    "            # Step 3: Finalize and Save\n",
    "            if optimized_atoms:\n",
    "                print(\"    4. Finalizing structure (removing vacuum)...\")\n",
    "                # Remove vacuum layer by fitting the cell to the atoms\n",
    "                positions = optimized_atoms.get_positions()\n",
    "                z_min, z_max = positions[:, 2].min(), positions[:, 2].max()\n",
    "                optimized_atoms.cell[2, 2] = z_max - z_min\n",
    "                positions[:, 2] -= z_min # Shift atoms to start at z=0\n",
    "                optimized_atoms.set_positions(positions)\n",
    "                \n",
    "                # Set periodic boundary conditions in all directions\n",
    "                optimized_atoms.pbc = (True, True, True)\n",
    "\n",
    "                print(f\"       -> Saving final periodic structure to: {output_path.name}\")\n",
    "                write(str(output_path), optimized_atoms)\n",
    "            else:\n",
    "                print(\"    -> âŒ Optimization failed, structure not saved.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  -> âŒ A critical error occurred while processing this interface: {e}\")\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"Runs the entire interface generation workflow.\"\"\"\n",
    "        al_slabs, cathode_slabs = self.find_surfaces()\n",
    "        if not al_slabs or not cathode_slabs:\n",
    "            print(\"\\n-> Could not find Al or NMC slabs. Aborting workflow.\")\n",
    "            return\n",
    "\n",
    "        for al_path in al_slabs:\n",
    "            for nmc_path in cathode_slabs:\n",
    "                self.process_interface(al_path, nmc_path)\n",
    "        \n",
    "        print(\"\\nâœ¨ All interface processing is complete. âœ¨\")\n",
    "\n",
    "# --- Results Viewer Function (Unchanged) ---\n",
    "def show_results_viewer(results_dir):\n",
    "    \"\"\"Creates an interactive dropdown to view the generated CIF files.\"\"\"\n",
    "    print(f\"\\n--- ğŸ”¬ Results Viewer: '{results_dir}' ---\")\n",
    "    files = sorted(list(Path(results_dir).glob(\"*.cif\")))\n",
    "    if not files:\n",
    "        print(\"No structures available to display.\")\n",
    "        return\n",
    "    \n",
    "    options = {\"-- Select a structure --\": \"\"}\n",
    "    options.update({p.name: str(p) for p in files})\n",
    "\n",
    "    def view_structure(file_path):\n",
    "        if file_path:\n",
    "            try:\n",
    "                atoms = read(file_path)\n",
    "                view = nv.show_ase(atoms)\n",
    "                display(view)\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading or displaying file: {e}\")\n",
    "\n",
    "    widgets.interact(\n",
    "        view_structure,\n",
    "        file_path=widgets.Dropdown(options=options, description='Interface:', layout={'width': 'max-content'})\n",
    "    )\n",
    "\n",
    "# --- Main Execution Block ---\n",
    "if __name__ == \"__main__\":\n",
    "    # ===== USER SETTINGS =====\n",
    "    # 1. Path to your single Aluminum (Al) CIF file\n",
    "    AL_CIF_PATH = \"/home/jovyan/Kaori/MD/LiB_2/Al555.xyz\"\n",
    "\n",
    "    # 2. Path to the directory containing your Nickel Manganese Cobalt Oxide (NMC) CIF files\n",
    "    NMC_CIF_DIR = \"/home/jovyan/Kaori/MD/LiB_2/structure/output/cif_files/cif_files/\"\n",
    "\n",
    "    # 3. Directory where the final interface structures will be saved\n",
    "    INTERFACES_DIR = \"/home/jovyan/Kaori/MD/LiB_2/structure/output/final_interfaces_Al_NMC\"\n",
    "    # =========================\n",
    "\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    # Initialize and run the interface optimization workflow\n",
    "    interface_optimizer = InterfaceOptimizer(\n",
    "        al_cif_path=AL_CIF_PATH,\n",
    "        nmc_cif_dir=NMC_CIF_DIR,\n",
    "        interfaces_dir=INTERFACES_DIR\n",
    "    )\n",
    "    interface_optimizer.run()\n",
    "\n",
    "    # Display the results\n",
    "    show_results_viewer(INTERFACES_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef1ff0ea-8b93-4fb3-ba4e-fa5b3c2a9b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- ç•Œé¢ æ§‹ç¯‰ãƒ»ãƒˆãƒªãƒŸãƒ³ã‚°ãƒ»æœ€é©åŒ–ãƒ—ãƒ­ã‚»ã‚¹ã‚’é–‹å§‹ ---\n",
      "   - Material 1 (æŒ‡å®š): 'Al555.xyz'\n",
      "   - Material 2 (æ¤œç´¢): 'NMC_' ã§å§‹ã¾ã‚‹CIFãƒ•ã‚¡ã‚¤ãƒ«\n",
      "   - ä¿å­˜å…ˆ: '/home/jovyan/Kaori/MD/LiB_2/structure/output/final_interfaces_Al555_vs_NMC'\n",
      "ğŸ” è¡¨é¢ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†é¡ä¸­...\n",
      "  - Material 1: 1å€‹è¦‹ã¤ã‹ã‚Šã¾ã—ãŸ -> Al555.xyz\n",
      "  - NMC_è¡¨é¢: 17å€‹è¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚\n",
      "\n",
      "--- Al555/NMC_ç•Œé¢ã®çµ„ã¿åˆã‚ã›å‡¦ç†ã‚’é–‹å§‹ ---\n",
      "\n",
      "--- å‡¦ç†é–‹å§‹: Al555 + NMC_Mn_decrease_104_surface ---\n",
      "    1. ç•Œé¢ã‚’æ§‹ç¯‰ä¸­...\n",
      "    2. ç•Œé¢ã‚’ãƒˆãƒªãƒŸãƒ³ã‚°ä¸­ (å„ã‚¹ãƒ©ãƒ–åšã¿: 25.0 Ã…)...\n",
      "        -> 0 å€‹ã®åŸå­ã‚’å‰Šé™¤ã—ã¾ã™ã€‚\n",
      "    3. ãƒˆãƒªãƒŸãƒ³ã‚°å¾Œã®æ§‹é€ ã‚’æœ€é©åŒ–ä¸­...\n",
      "  -> Matlantisæœ€é©åŒ–é–‹å§‹ (Interface_Al555_on_NMC_Mn_decrease_104_surface_trimmed, fmax = 0.05) ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a104edc968d424fb02a549b9148b5f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> âœ”ï¸ æœ€é©åŒ–å®Œäº†ï¼ ã‚¨ãƒãƒ«ã‚®ãƒ¼: -620.966 eV\n",
      "  -> ğŸ’¾ æœ€é©åŒ–å¾Œã®ä¸­é–“æ§‹é€ ã‚’ä¿å­˜ã—ã¾ã™: Interface_Al555_on_NMC_Mn_decrease_104_surface_trimmed.xyz\n",
      "    4. æœ€çµ‚æ§‹é€ ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ä¸­ -> Interface_Al555_on_NMC_Mn_decrease_104_surface_trimmed.cif\n",
      "\n",
      "--- å‡¦ç†é–‹å§‹: Al555 + NMC_Mn_increase_001_surface ---\n",
      "    1. ç•Œé¢ã‚’æ§‹ç¯‰ä¸­...\n",
      "    2. ç•Œé¢ã‚’ãƒˆãƒªãƒŸãƒ³ã‚°ä¸­ (å„ã‚¹ãƒ©ãƒ–åšã¿: 25.0 Ã…)...\n",
      "        -> 0 å€‹ã®åŸå­ã‚’å‰Šé™¤ã—ã¾ã™ã€‚\n",
      "    3. ãƒˆãƒªãƒŸãƒ³ã‚°å¾Œã®æ§‹é€ ã‚’æœ€é©åŒ–ä¸­...\n",
      "  -> Matlantisæœ€é©åŒ–é–‹å§‹ (Interface_Al555_on_NMC_Mn_increase_001_surface_trimmed, fmax = 0.05) ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cdebb1c50964518affdee47819d1008",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> âœ”ï¸ æœ€é©åŒ–å®Œäº†ï¼ ã‚¨ãƒãƒ«ã‚®ãƒ¼: -1762.656 eV\n",
      "  -> ğŸ’¾ æœ€é©åŒ–å¾Œã®ä¸­é–“æ§‹é€ ã‚’ä¿å­˜ã—ã¾ã™: Interface_Al555_on_NMC_Mn_increase_001_surface_trimmed.xyz\n",
      "    4. æœ€çµ‚æ§‹é€ ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ä¸­ -> Interface_Al555_on_NMC_Mn_increase_001_surface_trimmed.cif\n",
      "\n",
      "--- å‡¦ç†é–‹å§‹: Al555 + NMC_Co_decrease_104_surface ---\n",
      "    1. ç•Œé¢ã‚’æ§‹ç¯‰ä¸­...\n",
      "    2. ç•Œé¢ã‚’ãƒˆãƒªãƒŸãƒ³ã‚°ä¸­ (å„ã‚¹ãƒ©ãƒ–åšã¿: 25.0 Ã…)...\n",
      "        -> 0 å€‹ã®åŸå­ã‚’å‰Šé™¤ã—ã¾ã™ã€‚\n",
      "    3. ãƒˆãƒªãƒŸãƒ³ã‚°å¾Œã®æ§‹é€ ã‚’æœ€é©åŒ–ä¸­...\n",
      "  -> Matlantisæœ€é©åŒ–é–‹å§‹ (Interface_Al555_on_NMC_Co_decrease_104_surface_trimmed, fmax = 0.05) ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63f998c4228147f4adf582ed081fb1de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> âœ”ï¸ æœ€é©åŒ–å®Œäº†ï¼ ã‚¨ãƒãƒ«ã‚®ãƒ¼: -625.009 eV\n",
      "  -> ğŸ’¾ æœ€é©åŒ–å¾Œã®ä¸­é–“æ§‹é€ ã‚’ä¿å­˜ã—ã¾ã™: Interface_Al555_on_NMC_Co_decrease_104_surface_trimmed.xyz\n",
      "    4. æœ€çµ‚æ§‹é€ ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ä¸­ -> Interface_Al555_on_NMC_Co_decrease_104_surface_trimmed.cif\n",
      "\n",
      "--- å‡¦ç†é–‹å§‹: Al555 + NMC_Co_increase_104_surface ---\n",
      "    1. ç•Œé¢ã‚’æ§‹ç¯‰ä¸­...\n",
      "    2. ç•Œé¢ã‚’ãƒˆãƒªãƒŸãƒ³ã‚°ä¸­ (å„ã‚¹ãƒ©ãƒ–åšã¿: 25.0 Ã…)...\n",
      "        -> 0 å€‹ã®åŸå­ã‚’å‰Šé™¤ã—ã¾ã™ã€‚\n",
      "    3. ãƒˆãƒªãƒŸãƒ³ã‚°å¾Œã®æ§‹é€ ã‚’æœ€é©åŒ–ä¸­...\n",
      "  -> Matlantisæœ€é©åŒ–é–‹å§‹ (Interface_Al555_on_NMC_Co_increase_104_surface_trimmed, fmax = 0.05) ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cc35887648743d89ff33dec9d7749a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> âœ”ï¸ æœ€é©åŒ–å®Œäº†ï¼ ã‚¨ãƒãƒ«ã‚®ãƒ¼: -630.858 eV\n",
      "  -> ğŸ’¾ æœ€é©åŒ–å¾Œã®ä¸­é–“æ§‹é€ ã‚’ä¿å­˜ã—ã¾ã™: Interface_Al555_on_NMC_Co_increase_104_surface_trimmed.xyz\n",
      "    4. æœ€çµ‚æ§‹é€ ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ä¸­ -> Interface_Al555_on_NMC_Co_increase_104_surface_trimmed.cif\n",
      "\n",
      "--- å‡¦ç†é–‹å§‹: Al555 + NMC_Co_increase_bulk ---\n",
      "    1. ç•Œé¢ã‚’æ§‹ç¯‰ä¸­...\n",
      "    2. ç•Œé¢ã‚’ãƒˆãƒªãƒŸãƒ³ã‚°ä¸­ (å„ã‚¹ãƒ©ãƒ–åšã¿: 25.0 Ã…)...\n",
      "        -> 0 å€‹ã®åŸå­ã‚’å‰Šé™¤ã—ã¾ã™ã€‚\n",
      "    3. ãƒˆãƒªãƒŸãƒ³ã‚°å¾Œã®æ§‹é€ ã‚’æœ€é©åŒ–ä¸­...\n",
      "  -> Matlantisæœ€é©åŒ–é–‹å§‹ (Interface_Al555_on_NMC_Co_increase_bulk_trimmed, fmax = 0.05) ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "782be4e154704f0ba207629a303b203d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> âœ”ï¸ æœ€é©åŒ–å®Œäº†ï¼ ã‚¨ãƒãƒ«ã‚®ãƒ¼: -383.709 eV\n",
      "  -> ğŸ’¾ æœ€é©åŒ–å¾Œã®ä¸­é–“æ§‹é€ ã‚’ä¿å­˜ã—ã¾ã™: Interface_Al555_on_NMC_Co_increase_bulk_trimmed.xyz\n",
      "    4. æœ€çµ‚æ§‹é€ ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ä¸­ -> Interface_Al555_on_NMC_Co_increase_bulk_trimmed.cif\n",
      "\n",
      "--- å‡¦ç†é–‹å§‹: Al555 + NMC_Co_decrease_bulk ---\n",
      "    1. ç•Œé¢ã‚’æ§‹ç¯‰ä¸­...\n",
      "    2. ç•Œé¢ã‚’ãƒˆãƒªãƒŸãƒ³ã‚°ä¸­ (å„ã‚¹ãƒ©ãƒ–åšã¿: 25.0 Ã…)...\n",
      "        -> 0 å€‹ã®åŸå­ã‚’å‰Šé™¤ã—ã¾ã™ã€‚\n",
      "    3. ãƒˆãƒªãƒŸãƒ³ã‚°å¾Œã®æ§‹é€ ã‚’æœ€é©åŒ–ä¸­...\n",
      "  -> Matlantisæœ€é©åŒ–é–‹å§‹ (Interface_Al555_on_NMC_Co_decrease_bulk_trimmed, fmax = 0.05) ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33c036c1a24e4b50ab5a6765fac2bd5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> âœ”ï¸ æœ€é©åŒ–å®Œäº†ï¼ ã‚¨ãƒãƒ«ã‚®ãƒ¼: -380.668 eV\n",
      "  -> ğŸ’¾ æœ€é©åŒ–å¾Œã®ä¸­é–“æ§‹é€ ã‚’ä¿å­˜ã—ã¾ã™: Interface_Al555_on_NMC_Co_decrease_bulk_trimmed.xyz\n",
      "    4. æœ€çµ‚æ§‹é€ ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ä¸­ -> Interface_Al555_on_NMC_Co_decrease_bulk_trimmed.cif\n",
      "\n",
      "--- å‡¦ç†é–‹å§‹: Al555 + NMC_Co_decrease_001_surface ---\n",
      "    1. ç•Œé¢ã‚’æ§‹ç¯‰ä¸­...\n",
      "    2. ç•Œé¢ã‚’ãƒˆãƒªãƒŸãƒ³ã‚°ä¸­ (å„ã‚¹ãƒ©ãƒ–åšã¿: 25.0 Ã…)...\n",
      "        -> 0 å€‹ã®åŸå­ã‚’å‰Šé™¤ã—ã¾ã™ã€‚\n",
      "    3. ãƒˆãƒªãƒŸãƒ³ã‚°å¾Œã®æ§‹é€ ã‚’æœ€é©åŒ–ä¸­...\n",
      "  -> Matlantisæœ€é©åŒ–é–‹å§‹ (Interface_Al555_on_NMC_Co_decrease_001_surface_trimmed, fmax = 0.05) ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "004ea2250e5541c79fad75b4b80d2862",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> âœ”ï¸ æœ€é©åŒ–å®Œäº†ï¼ ã‚¨ãƒãƒ«ã‚®ãƒ¼: -1732.875 eV\n",
      "  -> ğŸ’¾ æœ€é©åŒ–å¾Œã®ä¸­é–“æ§‹é€ ã‚’ä¿å­˜ã—ã¾ã™: Interface_Al555_on_NMC_Co_decrease_001_surface_trimmed.xyz\n",
      "    4. æœ€çµ‚æ§‹é€ ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ä¸­ -> Interface_Al555_on_NMC_Co_decrease_001_surface_trimmed.cif\n",
      "\n",
      "--- å‡¦ç†é–‹å§‹: Al555 + NMC_Mn_decrease_010_surface ---\n",
      "    1. ç•Œé¢ã‚’æ§‹ç¯‰ä¸­...\n",
      "    2. ç•Œé¢ã‚’ãƒˆãƒªãƒŸãƒ³ã‚°ä¸­ (å„ã‚¹ãƒ©ãƒ–åšã¿: 25.0 Ã…)...\n",
      "        -> 205 å€‹ã®åŸå­ã‚’å‰Šé™¤ã—ã¾ã™ã€‚\n",
      "    3. ãƒˆãƒªãƒŸãƒ³ã‚°å¾Œã®æ§‹é€ ã‚’æœ€é©åŒ–ä¸­...\n",
      "  -> Matlantisæœ€é©åŒ–é–‹å§‹ (Interface_Al555_on_NMC_Mn_decrease_010_surface_trimmed, fmax = 0.05) ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "555bf0977aba4ac1ad0ed07096c13254",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> âœ”ï¸ æœ€é©åŒ–å®Œäº†ï¼ ã‚¨ãƒãƒ«ã‚®ãƒ¼: -2467.880 eV\n",
      "  -> ğŸ’¾ æœ€é©åŒ–å¾Œã®ä¸­é–“æ§‹é€ ã‚’ä¿å­˜ã—ã¾ã™: Interface_Al555_on_NMC_Mn_decrease_010_surface_trimmed.xyz\n",
      "    4. æœ€çµ‚æ§‹é€ ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ä¸­ -> Interface_Al555_on_NMC_Mn_decrease_010_surface_trimmed.cif\n",
      "\n",
      "--- å‡¦ç†é–‹å§‹: Al555 + NMC_Co_increase_012_surface ---\n",
      "    1. ç•Œé¢ã‚’æ§‹ç¯‰ä¸­...\n",
      "    2. ç•Œé¢ã‚’ãƒˆãƒªãƒŸãƒ³ã‚°ä¸­ (å„ã‚¹ãƒ©ãƒ–åšã¿: 25.0 Ã…)...\n",
      "        -> 0 å€‹ã®åŸå­ã‚’å‰Šé™¤ã—ã¾ã™ã€‚\n",
      "    3. ãƒˆãƒªãƒŸãƒ³ã‚°å¾Œã®æ§‹é€ ã‚’æœ€é©åŒ–ä¸­...\n",
      "  -> Matlantisæœ€é©åŒ–é–‹å§‹ (Interface_Al555_on_NMC_Co_increase_012_surface_trimmed, fmax = 0.05) ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "282522e966cb44a98a2d3ccf043f7a45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> âœ”ï¸ æœ€é©åŒ–å®Œäº†ï¼ ã‚¨ãƒãƒ«ã‚®ãƒ¼: -943.598 eV\n",
      "  -> ğŸ’¾ æœ€é©åŒ–å¾Œã®ä¸­é–“æ§‹é€ ã‚’ä¿å­˜ã—ã¾ã™: Interface_Al555_on_NMC_Co_increase_012_surface_trimmed.xyz\n",
      "    4. æœ€çµ‚æ§‹é€ ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ä¸­ -> Interface_Al555_on_NMC_Co_increase_012_surface_trimmed.cif\n",
      "\n",
      "--- å‡¦ç†é–‹å§‹: Al555 + NMC_Co_increase_010_surface ---\n",
      "    1. ç•Œé¢ã‚’æ§‹ç¯‰ä¸­...\n",
      "    2. ç•Œé¢ã‚’ãƒˆãƒªãƒŸãƒ³ã‚°ä¸­ (å„ã‚¹ãƒ©ãƒ–åšã¿: 25.0 Ã…)...\n",
      "        -> 203 å€‹ã®åŸå­ã‚’å‰Šé™¤ã—ã¾ã™ã€‚\n",
      "    3. ãƒˆãƒªãƒŸãƒ³ã‚°å¾Œã®æ§‹é€ ã‚’æœ€é©åŒ–ä¸­...\n",
      "  -> Matlantisæœ€é©åŒ–é–‹å§‹ (Interface_Al555_on_NMC_Co_increase_010_surface_trimmed, fmax = 0.05) ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51da641c9f694093a41e9d3dd39d8155",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> âœ”ï¸ æœ€é©åŒ–å®Œäº†ï¼ ã‚¨ãƒãƒ«ã‚®ãƒ¼: -2508.947 eV\n",
      "  -> ğŸ’¾ æœ€é©åŒ–å¾Œã®ä¸­é–“æ§‹é€ ã‚’ä¿å­˜ã—ã¾ã™: Interface_Al555_on_NMC_Co_increase_010_surface_trimmed.xyz\n",
      "    4. æœ€çµ‚æ§‹é€ ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ä¸­ -> Interface_Al555_on_NMC_Co_increase_010_surface_trimmed.cif\n",
      "\n",
      "--- å‡¦ç†é–‹å§‹: Al555 + NMC_Mn_increase_010_surface ---\n",
      "    1. ç•Œé¢ã‚’æ§‹ç¯‰ä¸­...\n",
      "    2. ç•Œé¢ã‚’ãƒˆãƒªãƒŸãƒ³ã‚°ä¸­ (å„ã‚¹ãƒ©ãƒ–åšã¿: 25.0 Ã…)...\n",
      "        -> 196 å€‹ã®åŸå­ã‚’å‰Šé™¤ã—ã¾ã™ã€‚\n",
      "    3. ãƒˆãƒªãƒŸãƒ³ã‚°å¾Œã®æ§‹é€ ã‚’æœ€é©åŒ–ä¸­...\n",
      "  -> Matlantisæœ€é©åŒ–é–‹å§‹ (Interface_Al555_on_NMC_Mn_increase_010_surface_trimmed, fmax = 0.05) ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d59872c12d0342e1b16011949ecb4680",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> âœ”ï¸ æœ€é©åŒ–å®Œäº†ï¼ ã‚¨ãƒãƒ«ã‚®ãƒ¼: -2516.125 eV\n",
      "  -> ğŸ’¾ æœ€é©åŒ–å¾Œã®ä¸­é–“æ§‹é€ ã‚’ä¿å­˜ã—ã¾ã™: Interface_Al555_on_NMC_Mn_increase_010_surface_trimmed.xyz\n",
      "    4. æœ€çµ‚æ§‹é€ ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ä¸­ -> Interface_Al555_on_NMC_Mn_increase_010_surface_trimmed.cif\n",
      "\n",
      "--- å‡¦ç†é–‹å§‹: Al555 + NMC_Co_decrease_010_surface ---\n",
      "    1. ç•Œé¢ã‚’æ§‹ç¯‰ä¸­...\n",
      "    2. ç•Œé¢ã‚’ãƒˆãƒªãƒŸãƒ³ã‚°ä¸­ (å„ã‚¹ãƒ©ãƒ–åšã¿: 25.0 Ã…)...\n",
      "        -> 202 å€‹ã®åŸå­ã‚’å‰Šé™¤ã—ã¾ã™ã€‚\n",
      "    3. ãƒˆãƒªãƒŸãƒ³ã‚°å¾Œã®æ§‹é€ ã‚’æœ€é©åŒ–ä¸­...\n",
      "  -> Matlantisæœ€é©åŒ–é–‹å§‹ (Interface_Al555_on_NMC_Co_decrease_010_surface_trimmed, fmax = 0.05) ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01c867022e244023a20f15cfb72c45c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> âœ”ï¸ æœ€é©åŒ–å®Œäº†ï¼ ã‚¨ãƒãƒ«ã‚®ãƒ¼: -2473.457 eV\n",
      "  -> ğŸ’¾ æœ€é©åŒ–å¾Œã®ä¸­é–“æ§‹é€ ã‚’ä¿å­˜ã—ã¾ã™: Interface_Al555_on_NMC_Co_decrease_010_surface_trimmed.xyz\n",
      "    4. æœ€çµ‚æ§‹é€ ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ä¸­ -> Interface_Al555_on_NMC_Co_decrease_010_surface_trimmed.cif\n",
      "\n",
      "--- å‡¦ç†é–‹å§‹: Al555 + NMC_Mn_decrease_001_surface ---\n",
      "    1. ç•Œé¢ã‚’æ§‹ç¯‰ä¸­...\n",
      "    2. ç•Œé¢ã‚’ãƒˆãƒªãƒŸãƒ³ã‚°ä¸­ (å„ã‚¹ãƒ©ãƒ–åšã¿: 25.0 Ã…)...\n",
      "        -> 0 å€‹ã®åŸå­ã‚’å‰Šé™¤ã—ã¾ã™ã€‚\n",
      "    3. ãƒˆãƒªãƒŸãƒ³ã‚°å¾Œã®æ§‹é€ ã‚’æœ€é©åŒ–ä¸­...\n",
      "  -> Matlantisæœ€é©åŒ–é–‹å§‹ (Interface_Al555_on_NMC_Mn_decrease_001_surface_trimmed, fmax = 0.05) ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "528a5c09d8df4513b6bc86b6fcaa91b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> âœ”ï¸ æœ€é©åŒ–å®Œäº†ï¼ ã‚¨ãƒãƒ«ã‚®ãƒ¼: -1698.866 eV\n",
      "  -> ğŸ’¾ æœ€é©åŒ–å¾Œã®ä¸­é–“æ§‹é€ ã‚’ä¿å­˜ã—ã¾ã™: Interface_Al555_on_NMC_Mn_decrease_001_surface_trimmed.xyz\n",
      "    4. æœ€çµ‚æ§‹é€ ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ä¸­ -> Interface_Al555_on_NMC_Mn_decrease_001_surface_trimmed.cif\n",
      "\n",
      "--- å‡¦ç†é–‹å§‹: Al555 + NMC_Mn_decrease_bulk ---\n",
      "    1. ç•Œé¢ã‚’æ§‹ç¯‰ä¸­...\n",
      "    2. ç•Œé¢ã‚’ãƒˆãƒªãƒŸãƒ³ã‚°ä¸­ (å„ã‚¹ãƒ©ãƒ–åšã¿: 25.0 Ã…)...\n",
      "        -> 0 å€‹ã®åŸå­ã‚’å‰Šé™¤ã—ã¾ã™ã€‚\n",
      "    3. ãƒˆãƒªãƒŸãƒ³ã‚°å¾Œã®æ§‹é€ ã‚’æœ€é©åŒ–ä¸­...\n",
      "  -> Matlantisæœ€é©åŒ–é–‹å§‹ (Interface_Al555_on_NMC_Mn_decrease_bulk_trimmed, fmax = 0.05) ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc80a081a5f84ca389b95bdb59ca7118",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> âœ”ï¸ æœ€é©åŒ–å®Œäº†ï¼ ã‚¨ãƒãƒ«ã‚®ãƒ¼: -382.577 eV\n",
      "  -> ğŸ’¾ æœ€é©åŒ–å¾Œã®ä¸­é–“æ§‹é€ ã‚’ä¿å­˜ã—ã¾ã™: Interface_Al555_on_NMC_Mn_decrease_bulk_trimmed.xyz\n",
      "    4. æœ€çµ‚æ§‹é€ ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ä¸­ -> Interface_Al555_on_NMC_Mn_decrease_bulk_trimmed.cif\n",
      "\n",
      "--- å‡¦ç†é–‹å§‹: Al555 + NMC_Co_increase_001_surface ---\n",
      "    1. ç•Œé¢ã‚’æ§‹ç¯‰ä¸­...\n",
      "    2. ç•Œé¢ã‚’ãƒˆãƒªãƒŸãƒ³ã‚°ä¸­ (å„ã‚¹ãƒ©ãƒ–åšã¿: 25.0 Ã…)...\n",
      "        -> 0 å€‹ã®åŸå­ã‚’å‰Šé™¤ã—ã¾ã™ã€‚\n",
      "    3. ãƒˆãƒªãƒŸãƒ³ã‚°å¾Œã®æ§‹é€ ã‚’æœ€é©åŒ–ä¸­...\n",
      "  -> Matlantisæœ€é©åŒ–é–‹å§‹ (Interface_Al555_on_NMC_Co_increase_001_surface_trimmed, fmax = 0.05) ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfeca6742e0740c8b839bd17b8ef8e9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> âœ”ï¸ æœ€é©åŒ–å®Œäº†ï¼ ã‚¨ãƒãƒ«ã‚®ãƒ¼: -1755.178 eV\n",
      "  -> ğŸ’¾ æœ€é©åŒ–å¾Œã®ä¸­é–“æ§‹é€ ã‚’ä¿å­˜ã—ã¾ã™: Interface_Al555_on_NMC_Co_increase_001_surface_trimmed.xyz\n",
      "    4. æœ€çµ‚æ§‹é€ ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ä¸­ -> Interface_Al555_on_NMC_Co_increase_001_surface_trimmed.cif\n",
      "\n",
      "--- å‡¦ç†é–‹å§‹: Al555 + NMC_Mn_decrease_012_surface ---\n",
      "    1. ç•Œé¢ã‚’æ§‹ç¯‰ä¸­...\n",
      "    2. ç•Œé¢ã‚’ãƒˆãƒªãƒŸãƒ³ã‚°ä¸­ (å„ã‚¹ãƒ©ãƒ–åšã¿: 25.0 Ã…)...\n",
      "        -> 0 å€‹ã®åŸå­ã‚’å‰Šé™¤ã—ã¾ã™ã€‚\n",
      "    3. ãƒˆãƒªãƒŸãƒ³ã‚°å¾Œã®æ§‹é€ ã‚’æœ€é©åŒ–ä¸­...\n",
      "  -> Matlantisæœ€é©åŒ–é–‹å§‹ (Interface_Al555_on_NMC_Mn_decrease_012_surface_trimmed, fmax = 0.05) ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aac6f44d4f6416d850fb7809f08cd0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> âœ”ï¸ æœ€é©åŒ–å®Œäº†ï¼ ã‚¨ãƒãƒ«ã‚®ãƒ¼: -930.500 eV\n",
      "  -> ğŸ’¾ æœ€é©åŒ–å¾Œã®ä¸­é–“æ§‹é€ ã‚’ä¿å­˜ã—ã¾ã™: Interface_Al555_on_NMC_Mn_decrease_012_surface_trimmed.xyz\n",
      "    4. æœ€çµ‚æ§‹é€ ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ä¸­ -> Interface_Al555_on_NMC_Mn_decrease_012_surface_trimmed.cif\n",
      "\n",
      "--- å‡¦ç†é–‹å§‹: Al555 + NMC_Co_decrease_012_surface ---\n",
      "    1. ç•Œé¢ã‚’æ§‹ç¯‰ä¸­...\n",
      "    2. ç•Œé¢ã‚’ãƒˆãƒªãƒŸãƒ³ã‚°ä¸­ (å„ã‚¹ãƒ©ãƒ–åšã¿: 25.0 Ã…)...\n",
      "        -> 0 å€‹ã®åŸå­ã‚’å‰Šé™¤ã—ã¾ã™ã€‚\n",
      "    3. ãƒˆãƒªãƒŸãƒ³ã‚°å¾Œã®æ§‹é€ ã‚’æœ€é©åŒ–ä¸­...\n",
      "  -> Matlantisæœ€é©åŒ–é–‹å§‹ (Interface_Al555_on_NMC_Co_decrease_012_surface_trimmed, fmax = 0.05) ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40e7275a758f413a8b74434177c5d89b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> âœ”ï¸ æœ€é©åŒ–å®Œäº†ï¼ ã‚¨ãƒãƒ«ã‚®ãƒ¼: -946.308 eV\n",
      "  -> ğŸ’¾ æœ€é©åŒ–å¾Œã®ä¸­é–“æ§‹é€ ã‚’ä¿å­˜ã—ã¾ã™: Interface_Al555_on_NMC_Co_decrease_012_surface_trimmed.xyz\n",
      "    4. æœ€çµ‚æ§‹é€ ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ä¸­ -> Interface_Al555_on_NMC_Co_decrease_012_surface_trimmed.cif\n",
      "\n",
      "âœ¨ å…¨ã¦ã®å‡¦ç†ãŒå®Œäº†ã€‚\n",
      "\n",
      "\n",
      "âœ¨ å…¨ã¦ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãŒå®Œäº†ã—ã¾ã—ãŸã€‚ âœ¨\n",
      "\n",
      "--- ğŸ”¬ çµæœãƒ“ãƒ¥ãƒ¼ãƒ¯ãƒ¼: '/home/jovyan/Kaori/MD/LiB_2/structure/output/final_interfaces_Al555_vs_NMC' ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d6a5d3cb0ee4771a7508942bd41f7f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Interface:', layout=Layout(width='max-content'), options={'-- é¸æŠã—ã¦â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "ç•Œé¢æ§‹ç¯‰ãƒ»æœ€é©åŒ–ã‚’è‡ªå‹•åŒ–ã™ã‚‹ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã€‚\n",
    "\n",
    "[æœ€çµ‚ç‰ˆ: CIFå¯¾å¿œ]\n",
    "- Material 1 ã‚’ç‰¹å®šã®ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿ã€Material 2 ã‚’CIFãƒ•ã‚¡ã‚¤ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰æ¤œç´¢ã—ã¦ç•Œé¢ã‚’æ§‹ç¯‰ã—ã¾ã™ã€‚\n",
    "- ç ´æã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ãªã©ã€ç‰¹å®šãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¦ã‚‚å…¨ä½“ãŒåœæ­¢ã›ãšã€\n",
    "  æ¬¡ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†ã‚’ç¶šè¡Œã—ã¾ã™ã€‚\n",
    "\"\"\"\n",
    "import os\n",
    "import itertools\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import nglview as nv\n",
    "\n",
    "# ASE\n",
    "from ase.io import read, write\n",
    "from ase.build import stack,cut\n",
    "\n",
    "# Matlantis / PFP\n",
    "from matlantis_features.atoms import MatlantisAtoms\n",
    "from matlantis_features.features.common.opt import FireLBFGSASEOptFeature\n",
    "from matlantis_features.utils.calculators import pfp_estimator_fn\n",
    "from pfp_api_client.pfp.estimator import EstimatorCalcMode\n",
    "\n",
    "# --- Matlantisæœ€é©åŒ–é–¢æ•° (å¤‰æ›´ãªã—) ---\n",
    "def run_matlantis_optimization(atoms, trajectory_path, fmax=0.05, name=\"structure\"):\n",
    "    print(f\"  -> Matlantisæœ€é©åŒ–é–‹å§‹ ({name}, fmax = {fmax}) ...\")\n",
    "    matlantis_atoms = MatlantisAtoms(atoms)\n",
    "    estimator_function = pfp_estimator_fn(\n",
    "        model_version='v7.0.0', calc_mode=EstimatorCalcMode.CRYSTAL_PLUS_D3\n",
    "    )\n",
    "    position_optimizer = FireLBFGSASEOptFeature(\n",
    "        estimator_fn=estimator_function, filter=False, trajectory=str(trajectory_path),\n",
    "        n_run=5000, fmax=fmax, show_progress_bar=True\n",
    "    )\n",
    "    try:\n",
    "        result = position_optimizer(matlantis_atoms)\n",
    "        optimized_atoms = result.atoms.ase_atoms\n",
    "        final_energy = result.output.energy_log[-1]\n",
    "        print(f\"  -> âœ”ï¸ æœ€é©åŒ–å®Œäº†ï¼ ã‚¨ãƒãƒ«ã‚®ãƒ¼: {final_energy:.3f} eV\")\n",
    "        xyz_save_path = Path(trajectory_path).with_suffix('.xyz')\n",
    "        print(f\"  -> ğŸ’¾ æœ€é©åŒ–å¾Œã®ä¸­é–“æ§‹é€ ã‚’ä¿å­˜ã—ã¾ã™: {xyz_save_path.name}\")\n",
    "        write(str(xyz_save_path), optimized_atoms)\n",
    "        return optimized_atoms\n",
    "    except Exception as e:\n",
    "        print(f\"  -> âŒ æœ€é©åŒ–ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}\")\n",
    "        return None\n",
    "\n",
    "# --- STEP 2: ç•Œé¢ã®æ§‹ç¯‰ãƒ»ãƒˆãƒªãƒŸãƒ³ã‚°ãƒ»æœ€é©åŒ–ã‚¯ãƒ©ã‚¹ ---\n",
    "class InterfaceOptimizer:\n",
    "    def __init__(self, material1_filepath, material2_surfaces_dir, interfaces_dir, material2_keyword):\n",
    "        self.material1_filepath = Path(material1_filepath)\n",
    "        self.material2_surfaces_dir = Path(material2_surfaces_dir)\n",
    "        self.interfaces_dir = Path(interfaces_dir)\n",
    "        self.material2_keyword = material2_keyword\n",
    "        \n",
    "        self.interfaces_dir.mkdir(parents=True, exist_ok=True)\n",
    "        print(f\"\\n--- ç•Œé¢ æ§‹ç¯‰ãƒ»ãƒˆãƒªãƒŸãƒ³ã‚°ãƒ»æœ€é©åŒ–ãƒ—ãƒ­ã‚»ã‚¹ã‚’é–‹å§‹ ---\")\n",
    "        print(f\"   - Material 1 (æŒ‡å®š): '{self.material1_filepath.name}'\")\n",
    "        print(f\"   - Material 2 (æ¤œç´¢): '{self.material2_keyword}' ã§å§‹ã¾ã‚‹CIFãƒ•ã‚¡ã‚¤ãƒ«\")\n",
    "        print(f\"   - ä¿å­˜å…ˆ: '{self.interfaces_dir}'\")\n",
    "\n",
    "    # â˜…å¤‰æ›´ç‚¹1: æ¤œç´¢ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã®æ‹¡å¼µå­ã‚’ .cif ã«å¤‰æ›´\n",
    "    def find_and_categorize_surfaces(self):\n",
    "        print(f\"ğŸ” è¡¨é¢ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†é¡ä¸­...\")\n",
    "        \n",
    "        # --- Material 1: æŒ‡å®šã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®å­˜åœ¨ç¢ºèª ---\n",
    "        if not self.material1_filepath.exists():\n",
    "            print(f\"ğŸ›‘ ã‚¨ãƒ©ãƒ¼: æŒ‡å®šã•ã‚ŒãŸMaterial1ãƒ•ã‚¡ã‚¤ãƒ« '{self.material1_filepath}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚\")\n",
    "            surfaces1 = []\n",
    "        else:\n",
    "            print(f\"  - Material 1: 1å€‹è¦‹ã¤ã‹ã‚Šã¾ã—ãŸ -> {self.material1_filepath.name}\")\n",
    "            surfaces1 = [self.material1_filepath]\n",
    "\n",
    "        # --- Material 2: ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§ .cif ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢ ---\n",
    "        if not self.material2_surfaces_dir.is_dir():\n",
    "            print(f\"ğŸ›‘ ã‚¨ãƒ©ãƒ¼: Material2ã®è¡¨é¢ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª '{self.material2_surfaces_dir}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚\")\n",
    "            surfaces2 = []\n",
    "        else:\n",
    "            # ã“ã“ã§ *.cif ã‚’æ¤œç´¢ã™ã‚‹ã‚ˆã†ã«å¤‰æ›´\n",
    "            all_surfaces = list(self.material2_surfaces_dir.glob(\"*.cif\"))\n",
    "            surfaces2 = [p for p in all_surfaces if p.stem.startswith(self.material2_keyword)]\n",
    "            print(f\"  - {self.material2_keyword}è¡¨é¢: {len(surfaces2)}å€‹è¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚\")\n",
    "            \n",
    "        return surfaces1, surfaces2\n",
    "    \n",
    "    def build_interface(self, slab1, slab2, target_xy=(12.0, 12.0), separation=2.0):\n",
    "        print(f\"    1. ç•Œé¢ã‚’æ§‹ç¯‰ä¸­...\")\n",
    "        position1 = slab1.get_positions()\n",
    "        position2 = slab2.get_positions()\n",
    "        indices_to_delete1 = np.where((position1[:, 0] >= target_xy[0]) | (position1[:, 1] >= target_xy[1]))[0]\n",
    "        indices_to_delete2 = np.where((position2[:, 0] >= target_xy[0]) | (position2[:, 1] >= target_xy[1]))[0]\n",
    "        cut_slab1, cut_slab2 = slab1.copy(), slab2.copy()\n",
    "        if len(indices_to_delete1) > 0: del cut_slab1[indices_to_delete1]\n",
    "        if len(indices_to_delete2) > 0: del cut_slab2[indices_to_delete2]\n",
    "        z1_max = cut_slab1.positions[:, 2].max()\n",
    "        z2_min = cut_slab2.positions[:, 2].min()\n",
    "        cut_slab2.positions[:, 2] += z1_max - z2_min + separation\n",
    "        interface = cut_slab1 + cut_slab2\n",
    "        interface.cell = [12, 12, 53] # ã‚»ãƒ«ã‚µã‚¤ã‚ºã¯é©å®œèª¿æ•´ã—ã¦ãã ã•ã„\n",
    "        return interface\n",
    "\n",
    "    def trim_interface(self, atoms, thickness_per_slab=25.0):\n",
    "        print(f\"    2. ç•Œé¢ã‚’ãƒˆãƒªãƒŸãƒ³ã‚°ä¸­ (å„ã‚¹ãƒ©ãƒ–åšã¿: {thickness_per_slab} Ã…)...\")\n",
    "        al_indices = [a.index for a in atoms if a.symbol == 'Al']\n",
    "        other_indices = [a.index for a in atoms if a.symbol not in ['Al']]\n",
    "        if not al_indices or not other_indices:\n",
    "             print(\"     -> è­¦å‘Š: ç•Œé¢ã®ä¸¡å´ã«åŸå­ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€ãƒˆãƒªãƒŸãƒ³ã‚°ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚\")\n",
    "             return atoms\n",
    "        al_pos = atoms.get_positions()[al_indices]\n",
    "        other_pos = atoms.get_positions()[other_indices]\n",
    "        if np.mean(al_pos[:, 2]) < np.mean(other_pos[:, 2]):\n",
    "            interface_z = (al_pos[:, 2].max() + other_pos[:, 2].min()) / 2\n",
    "        else:\n",
    "            interface_z = (other_pos[:, 2].max() + al_pos[:, 2].min()) / 2\n",
    "        indices_to_delete = []\n",
    "        is_al_bottom = np.mean(al_pos[:, 2]) < np.mean(other_pos[:, 2])\n",
    "        for atom in atoms:\n",
    "            if is_al_bottom:\n",
    "                if atom.symbol == 'Al' and atom.z < interface_z - thickness_per_slab:\n",
    "                    indices_to_delete.append(atom.index)\n",
    "                elif atom.symbol != 'Al' and atom.z > interface_z + thickness_per_slab:\n",
    "                    indices_to_delete.append(atom.index)\n",
    "            else:\n",
    "                if atom.symbol != 'Al' and atom.z < interface_z - thickness_per_slab:\n",
    "                    indices_to_delete.append(atom.index)\n",
    "                elif atom.symbol == 'Al' and atom.z > interface_z + thickness_per_slab:\n",
    "                    indices_to_delete.append(atom.index)\n",
    "        print(f\"        -> {len(indices_to_delete)} å€‹ã®åŸå­ã‚’å‰Šé™¤ã—ã¾ã™ã€‚\")\n",
    "        if len(indices_to_delete) > 0:\n",
    "            del atoms[indices_to_delete]\n",
    "        return atoms\n",
    "\n",
    "    # â˜…å¤‰æ›´ç‚¹2: ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰ä¸è¦ãªéƒ¨åˆ†ã‚’å‰Šé™¤ã™ã‚‹å‡¦ç†ã‚’ã‚ˆã‚Šã‚·ãƒ³ãƒ—ãƒ«ã«\n",
    "    def create_trim_and_optimize(self, slab1_path, slab2_path):\n",
    "        slab1_name = slab1_path.stem \n",
    "        slab2_name = slab2_path.stem\n",
    "        interface_name = f\"Interface_{slab1_name}_on_{slab2_name}_trimmed\"\n",
    "        output_path = self.interfaces_dir / f\"{interface_name}.cif\"\n",
    "        if output_path.exists():\n",
    "            print(f\"âœ… æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚ã‚Šã€ã‚¹ã‚­ãƒƒãƒ—: {output_path.name}\")\n",
    "            return\n",
    "        print(f\"\\n--- å‡¦ç†é–‹å§‹: {slab1_name} + {slab2_name} ---\")\n",
    "        try:\n",
    "            slab1, slab2 = read(str(slab1_path)), read(str(slab2_path))\n",
    "            interface_built = self.build_interface(slab1, slab2)\n",
    "            interface_trimmed = self.trim_interface(interface_built, thickness_per_slab=25.0)\n",
    "            if interface_trimmed is None:\n",
    "                print(\"    -> âŒ ãƒˆãƒªãƒŸãƒ³ã‚°ã«å¤±æ•—ã—ãŸãŸã‚ã€ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚\")\n",
    "                return\n",
    "            print(f\"    3. ãƒˆãƒªãƒŸãƒ³ã‚°å¾Œã®æ§‹é€ ã‚’æœ€é©åŒ–ä¸­...\")\n",
    "            traj_path = self.interfaces_dir / f\"{interface_name}.traj\"\n",
    "            optimized_structure = run_matlantis_optimization(interface_trimmed, traj_path, fmax=0.05, name=interface_name)\n",
    "            if optimized_structure:\n",
    "                optimized_structure.center(vacuum=15.0, axis=2)\n",
    "                optimized_structure.pbc = (True, True, False)\n",
    "                print(f\"    4. æœ€çµ‚æ§‹é€ ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ä¸­ -> {output_path.name}\")\n",
    "                write(str(output_path), optimized_structure)\n",
    "            else:\n",
    "                print(\"    -> âŒ æœ€é©åŒ–ã«å¤±æ•—ã—ãŸãŸã‚ã€ãƒ•ã‚¡ã‚¤ãƒ«ã¯ä¿å­˜ã•ã‚Œã¾ã›ã‚“ã€‚\")\n",
    "        except Exception as e:\n",
    "            print(f\"  -> âŒ ã“ã®ç•Œé¢ã®ä½œæˆä¸­ã«é‡å¤§ãªã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}\")\n",
    "\n",
    "    def run(self):\n",
    "        slabs1, slabs2 = self.find_and_categorize_surfaces()\n",
    "        if not slabs1 or not slabs2:\n",
    "            print(f\" -> Material 1ã®ãƒ•ã‚¡ã‚¤ãƒ«ã€ã¾ãŸã¯Material 2ã®è¡¨é¢ãƒ•ã‚¡ã‚¤ãƒ«ãŒä¸è¶³ã—ã¦ã„ã‚‹ãŸã‚ã€å‡¦ç†ã‚’çµ‚äº†ã—ã¾ã™ã€‚\")\n",
    "            return\n",
    "        print(f\"\\n--- {self.material1_filepath.stem}/{self.material2_keyword}ç•Œé¢ã®çµ„ã¿åˆã‚ã›å‡¦ç†ã‚’é–‹å§‹ ---\")\n",
    "        for slab1_path in slabs1:\n",
    "            for slab2_path in slabs2:\n",
    "                self.create_trim_and_optimize(slab1_path, slab2_path)\n",
    "        print(\"\\nâœ¨ å…¨ã¦ã®å‡¦ç†ãŒå®Œäº†ã€‚\")\n",
    "\n",
    "# --- çµæœè¡¨ç¤ºé–¢æ•° (å¤‰æ›´ãªã—) ---\n",
    "def show_results_viewer(results_dir):\n",
    "    print(f\"\\n--- ğŸ”¬ çµæœãƒ“ãƒ¥ãƒ¼ãƒ¯ãƒ¼: '{results_dir}' ---\")\n",
    "    files = sorted(list(Path(results_dir).glob(\"*.cif\")))\n",
    "    if not files:\n",
    "        print(\"è¡¨ç¤ºã§ãã‚‹æ§‹é€ ãŒã‚ã‚Šã¾ã›ã‚“ã€‚\")\n",
    "        return\n",
    "    options = {\"-- é¸æŠã—ã¦ãã ã•ã„ --\": None}\n",
    "    options.update({p.name: p for p in files})\n",
    "    widgets.interact(\n",
    "        lambda file_path: display(nv.show_ase(read(file_path)) if file_path else None),\n",
    "        file_path=widgets.Dropdown(options=options, description='Interface:', layout={'width': 'max-content'})\n",
    "    )\n",
    "\n",
    "# --- ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œéƒ¨ ---\n",
    "if __name__ == \"__main__\":\n",
    "    # ===== è¨­å®šé …ç›® =====\n",
    "    # 1. Material 1 ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’ç›´æ¥æŒ‡å®š\n",
    "    MATERIAL1_FILE_PATH = \"/home/jovyan/Kaori/MD/LiB_2/Al555.xyz\"\n",
    "    \n",
    "    # â˜…å¤‰æ›´ç‚¹3: Material 2 ã®CIFãƒ•ã‚¡ã‚¤ãƒ«ãŒå…¥ã£ã¦ã„ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹ã‚’æ›´æ–°\n",
    "    MATERIAL2_SURFACES_DIR = \"/home/jovyan/Kaori/MD/LiB_2/structure/output/cif_files/cif_file\"\n",
    "    \n",
    "    # 3. Material 2 ã‚’è¦‹ã¤ã‘ã‚‹ãŸã‚ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ (ãƒ•ã‚¡ã‚¤ãƒ«åã®å…ˆé ­éƒ¨åˆ†)\n",
    "    MATERIAL2_KEYWORD = \"NMC_\"\n",
    "    \n",
    "    # 4. ä½œæˆã—ãŸç•Œé¢æ§‹é€ ã®ä¿å­˜å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª\n",
    "    INTERFACES_DIR = \"/home/jovyan/Kaori/MD/LiB_2/structure/output/final_interfaces_Al555_vs_NMC\"\n",
    "    # ====================\n",
    "\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    # STEP 1ã®Trajectoryãƒ•ã‚¡ã‚¤ãƒ«æ•´ç†ã¯ä¸è¦ãªãŸã‚ã€å‘¼ã³å‡ºã—ã¾ã›ã‚“ã€‚\n",
    "\n",
    "    # STEP 2: ç•Œé¢ã®æ§‹ç¯‰ã€ãƒˆãƒªãƒŸãƒ³ã‚°ã€æœ€é©åŒ–ã‚’ä¸€æ‹¬å®Ÿè¡Œ\n",
    "    interface_opt = InterfaceOptimizer(\n",
    "        material1_filepath=MATERIAL1_FILE_PATH,\n",
    "        material2_surfaces_dir=MATERIAL2_SURFACES_DIR,\n",
    "        interfaces_dir=INTERFACES_DIR,\n",
    "        material2_keyword=MATERIAL2_KEYWORD\n",
    "    )\n",
    "    interface_opt.run()\n",
    "\n",
    "    print(\"\\n\\nâœ¨ å…¨ã¦ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãŒå®Œäº†ã—ã¾ã—ãŸã€‚ âœ¨\")\n",
    "\n",
    "    # çµæœã®è¡¨ç¤º\n",
    "    show_results_viewer(INTERFACES_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba9ab056-a942-415f-a777-e6d278b4ca8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cell([14.142135623730951, 14.142135623730951, 0.0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pfcc_extras import show_gui, view_ngl\n",
    "from ase.io import Trajectory,read,write\n",
    "import os\n",
    "import itertools\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import nglview as nv\n",
    "\n",
    "# ASE\n",
    "from ase.io import read, write\n",
    "from ase.build import stack,cut,bulk,fcc100\n",
    "\n",
    "atoms = fcc100(\"Al\",size = (5, 5, 10),a=4.0)\n",
    "# show_gui(atoms)\n",
    "# write(\"/home/jovyan/Kaori/MD/LiB_2/Al555.xyz\",atoms)\n",
    "atoms.cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa51b7c9-f44c-4b67-b2ee-e3190876c5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STEP 1: Trajectoryãƒ•ã‚¡ã‚¤ãƒ«ã®æ•´ç†ã¯ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ ---\n",
      "\n",
      "--- STEP 2: ç•Œé¢ æ§‹ç¯‰ãƒ»ãƒˆãƒªãƒŸãƒ³ã‚°ãƒ»æœ€é©åŒ–ãƒ—ãƒ­ã‚»ã‚¹ã‚’é–‹å§‹ ---\n",
      "âœ… æœ€çµ‚æ§‹é€ ã®ä¿å­˜å…ˆ: '/home/jovyan/Kaori/MD/LiB_2/structure/output/final_interfaces2'\n",
      "ğŸ” '/home/jovyan/Kaori/MD/LiB_2/structure/output' ã‹ã‚‰æ­£æ¥µæè¡¨é¢ (*_final.xyz) ã‚’åˆ†é¡ä¸­...\n",
      "... æŒ‡å®šã•ã‚ŒãŸAlå´ãƒ•ã‚¡ã‚¤ãƒ« (AlF3, Al2O3) ã®ã¿å¯¾è±¡ã¨ã—ã¾ã™...\n",
      "  -> âœ… å¯¾è±¡ã«è¿½åŠ : Al555.xyz\n",
      "  - Alè¡¨é¢ (æŒ‡å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿): 1å€‹,  æ­£æ¥µæè¡¨é¢: 0å€‹\n",
      " -> Alè¡¨é¢ã¾ãŸã¯æ­£æ¥µæè¡¨é¢ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒä¸è¶³ã—ã¦ã„ã‚‹ãŸã‚ã€ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚\n",
      "\n",
      "\n",
      "âœ¨ å…¨ã¦ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãŒå®Œäº†ã—ã¾ã—ãŸã€‚ âœ¨\n",
      "\n",
      "--- ğŸ”¬ çµæœãƒ“ãƒ¥ãƒ¼ãƒ¯ãƒ¼: '/home/jovyan/Kaori/MD/LiB_2/structure/output/final_interfaces2' ---\n",
      "è¡¨ç¤ºã§ãã‚‹æ§‹é€ ãŒã‚ã‚Šã¾ã›ã‚“ã€‚\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Trajectoryãƒ•ã‚¡ã‚¤ãƒ«ã®æ•´ç†ã¨ã€ãã‚Œã«åŸºã¥ãç•Œé¢æ§‹ç¯‰ãƒ»æœ€é©åŒ–ã‚’è‡ªå‹•åŒ–ã™ã‚‹ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã€‚\n",
    "\n",
    "[è¿½åŠ å®Ÿè¡Œç‰ˆ]\n",
    "- AlF3ã¨Al2O3ã®ã¿ã‚’Alå´è¡¨é¢ã¨ã—ã¦æ‰±ã„ã€è¿½åŠ ã§ç•Œé¢æ§‹ç¯‰ã¨æœ€é©åŒ–ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚\n",
    "- STEP1ã®Trajectoryãƒ•ã‚¡ã‚¤ãƒ«æ•´ç†ã¯ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚\n",
    "\"\"\"\n",
    "import os\n",
    "import itertools\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import nglview as nv\n",
    "\n",
    "# ASE\n",
    "from ase.io import read, write\n",
    "from ase.build import stack,cut\n",
    "\n",
    "# Matlantis / PFP\n",
    "from matlantis_features.atoms import MatlantisAtoms\n",
    "from matlantis_features.features.common.opt import FireLBFGSASEOptFeature\n",
    "from matlantis_features.utils.calculators import pfp_estimator_fn\n",
    "from pfp_api_client.pfp.estimator import EstimatorCalcMode\n",
    "\n",
    "# --- STEP 1: Trajectoryãƒ•ã‚¡ã‚¤ãƒ«ã®æ•´ç†ã‚¯ãƒ©ã‚¹ (ä»Šå›ã¯ä½¿ç”¨ã—ãªã„) ---\n",
    "class TrajectoryCleanup:\n",
    "    def __init__(self, directory):\n",
    "        print(\"--- STEP 1: Trajectoryãƒ•ã‚¡ã‚¤ãƒ«ã®åˆ†æã¨æ•´ç† (ã‚¹ã‚­ãƒƒãƒ—) ---\")\n",
    "    def run(self):\n",
    "        pass\n",
    "\n",
    "# --- Matlantisæœ€é©åŒ–é–¢æ•° (å…±é€š) ---\n",
    "\n",
    "def run_matlantis_optimization(atoms, trajectory_path, fmax=0.05, name=\"structure\"):\n",
    "    print(f\"  -> Matlantisæœ€é©åŒ–é–‹å§‹ ({name}, fmax = {fmax}) ...\")\n",
    "    matlantis_atoms = MatlantisAtoms(atoms)\n",
    "    estimator_function = pfp_estimator_fn(\n",
    "        model_version='v7.0.0', calc_mode=EstimatorCalcMode.CRYSTAL_PLUS_D3\n",
    "    )\n",
    "    position_optimizer = FireLBFGSASEOptFeature(\n",
    "        estimator_fn=estimator_function, filter=False, trajectory=str(trajectory_path),\n",
    "        n_run=5000, fmax=fmax, show_progress_bar=True\n",
    "    )\n",
    "    try:\n",
    "        result = position_optimizer(matlantis_atoms)\n",
    "        optimized_atoms = result.atoms.ase_atoms\n",
    "        final_energy = result.output.energy_log[-1]\n",
    "        print(f\"  -> âœ”ï¸ æœ€é©åŒ–å®Œäº†ï¼ ã‚¨ãƒãƒ«ã‚®ãƒ¼: {final_energy:.3f} eV\")\n",
    "        xyz_save_path = Path(trajectory_path).with_suffix('.xyz')\n",
    "        print(f\"  -> ğŸ’¾ æœ€é©åŒ–å¾Œã®ä¸­é–“æ§‹é€ ã‚’ä¿å­˜ã—ã¾ã™: {xyz_save_path.name}\")\n",
    "        write(str(xyz_save_path), optimized_atoms)\n",
    "        return optimized_atoms\n",
    "    except Exception as e:\n",
    "        print(f\"  -> âŒ æœ€é©åŒ–ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}\")\n",
    "        return None\n",
    "\n",
    "# --- STEP 2: ç•Œé¢ã®æ§‹ç¯‰ãƒ»ãƒˆãƒªãƒŸãƒ³ã‚°ãƒ»æœ€é©åŒ–ã‚¯ãƒ©ã‚¹ ---\n",
    "class InterfaceOptimizer:\n",
    "    def __init__(self, surfaces_dir, interfaces_dir):\n",
    "        self.surfaces_dir = Path(surfaces_dir)\n",
    "        self.interfaces_dir = Path(interfaces_dir)\n",
    "        self.interfaces_dir.mkdir(parents=True, exist_ok=True)\n",
    "        print(f\"\\n--- STEP 2: ç•Œé¢ æ§‹ç¯‰ãƒ»ãƒˆãƒªãƒŸãƒ³ã‚°ãƒ»æœ€é©åŒ–ãƒ—ãƒ­ã‚»ã‚¹ã‚’é–‹å§‹ ---\")\n",
    "        print(f\"âœ… æœ€çµ‚æ§‹é€ ã®ä¿å­˜å…ˆ: '{self.interfaces_dir}'\")\n",
    "\n",
    "    def find_and_categorize_surfaces(self):\n",
    "        \"\"\"\n",
    "        [å¤‰æ›´] æŒ‡å®šã•ã‚ŒãŸAlF3ã¨Al2O3ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ã‚’Alå´ã¨ã—ã¦å–å¾—ã—ã€\n",
    "               æ­£æ¥µå´ãƒ•ã‚¡ã‚¤ãƒ«ã¯å¾“æ¥é€šã‚Šæ¤œç´¢ã™ã‚‹ã€‚\n",
    "        \"\"\"\n",
    "        print(f\"ğŸ” '{self.surfaces_dir}' ã‹ã‚‰æ­£æ¥µæè¡¨é¢ (*_final.xyz) ã‚’åˆ†é¡ä¸­...\")\n",
    "        if not self.surfaces_dir.is_dir():\n",
    "            print(f\"ğŸ›‘ ã‚¨ãƒ©ãƒ¼: è¡¨é¢ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª '{self.surfaces_dir}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚\")\n",
    "            return [], []\n",
    "\n",
    "        # æ­£æ¥µæãƒ•ã‚¡ã‚¤ãƒ«ã¯å¾“æ¥é€šã‚Šæ¤œç´¢\n",
    "        all_surfaces = list(self.surfaces_dir.glob(\"*_final.xyz\"))\n",
    "        cathode_surfaces = [p for p in all_surfaces if \"NMC\" in p.stem]\n",
    "\n",
    "        # ===== ã“ã“ã‹ã‚‰ãŒå¤‰æ›´ç‚¹ =====\n",
    "        # Alå´ã¯æŒ‡å®šã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ã«é™å®š\n",
    "        print(\"... æŒ‡å®šã•ã‚ŒãŸAlå´ãƒ•ã‚¡ã‚¤ãƒ« (AlF3, Al2O3) ã®ã¿å¯¾è±¡ã¨ã—ã¾ã™...\")\n",
    "        al_surfaces = []\n",
    "        additional_al_files_paths = [\n",
    "            Path(\"/home/jovyan/Kaori/MD/LiB_2/Al555.xyz\")\n",
    "            # Path(\"/home/jovyan/Kaori/MD/LiB_2/AlF3_only.xyz\"),\n",
    "            # Path(\"/home/jovyan/Kaori/MD/LiB_2/Al2O3_only.xyz\")\n",
    "        ]\n",
    "        \n",
    "        for file_path in additional_al_files_paths:\n",
    "            if file_path.exists():\n",
    "                al_surfaces.append(file_path)\n",
    "                print(f\"  -> âœ… å¯¾è±¡ã«è¿½åŠ : {file_path.name}\")\n",
    "            else:\n",
    "                print(f\"  -> âš ï¸  è­¦å‘Š: æŒ‡å®šã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_path}\")\n",
    "        # ===== å¤‰æ›´ç‚¹ã“ã“ã¾ã§ =====\n",
    "\n",
    "        print(f\"  - Alè¡¨é¢ (æŒ‡å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿): {len(al_surfaces)}å€‹,  æ­£æ¥µæè¡¨é¢: {len(cathode_surfaces)}å€‹\")\n",
    "        return al_surfaces, cathode_surfaces\n",
    "\n",
    "    def build_interface(self, slab1, slab2, target_xy=(12.0, 12.0), separation=2.0):\n",
    "        print(f\"    1. ç•Œé¢ã‚’æ§‹ç¯‰ä¸­...\")\n",
    "        position1 = slab1.get_positions()\n",
    "        position2 = slab2.get_positions()\n",
    "        indices_to_delete1 = np.where((position1[:, 0] >= target_xy[0]) | (position1[:, 1] >= target_xy[1]))[0]\n",
    "        indices_to_delete2 = np.where((position2[:, 0] >= target_xy[0]) | (position2[:, 1] >= target_xy[1]))[0]\n",
    "        cut_slab1, cut_slab2 = slab1.copy(), slab2.copy()\n",
    "        if len(indices_to_delete1) > 0: del cut_slab1[indices_to_delete1]\n",
    "        if len(indices_to_delete2) > 0: del cut_slab2[indices_to_delete2]\n",
    "        z1_max = cut_slab1.positions[:, 2].max()\n",
    "        z2_min = cut_slab2.positions[:, 2].min()\n",
    "        cut_slab2.positions[:, 2] += z1_max - z2_min + separation\n",
    "        interface = cut_slab1 + cut_slab2\n",
    "        interface.cell = [12, 12, 53]\n",
    "        return interface\n",
    "\n",
    "    def trim_interface(self, atoms, thickness_per_slab=25.0):\n",
    "        print(f\"    2. ç•Œé¢ã‚’ãƒˆãƒªãƒŸãƒ³ã‚°ä¸­ (å„ã‚¹ãƒ©ãƒ–åšã¿: {thickness_per_slab} Ã…)...\")\n",
    "        al_indices = [a.index for a in atoms if a.symbol in ['Al', 'F']] # Alã¨Fã‚’Alå´ã¨ã¿ãªã™\n",
    "        nmc_indices = [a.index for a in atoms if a.symbol not in ['Al', 'F']]\n",
    "        if not al_indices or not nmc_indices:\n",
    "            print(\"     -> è­¦å‘Š: Alå´ã¾ãŸã¯NMCå´ã®åŸå­ãŒè¦‹ã¤ã‹ã‚‰ãšã€ãƒˆãƒªãƒŸãƒ³ã‚°ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚\")\n",
    "            return atoms\n",
    "\n",
    "        al_pos = atoms.get_positions()[al_indices]\n",
    "        nmc_pos = atoms.get_positions()[nmc_indices]\n",
    "        \n",
    "        if np.mean(al_pos[:, 2]) < np.mean(nmc_pos[:, 2]):\n",
    "            interface_z = (al_pos[:, 2].max() + nmc_pos[:, 2].min()) / 2\n",
    "            is_al_bottom = True\n",
    "        else:\n",
    "            interface_z = (nmc_pos[:, 2].max() + al_pos[:, 2].min()) / 2\n",
    "            is_al_bottom = False\n",
    "\n",
    "        indices_to_delete = []\n",
    "        for atom in atoms:\n",
    "            is_al_side = atom.symbol in ['Al', 'F']\n",
    "            if is_al_bottom:\n",
    "                if is_al_side and atom.z < interface_z - thickness_per_slab:\n",
    "                    indices_to_delete.append(atom.index)\n",
    "                elif not is_al_side and atom.z > interface_z + thickness_per_slab:\n",
    "                    indices_to_delete.append(atom.index)\n",
    "            else:\n",
    "                if not is_al_side and atom.z < interface_z - thickness_per_slab:\n",
    "                    indices_to_delete.append(atom.index)\n",
    "                elif is_al_side and atom.z > interface_z + thickness_per_slab:\n",
    "                    indices_to_delete.append(atom.index)\n",
    "\n",
    "        print(f\"        -> {len(indices_to_delete)} å€‹ã®åŸå­ã‚’å‰Šé™¤ã—ã¾ã™ã€‚\")\n",
    "        if len(indices_to_delete) > 0:\n",
    "            del atoms[indices_to_delete]\n",
    "        return atoms\n",
    "\n",
    "    def create_trim_and_optimize(self, slab1_path, slab2_path):\n",
    "        slab1_name = slab1_path.stem.replace('_pos_opt_final', '').replace('_cell_opt_final', '')\n",
    "        slab2_name = slab2_path.stem.replace('_pos_opt_final', '').replace('_cell_opt_final', '')\n",
    "        interface_name = f\"Interface_{slab1_name}_on_{slab2_name}_trimmed\"\n",
    "        output_path = self.interfaces_dir / f\"{interface_name}.cif\"\n",
    "\n",
    "        if output_path.exists():\n",
    "            print(f\"âœ… æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚ã‚Šã€ã‚¹ã‚­ãƒƒãƒ—: {output_path.name}\")\n",
    "            return\n",
    "\n",
    "        print(f\"\\n--- å‡¦ç†é–‹å§‹: {slab1_name} + {slab2_name} ---\")\n",
    "        try:\n",
    "            slab1, slab2 = read(str(slab1_path)), read(str(slab2_path))\n",
    "            interface_built = self.build_interface(slab1, slab2)\n",
    "            interface_trimmed = self.trim_interface(interface_built, thickness_per_slab=25.0)\n",
    "            if interface_trimmed is None:\n",
    "                print(\"    -> âŒ ãƒˆãƒªãƒŸãƒ³ã‚°ã«å¤±æ•—ã—ãŸãŸã‚ã€ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚\")\n",
    "                return\n",
    "\n",
    "            print(f\"    3. ãƒˆãƒªãƒŸãƒ³ã‚°å¾Œã®æ§‹é€ ã‚’æœ€é©åŒ–ä¸­...\")\n",
    "            traj_path = self.interfaces_dir / f\"{interface_name}.traj\"\n",
    "            optimized_structure = run_matlantis_optimization(interface_trimmed, traj_path, fmax=0.05, name=interface_name)\n",
    "\n",
    "            if optimized_structure:\n",
    "                optimized_structure.center(vacuum=15.0, axis=2)\n",
    "                optimized_structure.pbc = (True, True, False)\n",
    "                print(f\"    4. æœ€çµ‚æ§‹é€ ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ä¸­ -> {output_path.name}\")\n",
    "                write(str(output_path), optimized_structure)\n",
    "            else:\n",
    "                print(\"    -> âŒ æœ€é©åŒ–ã«å¤±æ•—ã—ãŸãŸã‚ã€ãƒ•ã‚¡ã‚¤ãƒ«ã¯ä¿å­˜ã•ã‚Œã¾ã›ã‚“ã€‚\")\n",
    "        except Exception as e:\n",
    "            print(f\"  -> âŒ ã“ã®ç•Œé¢ã®ä½œæˆä¸­ã«é‡å¤§ãªã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}\")\n",
    "\n",
    "    def run(self):\n",
    "        al_slabs, cathode_slabs = self.find_and_categorize_surfaces()\n",
    "        if not al_slabs or not cathode_slabs:\n",
    "            print(\" -> Alè¡¨é¢ã¾ãŸã¯æ­£æ¥µæè¡¨é¢ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒä¸è¶³ã—ã¦ã„ã‚‹ãŸã‚ã€ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚\")\n",
    "            return\n",
    "\n",
    "        print(\"\\n--- Al/NMCç•Œé¢ã®çµ„ã¿åˆã‚ã›å‡¦ç†ã‚’é–‹å§‹ ---\")\n",
    "        for al_path in al_slabs:\n",
    "            for cathode_path in cathode_slabs:\n",
    "                self.create_trim_and_optimize(al_path, cathode_path)\n",
    "        print(\"\\nâœ¨ STEP 2 å…¨ã¦ã®å‡¦ç†ãŒå®Œäº†ã€‚\")\n",
    "\n",
    "def show_results_viewer(results_dir):\n",
    "    print(f\"\\n--- ğŸ”¬ çµæœãƒ“ãƒ¥ãƒ¼ãƒ¯ãƒ¼: '{results_dir}' ---\")\n",
    "    files = sorted(list(Path(results_dir).glob(\"*.cif\")))\n",
    "    if not files:\n",
    "        print(\"è¡¨ç¤ºã§ãã‚‹æ§‹é€ ãŒã‚ã‚Šã¾ã›ã‚“ã€‚\")\n",
    "        return\n",
    "    \n",
    "    options = {\"-- é¸æŠã—ã¦ãã ã•ã„ --\": None}\n",
    "    options.update({p.name: str(p) for p in files})\n",
    "\n",
    "    def view_structure(file_path):\n",
    "        if file_path:\n",
    "            try:\n",
    "                atoms = read(file_path)\n",
    "                view = nv.show_ase(atoms)\n",
    "                display(view)\n",
    "            except Exception as e:\n",
    "                print(f\"ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã¾ãŸã¯è¡¨ç¤ºä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}\")\n",
    "\n",
    "    widgets.interact(\n",
    "        view_structure,\n",
    "        file_path=widgets.Dropdown(options=options, description='Interface:', layout={'width': 'max-content'})\n",
    "    )\n",
    "\n",
    "# --- ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œéƒ¨ ---\n",
    "if __name__ == \"__main__\":\n",
    "    # ===== è¨­å®šé …ç›® =====\n",
    "    OPTIMIZATION_OUTPUT_DIR = \"/home/jovyan/Kaori/MD/LiB_2/structure/output\"\n",
    "    INTERFACES_DIR = \"/home/jovyan/Kaori/MD/LiB_2/structure/output/final_interfaces2\"\n",
    "    # ====================\n",
    "\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    # ===== å¤‰æ›´ç‚¹ =====\n",
    "    # STEP 1: ä»Šå›ã¯ä¸è¦ãªãŸã‚å®Ÿè¡Œã—ãªã„\n",
    "    print(\"--- STEP 1: Trajectoryãƒ•ã‚¡ã‚¤ãƒ«ã®æ•´ç†ã¯ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ ---\")\n",
    "    # cleanup = TrajectoryCleanup(OPTIMIZATION_OUTPUT_DIR)\n",
    "    # cleanup.run()\n",
    "    # =================\n",
    "\n",
    "    # STEP 2: ç•Œé¢ã®æ§‹ç¯‰ã€ãƒˆãƒªãƒŸãƒ³ã‚°ã€æœ€é©åŒ–ã‚’ä¸€æ‹¬å®Ÿè¡Œ\n",
    "    interface_opt = InterfaceOptimizer(surfaces_dir=OPTIMIZATION_OUTPUT_DIR, interfaces_dir=INTERFACES_DIR)\n",
    "    interface_opt.run()\n",
    "\n",
    "    print(\"\\n\\nâœ¨ å…¨ã¦ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãŒå®Œäº†ã—ã¾ã—ãŸã€‚ âœ¨\")\n",
    "\n",
    "    # çµæœã®è¡¨ç¤º\n",
    "    show_results_viewer(INTERFACES_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f708b24f-b1f9-4d83-a70f-946cce8bd203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, http://pypi.artifact.svc:8080/simple\n",
      "Collecting pfp-api-client\n",
      "  Using cached pfp_api_client-1.24.0-py3-none-any.whl\n",
      "Collecting ase<4.0.0,>=3.21.1 (from pfp-api-client)\n",
      "  Using cached ase-3.26.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting numpy<2.0.0,>=1.20.3 (from pfp-api-client)\n",
      "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting grpcio<2.0.0,>=1.70.0 (from pfp-api-client)\n",
      "  Using cached grpcio-1.75.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.7 kB)\n",
      "Collecting protobuf<6.0.0,>=5.29.0 (from pfp-api-client)\n",
      "  Using cached protobuf-5.29.5-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Collecting googleapis-common-protos<2.0.0,>=1.60.0 (from pfp-api-client)\n",
      "  Using cached googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting scipy>=1.6.0 (from ase<4.0.0,>=3.21.1->pfp-api-client)\n",
      "  Using cached scipy-1.16.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (62 kB)\n",
      "Collecting matplotlib>=3.3.4 (from ase<4.0.0,>=3.21.1->pfp-api-client)\n",
      "  Downloading matplotlib-3.10.7-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
      "Collecting typing-extensions~=4.12 (from grpcio<2.0.0,>=1.70.0->pfp-api-client)\n",
      "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib>=3.3.4->ase<4.0.0,>=3.21.1->pfp-api-client)\n",
      "  Using cached contourpy-1.3.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib>=3.3.4->ase<4.0.0,>=3.21.1->pfp-api-client)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib>=3.3.4->ase<4.0.0,>=3.21.1->pfp-api-client)\n",
      "  Downloading fonttools-4.60.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (112 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib>=3.3.4->ase<4.0.0,>=3.21.1->pfp-api-client)\n",
      "  Using cached kiwisolver-1.4.9-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.3 kB)\n",
      "Collecting packaging>=20.0 (from matplotlib>=3.3.4->ase<4.0.0,>=3.21.1->pfp-api-client)\n",
      "  Using cached packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting pillow>=8 (from matplotlib>=3.3.4->ase<4.0.0,>=3.21.1->pfp-api-client)\n",
      "  Using cached pillow-11.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (9.0 kB)\n",
      "Collecting pyparsing>=3 (from matplotlib>=3.3.4->ase<4.0.0,>=3.21.1->pfp-api-client)\n",
      "  Using cached pyparsing-3.2.5-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting python-dateutil>=2.7 (from matplotlib>=3.3.4->ase<4.0.0,>=3.21.1->pfp-api-client)\n",
      "  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting six>=1.5 (from python-dateutil>=2.7->matplotlib>=3.3.4->ase<4.0.0,>=3.21.1->pfp-api-client)\n",
      "  Using cached six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Using cached ase-3.26.0-py3-none-any.whl (2.9 MB)\n",
      "Using cached googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
      "Using cached grpcio-1.75.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (6.5 MB)\n",
      "Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
      "Using cached protobuf-5.29.5-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
      "Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Downloading matplotlib-3.10.7-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m145.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached contourpy-1.3.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (355 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.60.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (5.0 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m166.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached kiwisolver-1.4.9-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.4 MB)\n",
      "Using cached packaging-25.0-py3-none-any.whl (66 kB)\n",
      "Using cached pillow-11.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\n",
      "Using cached pyparsing-3.2.5-py3-none-any.whl (113 kB)\n",
      "Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "Using cached scipy-1.16.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.9 MB)\n",
      "Using cached six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
      "Installing collected packages: typing-extensions, six, pyparsing, protobuf, pillow, packaging, numpy, kiwisolver, fonttools, cycler, scipy, python-dateutil, grpcio, googleapis-common-protos, contourpy, matplotlib, ase, pfp-api-client\n",
      "\u001b[2K  Attempting uninstall: typing-extensions\n",
      "\u001b[2K    Found existing installation: typing_extensions 4.12.2\n",
      "\u001b[2K    Not uninstalling typing-extensions at /usr/local/pyenv/versions/3.11.11/envs/python311/lib/python3.11/site-packages, outside environment /home/jovyan/.py311\n",
      "\u001b[2K    Can't uninstall 'typing_extensions'. No files were found to uninstall.\n",
      "\u001b[2K  Attempting uninstall: six\n",
      "\u001b[2K    Found existing installation: six 1.17.0\n",
      "\u001b[2K    Not uninstalling six at /usr/local/pyenv/versions/3.11.11/envs/python311/lib/python3.11/site-packages, outside environment /home/jovyan/.py311\n",
      "\u001b[2K    Can't uninstall 'six'. No files were found to uninstall.\n",
      "\u001b[2K  Attempting uninstall: pyparsing\n",
      "\u001b[2K    Found existing installation: pyparsing 3.2.1\n",
      "\u001b[2K    Uninstalling pyparsing-3.2.1:â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 2/18\u001b[0m [pyparsing]\n",
      "\u001b[2K      Successfully uninstalled pyparsing-3.2.1â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 2/18\u001b[0m [pyparsing]\n",
      "\u001b[2K  Attempting uninstall: protobufâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 2/18\u001b[0m [pyparsing]\n",
      "\u001b[2K    Found existing installation: protobuf 5.29.4â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 2/18\u001b[0m [pyparsing]\n",
      "\u001b[2K    Uninstalling protobuf-5.29.4:â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 2/18\u001b[0m [pyparsing]\n",
      "\u001b[2K      Successfully uninstalled protobuf-5.29.4â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 2/18\u001b[0m [pyparsing]\n",
      "\u001b[2K  Attempting uninstall: pillow90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 3/18\u001b[0m [protobuf]\n",
      "\u001b[2K    Found existing installation: pillow 11.1.0â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 3/18\u001b[0m [protobuf]\n",
      "\u001b[2K    Uninstalling pillow-11.1.0:[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 4/18\u001b[0m [pillow]\n",
      "\u001b[2K      Successfully uninstalled pillow-11.1.0â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 4/18\u001b[0m [pillow]\n",
      "\u001b[2K  Attempting uninstall: packaging0mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 4/18\u001b[0m [pillow]\n",
      "\u001b[2K    Found existing installation: packaging 24.2â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 4/18\u001b[0m [pillow]\n",
      "\u001b[2K    Not uninstalling packaging at /usr/local/pyenv/versions/3.11.11/envs/python311/lib/python3.11/site-packages, outside environment /home/jovyan/.py311\n",
      "\u001b[2K    Can't uninstall 'packaging'. No files were found to uninstall. \u001b[32m 4/18\u001b[0m [pillow]\n",
      "\u001b[2K  Attempting uninstall: numpy\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 5/18\u001b[0m [packaging]\n",
      "\u001b[2K    Found existing installation: numpy 1.26.4â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 5/18\u001b[0m [packaging]\n",
      "\u001b[2K    Uninstalling numpy-1.26.4:[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 5/18\u001b[0m [packaging]\n",
      "\u001b[2K      Successfully uninstalled numpy-1.26.4â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 5/18\u001b[0m [packaging]\n",
      "\u001b[2K  Attempting uninstall: kiwisolverm\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 6/18\u001b[0m [numpy]\n",
      "\u001b[2K    Found existing installation: kiwisolver 1.4.8â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 6/18\u001b[0m [numpy]\n",
      "\u001b[2K    Uninstalling kiwisolver-1.4.8:0mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 6/18\u001b[0m [numpy]\n",
      "\u001b[2K      Successfully uninstalled kiwisolver-1.4.8â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 6/18\u001b[0m [numpy]\n",
      "\u001b[2K  Attempting uninstall: fonttools90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 6/18\u001b[0m [numpy]\n",
      "\u001b[2K    Found existing installation: fonttools 4.56.0â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 6/18\u001b[0m [numpy]\n",
      "\u001b[2K    Uninstalling fonttools-4.56.0:â•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 8/18\u001b[0m [fonttools]\n",
      "\u001b[2K      Successfully uninstalled fonttools-4.56.0â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 8/18\u001b[0m [fonttools]\n",
      "\u001b[2K  Attempting uninstall: cycler[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 8/18\u001b[0m [fonttools]\n",
      "\u001b[2K    Found existing installation: cycler 0.12.1â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 8/18\u001b[0m [fonttools]\n",
      "\u001b[2K    Uninstalling cycler-0.12.1:\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 8/18\u001b[0m [fonttools]\n",
      "\u001b[2K      Successfully uninstalled cycler-0.12.1â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 8/18\u001b[0m [fonttools]\n",
      "\u001b[2K  Attempting uninstall: scipy[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 9/18\u001b[0m [cycler]\n",
      "\u001b[2K    Found existing installation: scipy 1.15.2â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 9/18\u001b[0m [cycler]\n",
      "\u001b[2K    Uninstalling scipy-1.15.2:90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 9/18\u001b[0m [cycler]\n",
      "\u001b[2K      Successfully uninstalled scipy-1.15.2m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10/18\u001b[0m [scipy]\n",
      "\u001b[2K  Attempting uninstall: python-dateutilâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10/18\u001b[0m [scipy]\n",
      "\u001b[2K    Found existing installation: python-dateutil 2.9.0.post0â”â”\u001b[0m \u001b[32m10/18\u001b[0m [scipy]\n",
      "\u001b[2K    Not uninstalling python-dateutil at /usr/local/pyenv/versions/3.11.11/envs/python311/lib/python3.11/site-packages, outside environment /home/jovyan/.py311\n",
      "\u001b[2K    Can't uninstall 'python-dateutil'. No files were found to uninstall.10/18\u001b[0m [scipy]\n",
      "\u001b[2K  Attempting uninstall: grpcioâ”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11/18\u001b[0m [python-dateutil]\n",
      "\u001b[2K    Found existing installation: grpcio 1.71.0mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11/18\u001b[0m [python-dateutil]\n",
      "\u001b[2K    Uninstalling grpcio-1.71.0:m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11/18\u001b[0m [python-dateutil]\n",
      "\u001b[2K      Successfully uninstalled grpcio-1.71.090mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11/18\u001b[0m [python-dateutil]\n",
      "\u001b[2K  Attempting uninstall: contourpyâ”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12/18\u001b[0m [grpcio]util]\n",
      "\u001b[2K    Found existing installation: contourpy 1.3.1mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12/18\u001b[0m [grpcio]\n",
      "\u001b[2K    Uninstalling contourpy-1.3.1:m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12/18\u001b[0m [grpcio]\n",
      "\u001b[2K      Successfully uninstalled contourpy-1.3.190mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12/18\u001b[0m [grpcio]\n",
      "\u001b[2K  Attempting uninstall: matplotlibâ”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”\u001b[0m \u001b[32m14/18\u001b[0m [contourpy]\n",
      "\u001b[2K    Found existing installation: matplotlib 3.10.1[90mâ”â”â”â”â”â”â”â”\u001b[0m \u001b[32m14/18\u001b[0m [contourpy]\n",
      "\u001b[2K    Uninstalling matplotlib-3.10.1:\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”\u001b[0m \u001b[32m14/18\u001b[0m [contourpy]\n",
      "\u001b[2K      Successfully uninstalled matplotlib-3.10.10mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”\u001b[0m \u001b[32m15/18\u001b[0m [matplotlib]\n",
      "\u001b[2K  Attempting uninstall: aseâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”\u001b[0m \u001b[32m15/18\u001b[0m [matplotlib]\n",
      "\u001b[2K    Found existing installation: ase 3.25.090mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”\u001b[0m \u001b[32m15/18\u001b[0m [matplotlib]\n",
      "\u001b[2K    Uninstalling ase-3.25.0:â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”\u001b[0m \u001b[32m16/18\u001b[0m [ase]ib]\n",
      "\u001b[2K      Successfully uninstalled ase-3.25.00m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”\u001b[0m \u001b[32m16/18\u001b[0m [ase]\n",
      "\u001b[2K  Attempting uninstall: pfp-api-clientâ”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”\u001b[0m \u001b[32m16/18\u001b[0m [ase]\n",
      "\u001b[2K    Found existing installation: pfp-api-client 1.24.0[90mâ”â”â”â”\u001b[0m \u001b[32m16/18\u001b[0m [ase]\n",
      "\u001b[2K    Uninstalling pfp-api-client-1.24.0:\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”\u001b[0m \u001b[32m16/18\u001b[0m [ase]\n",
      "\u001b[2K      Successfully uninstalled pfp-api-client-1.24.0m\u001b[90mâ”â”â”â”\u001b[0m \u001b[32m16/18\u001b[0m [ase]\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m18/18\u001b[0m [pfp-api-client]m [pfp-api-client]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed ase-3.26.0 contourpy-1.3.3 cycler-0.12.1 fonttools-4.60.1 googleapis-common-protos-1.70.0 grpcio-1.75.1 kiwisolver-1.4.9 matplotlib-3.10.7 numpy-1.26.4 packaging-25.0 pfp-api-client-1.24.0 pillow-11.3.0 protobuf-5.29.5 pyparsing-3.2.5 python-dateutil-2.9.0.post0 scipy-1.16.2 six-1.17.0 typing-extensions-4.15.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --force-reinstall pfp-api-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc5d8cc-9103-495b-99b9-4be93e7861ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "91f80494-3bc6-4da3-a830-74ed2678990e",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 228)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m<tokenize>:228\u001b[0;36m\u001b[0m\n\u001b[0;31m    def find_and_categorize_surfaces(self):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Trajectoryãƒ•ã‚¡ã‚¤ãƒ«ã®æ•´ç†ã¨ã€ãã‚Œã«åŸºã¥ãç•Œé¢æ§‹ç¯‰ãƒ»æœ€é©åŒ–ã‚’è‡ªå‹•åŒ–ã™ã‚‹ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã€‚\n",
    "\n",
    "[ã‚¨ãƒ©ãƒ¼è€æ€§å¼·åŒ–ç‰ˆ]\n",
    "- ç ´æã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ãªã©ã€ç‰¹å®šãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¦ã‚‚å…¨ä½“ãŒåœæ­¢ã›ãšã€\n",
    "  æ¬¡ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†ã‚’ç¶šè¡Œã—ã¾ã™ã€‚\n",
    "\n",
    "STEP 1: Trajectoryãƒ•ã‚¡ã‚¤ãƒ«ã®åˆ†æã¨ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—\n",
    "  - 0KBã®.trajãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆå¤±æ•—ã—ãŸè¨ˆç®—ï¼‰ã‚’å‰Šé™¤\n",
    "  - æ­£å¸¸ãª.trajãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆæœŸ/æœ€çµ‚æ§‹é€ ã®.xyzã«å¤‰æ›ã—ã€å…ƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤\n",
    "\n",
    "STEP 2: ç•Œé¢ã®æ§‹ç¯‰ã¨æœ€é©åŒ–\n",
    "  - STEP 1ã§ç”Ÿæˆã•ã‚ŒãŸæœ€çµ‚æ§‹é€ (.xyz)ã‚’ç”¨ã„ã¦ç•Œé¢ã‚’æ§‹ç¯‰\n",
    "  - Matlantisã‚’ç”¨ã„ã¦åŸå­ä½ç½®ã®ã¿ã‚’æœ€é©åŒ–\n",
    "\"\"\"\n",
    "import os\n",
    "import itertools\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import nglview as nv\n",
    "\n",
    "# ASE\n",
    "from ase.io import read, write\n",
    "from ase.build import stack,cut\n",
    "\n",
    "# Matlantis / PFP\n",
    "from matlantis_features.atoms import MatlantisAtoms\n",
    "from matlantis_features.features.common.opt import FireLBFGSASEOptFeature\n",
    "from matlantis_features.utils.calculators import pfp_estimator_fn\n",
    "from pfp_api_client.pfp.estimator import EstimatorCalcMode\n",
    "\n",
    "# --- STEP 1: Trajectoryãƒ•ã‚¡ã‚¤ãƒ«ã®æ•´ç†ã‚¯ãƒ©ã‚¹ ---\n",
    "class TrajectoryCleanup:\n",
    "    \"\"\"\n",
    "    .trajãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†æã—ã€.xyzã«å¤‰æ›ã—ã¦ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã™ã‚‹ã‚¯ãƒ©ã‚¹ã€‚\n",
    "    \"\"\"\n",
    "    def __init__(self, directory):\n",
    "        self.directory = Path(directory)\n",
    "        print(\"--- STEP 1: Trajectoryãƒ•ã‚¡ã‚¤ãƒ«ã®åˆ†æã¨æ•´ç†ã‚’é–‹å§‹ ---\")\n",
    "        if not self.directory.is_dir():\n",
    "            print(f\"ğŸ›‘ ã‚¨ãƒ©ãƒ¼: ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª '{self.directory}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚\")\n",
    "            self.files_to_process = []\n",
    "        else:\n",
    "            self.files_to_process = list(self.directory.glob(\"*.traj\"))\n",
    "            print(f\"ğŸ” '{self.directory}' ã‹ã‚‰ {len(self.files_to_process)} å€‹ã® .traj ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç™ºè¦‹ã€‚\")\n",
    "\n",
    "    def process_file(self, traj_path):\n",
    "        \"\"\"\n",
    "        1ã¤ã®.trajãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã™ã‚‹ã€‚\n",
    "        [ä¿®æ­£] ã“ã®é–¢æ•°å…¨ä½“ã‚’try...exceptã§å›²ã¿ã€ã‚¨ãƒ©ãƒ¼è€æ€§ã‚’å‘ä¸Šã€‚\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã‚’ç¢ºèª\n",
    "            file_size = traj_path.stat().st_size\n",
    "            if file_size == 0:\n",
    "                print(f\"  -> ğŸ—‘ï¸  0KBãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¾ã™: {traj_path.name}\")\n",
    "                os.remove(traj_path)\n",
    "                return\n",
    "\n",
    "            # æ­£å¸¸ãªãƒ•ã‚¡ã‚¤ãƒ«ã¯å¤‰æ›\n",
    "            base_name = traj_path.stem\n",
    "            initial_xyz_path = self.directory / f\"{base_name}_initial.xyz\"\n",
    "            final_xyz_path = self.directory / f\"{base_name}_final.xyz\"\n",
    "            \n",
    "            print(f\"  -> ğŸ”„ å¤‰æ›ä¸­: {traj_path.name}\")\n",
    "            \n",
    "            # Trajectoryã‹ã‚‰åˆæœŸæ§‹é€ ã¨æœ€çµ‚æ§‹é€ ã‚’èª­ã¿è¾¼ã¿\n",
    "            atoms_list = read(traj_path, index=\":\")\n",
    "            if not atoms_list:\n",
    "                print(f\"  -> âŒ èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ï¼ˆç©ºã®Trajectoryï¼‰ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¾ã™: {traj_path.name}\")\n",
    "                os.remove(traj_path)\n",
    "                return\n",
    "\n",
    "            # .xyzãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜\n",
    "            write(str(initial_xyz_path), atoms_list[0])\n",
    "            write(str(final_xyz_path), atoms_list[-1])\n",
    "            \n",
    "            # å…ƒã®.trajãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤\n",
    "            os.remove(traj_path)\n",
    "            print(f\"  -> âœ”ï¸ å¤‰æ›æˆåŠŸã€å…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¾ã—ãŸ: {traj_path.name}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            # äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã€ãƒ­ã‚°ã‚’å‡ºåŠ›ã—ã¦å‡¦ç†ã‚’ç¶šè¡Œ\n",
    "            print(f\"  -> âŒ é‡å¤§ãªã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸãŸã‚ã€ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ ({traj_path.name}): {e}\")\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"å…¨ã¦ã®å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ã«å¯¾ã—ã¦å‡¦ç†ã‚’å®Ÿè¡Œã™ã‚‹ã€‚\"\"\"\n",
    "        if not self.files_to_process:\n",
    "            print(\" -> å‡¦ç†å¯¾è±¡ã®.trajãƒ•ã‚¡ã‚¤ãƒ«ãŒãªã„ãŸã‚ã€ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚\")\n",
    "            return\n",
    "        for traj_file in self.files_to_process:\n",
    "            self.process_file(traj_file)\n",
    "        print(\"\\nâœ¨ STEP 1 å®Œäº†ã€‚\")\n",
    "\n",
    "\n",
    "# --- Matlantisæœ€é©åŒ–é–¢æ•° (å…±é€š) ---\n",
    "def run_matlantis_optimization(atoms, trajectory_path, fmax=0.05, name=\"structure\"):\n",
    "    print(f\"  -> Matlantisæœ€é©åŒ–é–‹å§‹ ({name}, fmax = {fmax}) ...\")\n",
    "    matlantis_atoms = MatlantisAtoms(atoms)\n",
    "    estimator_function = pfp_estimator_fn(\n",
    "        model_version='v7.0.0', calc_mode=EstimatorCalcMode.CRYSTAL_PLUS_D3\n",
    "    )\n",
    "    position_optimizer = FireLBFGSASEOptFeature(\n",
    "        estimator_fn=estimator_function, filter=False, trajectory=str(trajectory_path),\n",
    "        n_run=5000, fmax=fmax, show_progress_bar=True\n",
    "    )\n",
    "    try:\n",
    "        result = position_optimizer(matlantis_atoms)\n",
    "        optimized_atoms = result.atoms.ase_atoms\n",
    "        final_energy = result.output.energy_log[-1]\n",
    "        print(f\"  -> âœ”ï¸ æœ€é©åŒ–å®Œäº†ï¼ ã‚¨ãƒãƒ«ã‚®ãƒ¼: {final_energy:.3f} eV\")\n",
    "        xyz_save_path = Path(trajectory_path).with_suffix('.xyz')\n",
    "        print(f\"  -> ğŸ’¾ æœ€é©åŒ–å¾Œã®æ§‹é€ ã‚’ä¿å­˜ã—ã¾ã™: {xyz_save_path.name}\")\n",
    "        write(str(xyz_save_path), optimized_atoms)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"  -> âŒ æœ€é©åŒ–ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}\")\n",
    "        return False\n",
    "\n",
    "# --- STEP 2: ç•Œé¢æœ€é©åŒ–ã‚¯ãƒ©ã‚¹ ---\n",
    "class InterfaceOptimizer:\n",
    "    def __init__(self, surfaces_dir, interfaces_dir):\n",
    "        self.surfaces_dir = Path(surfaces_dir)\n",
    "        self.interfaces_dir = Path(interfaces_dir)\n",
    "        self.interfaces_dir.mkdir(parents=True, exist_ok=True)\n",
    "        print(f\"\\n--- STEP 2: ç•Œé¢æ§‹ç¯‰ãƒ»æœ€é©åŒ–ãƒ—ãƒ­ã‚»ã‚¹ã‚’é–‹å§‹ ---\")\n",
    "        print(f\"âœ… ç•Œé¢æ§‹é€ ã®ä¿å­˜å…ˆ: '{self.interfaces_dir}'\")\n",
    "\n",
    "    # def build_and_cut_interface(self, slab1, slab2, target_xy=(12.0, 12.0), target_z=20.0, separation=2.0):\n",
    "    #     \"\"\"\n",
    "    #     ç·©å’Œæ¸ˆã¿è¡¨é¢ã‚’ç¶­æŒã—ã¤ã¤ã€æŒ‡å®šã‚µã‚¤ã‚ºã«ç•Œé¢ã‚’ç²¾å¯†ã«æ§‹ç¯‰ãƒ»ã‚«ãƒƒãƒˆã™ã‚‹ã€‚\n",
    "    #     \"\"\"\n",
    "    #     print(f\"    -> ç•Œé¢ã‚’ ({target_xy[0]}, {target_xy[1]}, {target_z}) Ã… ã«ç²¾å¯†æ§‹ç¯‰...\")\n",
    "    #     # Step 1: å„ã‚¹ãƒ©ãƒ–ã‚’X,Yæ–¹å‘ã«ã‚«ãƒƒãƒˆ\n",
    "    #     # cut_slab1 = cut(slab1, a=(target_xy[0], 0, 0), b=(0, target_xy[1], 0), origo=(0,0,0))\n",
    "    #     # cut_slab2 = cut(slab2, a=(target_xy[0], 0, 0), b=(0, target_xy[1], 0), origo=(0,0,0))\n",
    "    #     position1 = slab1.get_positions()\n",
    "    #     position2 = slab2.get_positions()\n",
    "    #     # æ¡ä»¶ï¼ˆx>=12 ã¾ãŸã¯ y>=12ï¼‰ã«åˆã†åŸå­ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ¢ã™\n",
    "    #     # np.whereã¯æ¡ä»¶ã«åˆã†è¦ç´ ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’è¿”ã™\n",
    "    #     indices_to_delete1 = np.where(\n",
    "    #         (position1[:, 0] >= target_xy[0]) | (position1[:, 1] >= target_xy[1])\n",
    "    #     )[0]\n",
    "    #     indices_to_delete2 = np.where(\n",
    "    #         (position2[:, 0] >= target_xy[0]) | (position2[:, 1] >= target_xy[1])\n",
    "    #     )[0]\n",
    "    #     # è¦‹ã¤ã‹ã£ãŸã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®åŸå­ã‚’å‰Šé™¤\n",
    "    #     cut_slab1=slab1.copy()\n",
    "    #     cut_slab2=slab2.copy()\n",
    "    #     del cut_slab1[indices_to_delete1]\n",
    "    #     del cut_slab2[indices_to_delete2]\n",
    "    #     print(f\"ç•Œé¢ã‹ã‚‰é ã„åŸå­ã‚’ {len(indices_to_delete1)},{len(indices_to_delete2)}å‰Šé™¤\")\n",
    "    #     # Step 2: ç·©å’Œæ¸ˆã¿è¡¨é¢ã®ä½ç½®ã‚’ç‰¹å®š\n",
    "    #     z1_max = cut_slab1.positions[:, 2].max()\n",
    "    #     z2_min = cut_slab2.positions[:, 2].min()\n",
    "\n",
    "    #     # Step 3: ç•Œé¢ãŒä¸­å¤®ã«æ¥ã‚‹ã‚ˆã†ã«å„ã‚¹ãƒ©ãƒ–ã‚’Zæ–¹å‘ã«ã‚·ãƒ•ãƒˆ\n",
    "    #     cut_slab1.positions[:, 2] += (target_z / 2) - (separation / 2) - z1_max\n",
    "    #     cut_slab2.positions[:, 2] += (target_z / 2) + (separation / 2) - z2_min\n",
    "        \n",
    "    #     # Step 4: 2ã¤ã®ã‚¹ãƒ©ãƒ–ã‚’çµåˆ\n",
    "    #     interface = cut_slab1 + cut_slab2\n",
    "        \n",
    "    #     # Step 5: æœ€çµ‚çš„ãªã‚»ãƒ«ã‚’è¨­å®š (åŸå­ã¯ã‚¹ã‚±ãƒ¼ãƒ«ã—ãªã„)\n",
    "    #     cell_z=target_z*2+2\n",
    "    #     interface.set_cell([target_xy[0], target_xy[1], cell_z], scale_atoms=False)\n",
    "    #     interface.pbc = (True, True, True) # MDç”¨ã«PBCã‚’Trueã«è¨­å®š\n",
    "        \n",
    "    #     # Step 6: ã‚»ãƒ«ã‹ã‚‰ã¯ã¿å‡ºã—ãŸåŸå­ï¼ˆç•Œé¢ã‹ã‚‰é ã„åŸå­ï¼‰ã‚’å‰Šé™¤\n",
    "    #     # np.deleteã¯ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®é‡è¤‡ã‚’è¨±ã•ãªã„ãŸã‚ã€ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—\n",
    "        \n",
    "    #     # if len(indices_to_delete) > 0:\n",
    "    #     #     del interface[indices_to_delete]\n",
    "    #     #     print(f\"    -> ç•Œé¢ã‹ã‚‰é ã„åŸå­ã‚’ {len(indices_to_delete)} å€‹å‰Šé™¤ã—ã¾ã—ãŸã€‚\")\n",
    "        \n",
    "    #     # Step 7: åŸå­ã‚’ã‚»ãƒ«å†…ã«æŠ˜ã‚ŠãŸãŸã‚€\n",
    "    #     interface.wrap()\n",
    "    #     print(f\"    -> æ§‹ç¯‰å¾Œã®åŸå­æ•°: {len(interface)}\")\n",
    "    #     return interface\n",
    "    def build_and_cut_interface(slab1, slab2, target_xy=(12.0, 12.0), separation=2.0, vacuum=1.0):\n",
    "        # Step 1: å„ã‚¹ãƒ©ãƒ–ã‹ã‚‰æŒ‡å®šç¯„å›²å¤–ã®åŸå­ã‚’å‰Šé™¤\n",
    "        position1 = slab1.get_positions()\n",
    "        position2 = slab2.get_positions()\n",
    "        indices_to_delete1 = np.where(\n",
    "            (position1[:, 0] >= target_xy[0]) | (position1[:, 1] >= target_xy[1])\n",
    "        )[0]\n",
    "        indices_to_delete2 = np.where(\n",
    "            (position2[:, 0] >= target_xy[0]) | (position2[:, 1] >= target_xy[1])\n",
    "        )[0]\n",
    "        cut_slab1=slab1.copy()\n",
    "        cut_slab2=slab2.copy()\n",
    "        if len(indices_to_delete1) > 0: del cut_slab1[indices_to_delete1]\n",
    "        if len(indices_to_delete2) > 0: del cut_slab2[indices_to_delete2]\n",
    "        print(f\"Â  Â  -> ã‚¹ãƒ©ãƒ–1, 2ã‹ã‚‰ãã‚Œãã‚Œ {len(indices_to_delete1)}, {len(indices_to_delete2)} å€‹ã®åŸå­ã‚’å‰Šé™¤ã€‚\")\n",
    "Â  Â  Â  Â Â \n",
    "        # Step 2: ç•Œé¢é–“ã®è·é›¢ã‚’èª¿æ•´ã—ã¦ã‚¹ã‚¿ãƒƒã‚¯\n",
    "        z1_max = cut_slab1.positions[:, 2].max()\n",
    "        z2_min = cut_slab2.positions[:, 2].min()\n",
    "        cut_slab2.positions[:, 2] += z1_max - z2_min + separation\n",
    "Â  Â  Â  Â Â \n",
    "        # Step 3: 2ã¤ã®ã‚¹ãƒ©ãƒ–ã‚’çµåˆã—ã€æ–°ã—ã„ã‚»ãƒ«ã‚’è¨­å®š\n",
    "        interface = cut_slab1 + cut_slab2\n",
    "        interface.set_cell([target_xy[0], target_xy[1], 50], scale_atoms=False) # Zã¯ä»®ã®é«˜ã•\n",
    "Â  Â  Â  Â Â \n",
    "        # Step 4: Zæ–¹å‘ã®å‘¨æœŸæ€§ã‚’ç„¡ãã—ã€çœŸç©ºå±¤ã‚’è¨­ã‘ã¦ä¸­å¤®ã«é…ç½®\n",
    "        interface.pbc = (True, True, False)\n",
    "        interface.center(vacuum=vacuum, axis=2)\n",
    "Â  Â  Â  Â Â \n",
    "        print(f\"Â  Â  -> æ§‹ç¯‰å¾Œã®åŸå­æ•°: {len(interface)}ã€‚Zæ–¹å‘ã«çœŸç©ºå±¤ã‚’æŒã¤2å±¤æ§‹é€ ã‚’ä½œæˆã€‚\")\n",
    "        return interface\n",
    "    # def cut_slab_to_size(self, slab, target_xy=(12.0, 12.0)):\n",
    "    #     print(f\"    -> ã‚¹ãƒ©ãƒ–ã‚’ ({target_xy[0]}, {target_xy[1]}) Ã… ã«ã‚«ãƒƒãƒˆ...\")\n",
    "    #     # æ–°ã—ã„ã‚»ãƒ«ã®åŸºåº•ãƒ™ã‚¯ãƒˆãƒ«ã‚’å®šç¾©\n",
    "    #     new_a = (target_xy[0], 0, 0)\n",
    "    #     new_b = (0, target_xy[1], 0)\n",
    "        \n",
    "    #     # å…ƒã®ã‚¹ãƒ©ãƒ–ã®ä¸­å¿ƒã‚’åŸºæº–ã«ã‚«ãƒƒãƒˆ\n",
    "    #     origo_cart = slab.cell.sum(axis=0) / 2 - (target_xy[0]/2, target_xy[1]/2, 0)\n",
    "    #     origo = np.linalg.solve(slab.cell.T, origo_cart.T)\n",
    "\n",
    "    #     cut_slab = cut(slab, a=new_a, b=new_b, origo=origo)\n",
    "    #     cut_slab.pbc = (True, True, False) # pbcã‚’å†è¨­å®š\n",
    "    #     print(f\"    -> ã‚«ãƒƒãƒˆå¾Œã®åŸå­æ•°: {len(cut_slab)}\")\n",
    "    #     return cut_slab\n",
    "    def find_and_categorize_surfaces(self):\n",
    "        print(f\"ğŸ” '{self.surfaces_dir}' ã‹ã‚‰æœ€é©åŒ–æ¸ˆã¿è¡¨é¢ (*_final.xyz) ã‚’åˆ†é¡ä¸­...\")\n",
    "        if not self.surfaces_dir.is_dir():\n",
    "             print(f\"ğŸ›‘ ã‚¨ãƒ©ãƒ¼: è¡¨é¢ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª '{self.surfaces_dir}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚\")\n",
    "             return [], []\n",
    "        \n",
    "        all_surfaces = list(self.surfaces_dir.glob(\"*_final.xyz\"))\n",
    "        \n",
    "        al_surfaces = [p for p in all_surfaces if \"Al\" in p.stem]\n",
    "        cathode_surfaces = [p for p in all_surfaces if \"NMC\" in p.stem]\n",
    "        print(f\"  - Alè¡¨é¢: {len(al_surfaces)}å€‹,  æ­£æ¥µæè¡¨é¢: {len(cathode_surfaces)}å€‹\")\n",
    "        return al_surfaces, cathode_surfaces\n",
    "\n",
    "    def create_and_optimize_interface(self, slab1_path, slab2_path):\n",
    "        slab1_name = slab1_path.stem.replace('_pos_opt_final', '').replace('_cell_opt_final', '')\n",
    "        slab2_name = slab2_path.stem.replace('_pos_opt_final', '').replace('_cell_opt_final', '')\n",
    "        interface_name = f\"Interface_{slab1_name}_on_{slab2_name}\"\n",
    "        output_path = self.interfaces_dir / f\"{interface_name}.cif\"\n",
    "        \n",
    "        if output_path.exists():\n",
    "            print(f\"âœ… æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚ã‚Šã€ã‚¹ã‚­ãƒƒãƒ—: {output_path.name}\")\n",
    "            return\n",
    "\n",
    "        print(f\"\\n--- ç•Œé¢ã‚’æ§‹ç¯‰ãƒ»æœ€é©åŒ–: {slab1_name} + {slab2_name} ---\")\n",
    "        try:\n",
    "            slab1, slab2 = read(slab1_path), read(slab2_path)\n",
    "            # ä¿®æ­£ã•ã‚ŒãŸé–¢æ•°ã‚’å‘¼ã³å‡ºã™\n",
    "            interface = self.build_and_cut_interface(slab1, slab2)\n",
    "            traj_path = self.interfaces_dir / f\"{interface_name}.traj\"\n",
    "            if run_matlantis_optimization(interface, traj_path, fmax=0.05, name=interface_name):\n",
    "                # æœ€é©åŒ–æˆåŠŸæ™‚ã«CIFãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›¸ãè¾¼ã‚€\n",
    "                write(str(output_path), interface)\n",
    "                print(f\"Â  -> ğŸ’¾ ä¿å­˜ã—ã¾ã—ãŸ: {output_path.name}\")\n",
    "        # 'except'ã®ã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆã‚’'try'ã«åˆã‚ã›ã‚‹\n",
    "        except Exception as e:\n",
    "            print(f\"Â  -> âŒ ã“ã®ç•Œé¢ã®ä½œæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸãŸã‚ã€ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™: {e}\")\n",
    "    def run(self):\n",
    "        al_slabs, cathode_slabs = self.find_and_categorize_surfaces()\n",
    "        if not al_slabs and not cathode_slabs:\n",
    "            print(\" -> å‡¦ç†å¯¾è±¡ã®è¡¨é¢ãƒ•ã‚¡ã‚¤ãƒ«ãŒãªã„ãŸã‚ã€çµ‚äº†ã—ã¾ã™ã€‚\")\n",
    "            return\n",
    "            \n",
    "        print(\"\\n--- ã‚«ãƒ†ã‚´ãƒª1: Alã‚’å«ã‚€ç•Œé¢ ---\")\n",
    "        if al_slabs and cathode_slabs:\n",
    "            for al_path in al_slabs:\n",
    "                for cathode_path in cathode_slabs:\n",
    "                    self.create_and_optimize_interface(al_path, cathode_path)\n",
    "        else:\n",
    "            print(\" -> ã‚¹ã‚­ãƒƒãƒ— (Alè¡¨é¢ã¾ãŸã¯æ­£æ¥µæè¡¨é¢ã®ã„ãšã‚Œã‹ãŒä¸è¶³)\")\n",
    "            \n",
    "        # print(\"\\n--- ã‚«ãƒ†ã‚´ãƒª2: Alã‚’å«ã¾ãªã„ç•Œé¢ ---\")\n",
    "        # if len(cathode_slabs) >= 2:\n",
    "        #     for pair in itertools.combinations(cathode_slabs, 2):\n",
    "        #         self.create_and_optimize_interface(pair[0], pair[1])\n",
    "        # else:\n",
    "        #     print(\" -> ã‚¹ã‚­ãƒƒãƒ— (æ­£æ¥µæè¡¨é¢ãŒ2ã¤æœªæº€)\")\n",
    "        print(\"\\nâœ¨ STEP 2 å®Œäº†ã€‚\")\n",
    "\n",
    "def show_results_viewer(results_dir):\n",
    "    print(f\"\\n--- ğŸ”¬ çµæœãƒ“ãƒ¥ãƒ¼ãƒ¯ãƒ¼: '{results_dir}' ---\")\n",
    "    files = sorted(list(Path(results_dir).glob(\"*.cif\")))\n",
    "    if not files:\n",
    "        print(\"è¡¨ç¤ºã§ãã‚‹æ§‹é€ ãŒã‚ã‚Šã¾ã›ã‚“ã€‚\")\n",
    "        return\n",
    "    options = {\"-- é¸æŠã—ã¦ãã ã•ã„ --\": None}\n",
    "    options.update({p.name: p for p in files})\n",
    "    widgets.interact(\n",
    "        lambda file_path: display(nv.show_ase(read(file_path)) if file_path else None),\n",
    "        file_path=widgets.Dropdown(options=options, description='Interface:', layout={'width': 'max-content'})\n",
    "    )\n",
    "\n",
    "# --- ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œéƒ¨ ---\n",
    "if __name__ == \"__main__\":\n",
    "    # ===== è¨­å®šé …ç›® =====\n",
    "    # 1. Trajectoryãƒ•ã‚¡ã‚¤ãƒ«ãŒä¿å­˜ã•ã‚Œã¦ã„ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª\n",
    "    OPTIMIZATION_OUTPUT_DIR = \"/home/jovyan/Kaori/MD/LiB_2/structure/output\"\n",
    "    \n",
    "    # 2. æœ€é©åŒ–ã—ãŸç•Œé¢ã®ä¿å­˜å…ˆ\n",
    "    INTERFACES_DIR = \"/home/jovyan/Kaori/MD/LiB_2/structure/output/optimized_interfaces\"\n",
    "    # ====================\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    # STEP 1: ãƒ¡ãƒ¢ãƒªç®¡ç† (traj -> xyzå¤‰æ› & å‰Šé™¤)\n",
    "    cleanup = TrajectoryCleanup(OPTIMIZATION_OUTPUT_DIR)\n",
    "    cleanup.run()\n",
    "    \n",
    "    # STEP 2: ç•Œé¢ã®æ§‹ç¯‰ã¨æœ€é©åŒ–\n",
    "    interface_opt = InterfaceOptimizer(surfaces_dir=OPTIMIZATION_OUTPUT_DIR, interfaces_dir=INTERFACES_DIR)\n",
    "    interface_opt.run()\n",
    "    \n",
    "    print(\"\\n\\nâœ¨ å…¨ã¦ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãŒå®Œäº†ã—ã¾ã—ãŸã€‚ âœ¨\")\n",
    "    \n",
    "    # STEP 3: çµæœã®è¡¨ç¤º\n",
    "    show_results_viewer(INTERFACES_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d6fea1-b1d9-4c94-a39e-2de3fb84e7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Trajectoryãƒ•ã‚¡ã‚¤ãƒ«ã®æ•´ç†ã¨ã€ãã‚Œã«åŸºã¥ãç•Œé¢æ§‹ç¯‰ãƒ»æœ€é©åŒ–ã‚’è‡ªå‹•åŒ–ã™ã‚‹ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã€‚\n",
    "\n",
    "[ã‚¨ãƒ©ãƒ¼è€æ€§å¼·åŒ–ç‰ˆ]\n",
    "- ç ´æã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ãªã©ã€ç‰¹å®šãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¦ã‚‚å…¨ä½“ãŒåœæ­¢ã›ãšã€\n",
    "  æ¬¡ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†ã‚’ç¶šè¡Œã—ã¾ã™ã€‚\n",
    "\n",
    "STEP 1: Trajectoryãƒ•ã‚¡ã‚¤ãƒ«ã®åˆ†æã¨ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—\n",
    "  - 0KBã®.trajãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆå¤±æ•—ã—ãŸè¨ˆç®—ï¼‰ã‚’å‰Šé™¤\n",
    "  - æ­£å¸¸ãª.trajãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆæœŸ/æœ€çµ‚æ§‹é€ ã®.xyzã«å¤‰æ›ã—ã€å…ƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤\n",
    "\n",
    "STEP 2: ç•Œé¢ã®æ§‹ç¯‰ã¨æœ€é©åŒ–\n",
    "  - STEP 1ã§ç”Ÿæˆã•ã‚ŒãŸæœ€çµ‚æ§‹é€ (.xyz)ã‚’ç”¨ã„ã¦ç•Œé¢ã‚’æ§‹ç¯‰\n",
    "  - Matlantisã‚’ç”¨ã„ã¦åŸå­ä½ç½®ã®ã¿ã‚’æœ€é©åŒ–\n",
    "\"\"\"\n",
    "import os\n",
    "import itertools\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import nglview as nv\n",
    "\n",
    "# ASE\n",
    "from ase.io import read, write\n",
    "from ase.build import stack,cut\n",
    "\n",
    "# Matlantis / PFP\n",
    "from matlantis_features.atoms import MatlantisAtoms\n",
    "from matlantis_features.features.common.opt import FireLBFGSASEOptFeature\n",
    "from matlantis_features.utils.calculators import pfp_estimator_fn\n",
    "from pfp_api_client.pfp.estimator import EstimatorCalcMode\n",
    "\n",
    "# --- STEP 1: Trajectoryãƒ•ã‚¡ã‚¤ãƒ«ã®æ•´ç†ã‚¯ãƒ©ã‚¹ ---\n",
    "class TrajectoryCleanup:\n",
    "    \"\"\"\n",
    "    .trajãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†æã—ã€.xyzã«å¤‰æ›ã—ã¦ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã™ã‚‹ã‚¯ãƒ©ã‚¹ã€‚\n",
    "    \"\"\"\n",
    "    def __init__(self, directory):\n",
    "        self.directory = Path(directory)\n",
    "        print(\"--- STEP 1: Trajectoryãƒ•ã‚¡ã‚¤ãƒ«ã®åˆ†æã¨æ•´ç†ã‚’é–‹å§‹ ---\")\n",
    "        if not self.directory.is_dir():\n",
    "            print(f\"ğŸ›‘ ã‚¨ãƒ©ãƒ¼: ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª '{self.directory}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚\")\n",
    "            self.files_to_process = []\n",
    "        else:\n",
    "            self.files_to_process = list(self.directory.glob(\"*.traj\"))\n",
    "            print(f\"ğŸ” '{self.directory}' ã‹ã‚‰ {len(self.files_to_process)} å€‹ã® .traj ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç™ºè¦‹ã€‚\")\n",
    "\n",
    "    def process_file(self, traj_path):\n",
    "        \"\"\"\n",
    "        1ã¤ã®.trajãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã™ã‚‹ã€‚\n",
    "        [ä¿®æ­£] ã“ã®é–¢æ•°å…¨ä½“ã‚’try...exceptã§å›²ã¿ã€ã‚¨ãƒ©ãƒ¼è€æ€§ã‚’å‘ä¸Šã€‚\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã‚’ç¢ºèª\n",
    "            file_size = traj_path.stat().st_size\n",
    "            if file_size == 0:\n",
    "                print(f\"  -> ğŸ—‘ï¸  0KBãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¾ã™: {traj_path.name}\")\n",
    "                os.remove(traj_path)\n",
    "                return\n",
    "\n",
    "            # æ­£å¸¸ãªãƒ•ã‚¡ã‚¤ãƒ«ã¯å¤‰æ›\n",
    "            base_name = traj_path.stem\n",
    "            initial_xyz_path = self.directory / f\"{base_name}_initial.xyz\"\n",
    "            final_xyz_path = self.directory / f\"{base_name}_final.xyz\"\n",
    "\n",
    "            print(f\"  -> ğŸ”„ å¤‰æ›ä¸­: {traj_path.name}\")\n",
    "\n",
    "            # Trajectoryã‹ã‚‰åˆæœŸæ§‹é€ ã¨æœ€çµ‚æ§‹é€ ã‚’èª­ã¿è¾¼ã¿\n",
    "            atoms_list = read(traj_path, index=\":\")\n",
    "            if not atoms_list:\n",
    "                print(f\"  -> âŒ èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ï¼ˆç©ºã®Trajectoryï¼‰ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¾ã™: {traj_path.name}\")\n",
    "                os.remove(traj_path)\n",
    "                return\n",
    "\n",
    "            # .xyzãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜\n",
    "            write(str(initial_xyz_path), atoms_list[0])\n",
    "            write(str(final_xyz_path), atoms_list[-1])\n",
    "\n",
    "            # å…ƒã®.trajãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤\n",
    "            os.remove(traj_path)\n",
    "            print(f\"  -> âœ”ï¸ å¤‰æ›æˆåŠŸã€å…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¾ã—ãŸ: {traj_path.name}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            # äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã€ãƒ­ã‚°ã‚’å‡ºåŠ›ã—ã¦å‡¦ç†ã‚’ç¶šè¡Œ\n",
    "            print(f\"  -> âŒ é‡å¤§ãªã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸãŸã‚ã€ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ ({traj_path.name}): {e}\")\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"å…¨ã¦ã®å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ã«å¯¾ã—ã¦å‡¦ç†ã‚’å®Ÿè¡Œã™ã‚‹ã€‚\"\"\"\n",
    "        if not self.files_to_process:\n",
    "            print(\" -> å‡¦ç†å¯¾è±¡ã®.trajãƒ•ã‚¡ã‚¤ãƒ«ãŒãªã„ãŸã‚ã€ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚\")\n",
    "            return\n",
    "        for traj_file in self.files_to_process:\n",
    "            self.process_file(traj_file)\n",
    "        print(\"\\nâœ¨ STEP 1 å®Œäº†ã€‚\")\n",
    "\n",
    "\n",
    "# --- Matlantisæœ€é©åŒ–é–¢æ•° (å…±é€š) ---\n",
    "def run_matlantis_optimization(atoms, trajectory_path, fmax=0.05, name=\"structure\"):\n",
    "    print(f\"  -> Matlantisæœ€é©åŒ–é–‹å§‹ ({name}, fmax = {fmax}) ...\")\n",
    "    matlantis_atoms = MatlantisAtoms(atoms)\n",
    "    estimator_function = pfp_estimator_fn(\n",
    "        model_version='v7.0.0', calc_mode=EstimatorCalcMode.CRYSTAL_PLUS_D3\n",
    "    )\n",
    "    position_optimizer = FireLBFGSASEOptFeature(\n",
    "        estimator_fn=estimator_function, filter=False, trajectory=str(trajectory_path),\n",
    "        n_run=5000, fmax=fmax, show_progress_bar=True\n",
    "    )\n",
    "    try:\n",
    "        result = position_optimizer(matlantis_atoms)\n",
    "        optimized_atoms = result.atoms.ase_atoms\n",
    "        final_energy = result.output.energy_log[-1]\n",
    "        print(f\"  -> âœ”ï¸ æœ€é©åŒ–å®Œäº†ï¼ ã‚¨ãƒãƒ«ã‚®ãƒ¼: {final_energy:.3f} eV\")\n",
    "        xyz_save_path = Path(trajectory_path).with_suffix('.xyz')\n",
    "        print(f\"  -> ğŸ’¾ æœ€é©åŒ–å¾Œã®æ§‹é€ ã‚’ä¿å­˜ã—ã¾ã™: {xyz_save_path.name}\")\n",
    "        write(str(xyz_save_path), optimized_atoms)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"  -> âŒ æœ€é©åŒ–ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}\")\n",
    "        return False\n",
    "\n",
    "# --- STEP 2: ç•Œé¢æœ€é©åŒ–ã‚¯ãƒ©ã‚¹ ---\n",
    "class InterfaceOptimizer:\n",
    "    def __init__(self, surfaces_dir, interfaces_dir):\n",
    "        self.surfaces_dir = Path(surfaces_dir)\n",
    "        self.interfaces_dir = Path(interfaces_dir)\n",
    "        self.interfaces_dir.mkdir(parents=True, exist_ok=True)\n",
    "        print(f\"\\n--- STEP 2: ç•Œé¢æ§‹ç¯‰ãƒ»æœ€é©åŒ–ãƒ—ãƒ­ã‚»ã‚¹ã‚’é–‹å§‹ ---\")\n",
    "        print(f\"âœ… ç•Œé¢æ§‹é€ ã®ä¿å­˜å…ˆ: '{self.interfaces_dir}'\")\n",
    "\n",
    "    def build_and_cut_interface(self, slab1, slab2, target_xy=(12.0, 12.0), separation=2.0, vacuum=2.0):\n",
    "        \"\"\"\n",
    "        ç·©å’Œæ¸ˆã¿è¡¨é¢ã‚’ç¶­æŒã—ã¤ã¤ã€æŒ‡å®šã‚µã‚¤ã‚ºã§2å±¤ã®ç•Œé¢ã‚’æ§‹ç¯‰ã™ã‚‹ã€‚\n",
    "        \"\"\"\n",
    "        print(f\"    -> 2å±¤ç•Œé¢ã‚’ ({target_xy[0]}, {target_xy[1]}) Ã… ã«æ§‹ç¯‰...\")\n",
    "\n",
    "        # Step 1: å„ã‚¹ãƒ©ãƒ–ã‹ã‚‰æŒ‡å®šç¯„å›²å¤–ã®åŸå­ã‚’å‰Šé™¤\n",
    "        position1 = slab1.get_positions()\n",
    "        position2 = slab2.get_positions()\n",
    "        indices_to_delete1 = np.where(\n",
    "            (position1[:, 0] >= target_xy[0]) | (position1[:, 1] >= target_xy[1])\n",
    "        )[0]\n",
    "        indices_to_delete2 = np.where(\n",
    "            (position2[:, 0] >= target_xy[0]) | (position2[:, 1] >= target_xy[1])\n",
    "        )[0]\n",
    "        cut_slab1=slab1.copy()\n",
    "        cut_slab2=slab2.copy()\n",
    "        if len(indices_to_delete1) > 0: del cut_slab1[indices_to_delete1]\n",
    "        if len(indices_to_delete2) > 0: del cut_slab2[indices_to_delete2]\n",
    "        print(f\"    -> ã‚¹ãƒ©ãƒ–1, 2ã‹ã‚‰ãã‚Œãã‚Œ {len(indices_to_delete1)}, {len(indices_to_delete2)} å€‹ã®åŸå­ã‚’å‰Šé™¤ã€‚\")\n",
    "\n",
    "        # Step 2: ç•Œé¢é–“ã®è·é›¢ã‚’èª¿æ•´ã—ã¦ã‚¹ã‚¿ãƒƒã‚¯\n",
    "        z1_max = cut_slab1.positions[:, 2].max()\n",
    "        z2_min = cut_slab2.positions[:, 2].min()\n",
    "        cut_slab2.positions[:, 2] += z1_max - z2_min + separation\n",
    "\n",
    "        # Step 3: 2ã¤ã®ã‚¹ãƒ©ãƒ–ã‚’çµåˆã—ã€æ–°ã—ã„ã‚»ãƒ«ã‚’è¨­å®š\n",
    "        interface = cut_slab1 + cut_slab2\n",
    "        interface.set_cell([target_xy[0], target_xy[1], 50], scale_atoms=False) # Zã¯ä»®ã®é«˜ã•\n",
    "\n",
    "        # Step 4: Zæ–¹å‘ã®å‘¨æœŸæ€§ã‚’ç„¡ãã—ã€çœŸç©ºå±¤ã‚’è¨­ã‘ã¦ä¸­å¤®ã«é…ç½®\n",
    "        interface.pbc = (True, True, False)\n",
    "        interface.center(vacuum=vacuum, axis=2)\n",
    "\n",
    "        print(f\"    -> æ§‹ç¯‰å¾Œã®åŸå­æ•°: {len(interface)}ã€‚Zæ–¹å‘ã«çœŸç©ºå±¤ã‚’æŒã¤2å±¤æ§‹é€ ã‚’ä½œæˆã€‚\")\n",
    "        return interface\n",
    "\n",
    "    def cut_slab_to_size(self, slab, target_xy=(12.0, 12.0)):\n",
    "        print(f\"    -> ã‚¹ãƒ©ãƒ–ã‚’ ({target_xy[0]}, {target_xy[1]}) Ã… ã«ã‚«ãƒƒãƒˆ...\")\n",
    "        # æ–°ã—ã„ã‚»ãƒ«ã®åŸºåº•ãƒ™ã‚¯ãƒˆãƒ«ã‚’å®šç¾©\n",
    "        new_a = (target_xy[0], 0, 0)\n",
    "        new_b = (0, target_xy[1], 0)\n",
    "\n",
    "        # å…ƒã®ã‚¹ãƒ©ãƒ–ã®ä¸­å¿ƒã‚’åŸºæº–ã«ã‚«ãƒƒãƒˆ\n",
    "        origo_cart = slab.cell.sum(axis=0) / 2 - (target_xy[0]/2, target_xy[1]/2, 0)\n",
    "        origo = np.linalg.solve(slab.cell.T, origo_cart.T)\n",
    "\n",
    "        cut_slab = cut(slab, a=new_a, b=new_b, origo=origo)\n",
    "        cut_slab.pbc = (True, True, False) # pbcã‚’å†è¨­å®š\n",
    "        print(f\"    -> ã‚«ãƒƒãƒˆå¾Œã®åŸå­æ•°: {len(cut_slab)}\")\n",
    "        return cut_slab\n",
    "\n",
    "    def find_and_categorize_surfaces(self):\n",
    "        print(f\"ğŸ” '{self.surfaces_dir}' ã‹ã‚‰æœ€é©åŒ–æ¸ˆã¿è¡¨é¢ (*_final.xyz) ã‚’åˆ†é¡ä¸­...\")\n",
    "        if not self.surfaces_dir.is_dir():\n",
    "            print(f\"ğŸ›‘ ã‚¨ãƒ©ãƒ¼: è¡¨é¢ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª '{self.surfaces_dir}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚\")\n",
    "            return [], []\n",
    "\n",
    "        all_surfaces = list(self.surfaces_dir.glob(\"*_final.xyz\"))\n",
    "\n",
    "        al_surfaces = [p for p in all_surfaces if \"Al\" in p.stem]\n",
    "        cathode_surfaces = [p for p in all_surfaces if \"NMC\" in p.stem]\n",
    "        print(f\"  - Alè¡¨é¢: {len(al_surfaces)}å€‹,  æ­£æ¥µæè¡¨é¢: {len(cathode_surfaces)}å€‹\")\n",
    "        return al_surfaces, cathode_surfaces\n",
    "\n",
    "    def create_and_optimize_interface(self, slab1_path, slab2_path):\n",
    "        slab1_name = slab1_path.stem.replace('_pos_opt_final', '').replace('_cell_opt_final', '')\n",
    "        slab2_name = slab2_path.stem.replace('_pos_opt_final', '').replace('_cell_opt_final', '')\n",
    "        interface_name = f\"Interface_{slab1_name}_on_{slab2_name}\"\n",
    "        output_path = self.interfaces_dir / f\"{interface_name}.cif\"\n",
    "\n",
    "        if output_path.exists():\n",
    "            print(f\"âœ… æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚ã‚Šã€ã‚¹ã‚­ãƒƒãƒ—: {output_path.name}\")\n",
    "            return\n",
    "\n",
    "        print(f\"\\n--- ç•Œé¢ã‚’æ§‹ç¯‰ãƒ»æœ€é©åŒ–: {slab1_name} + {slab2_name} ---\")\n",
    "        try:\n",
    "            slab1, slab2 = read(slab1_path), read(slab2_path)\n",
    "            # ä¿®æ­£ã•ã‚ŒãŸé–¢æ•°ã‚’å‘¼ã³å‡ºã™\n",
    "            interface = self.build_and_cut_interface(slab1, slab2)\n",
    "            traj_path = self.interfaces_dir / f\"{interface_name}.traj\"\n",
    "            if run_matlantis_optimization(interface, traj_path, fmax=0.05, name=interface_name):\n",
    "                # æœ€é©åŒ–æˆåŠŸæ™‚ã«CIFãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›¸ãè¾¼ã‚€\n",
    "                write(str(output_path), interface)\n",
    "                print(f\"  -> ğŸ’¾ ä¿å­˜ã—ã¾ã—ãŸ: {output_path.name}\")\n",
    "        # 'except'ã®ã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆã‚’'try'ã«åˆã‚ã›ã‚‹\n",
    "        except Exception as e:\n",
    "            print(f\"  -> âŒ ã“ã®ç•Œé¢ã®ä½œæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸãŸã‚ã€ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™: {e}\")\n",
    "\n",
    "    def run(self):\n",
    "        al_slabs, cathode_slabs = self.find_and_categorize_surfaces()\n",
    "        if not al_slabs and not cathode_slabs:\n",
    "            print(\" -> å‡¦ç†å¯¾è±¡ã®è¡¨é¢ãƒ•ã‚¡ã‚¤ãƒ«ãŒãªã„ãŸã‚ã€çµ‚äº†ã—ã¾ã™ã€‚\")\n",
    "            return\n",
    "\n",
    "        print(\"\\n--- ã‚«ãƒ†ã‚´ãƒª1: Alã‚’å«ã‚€ç•Œé¢ ---\")\n",
    "        if al_slabs and cathode_slabs:\n",
    "            for al_path in al_slabs:\n",
    "                for cathode_path in cathode_slabs:\n",
    "                    self.create_and_optimize_interface(al_path, cathode_path)\n",
    "        else:\n",
    "            print(\" -> ã‚¹ã‚­ãƒƒãƒ— (Alè¡¨é¢ã¾ãŸã¯æ­£æ¥µæè¡¨é¢ã®ã„ãšã‚Œã‹ãŒä¸è¶³)\")\n",
    "\n",
    "        # print(\"\\n--- ã‚«ãƒ†ã‚´ãƒª2: Alã‚’å«ã¾ãªã„ç•Œé¢ ---\")\n",
    "        # if len(cathode_slabs) >= 2:\n",
    "        #     for pair in itertools.combinations(cathode_slabs, 2):\n",
    "        #         self.create_and_optimize_interface(pair[0], pair[1])\n",
    "        # else:\n",
    "        #     print(\" -> ã‚¹ã‚­ãƒƒãƒ— (æ­£æ¥µæè¡¨é¢ãŒ2ã¤æœªæº€)\")\n",
    "        print(\"\\nâœ¨ STEP 2 å®Œäº†ã€‚\")\n",
    "\n",
    "\n",
    "        \n",
    "def show_results_viewer(results_dir):\n",
    "    print(f\"\\n--- ğŸ”¬ çµæœãƒ“ãƒ¥ãƒ¼ãƒ¯ãƒ¼: '{results_dir}' ---\")\n",
    "    files = sorted(list(Path(results_dir).glob(\"*.cif\")))\n",
    "    if not files:\n",
    "        print(\"è¡¨ç¤ºã§ãã‚‹æ§‹é€ ãŒã‚ã‚Šã¾ã›ã‚“ã€‚\")\n",
    "        return\n",
    "    options = {\"-- é¸æŠã—ã¦ãã ã•ã„ --\": None}\n",
    "    options.update({p.name: p for p in files})\n",
    "    widgets.interact(\n",
    "        lambda file_path: display(nv.show_ase(read(file_path)) if file_path else None),\n",
    "        file_path=widgets.Dropdown(options=options, description='Interface:', layout={'width': 'max-content'})\n",
    "    )\n",
    "\n",
    "# --- ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œéƒ¨ ---\n",
    "if __name__ == \"__main__\":\n",
    "    # ===== è¨­å®šé …ç›® =====\n",
    "    # 1. Trajectoryãƒ•ã‚¡ã‚¤ãƒ«ãŒä¿å­˜ã•ã‚Œã¦ã„ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª\n",
    "    OPTIMIZATION_OUTPUT_DIR = \"/home/jovyan/Kaori/MD/LiB_2/structure/output\"\n",
    "\n",
    "    # 2. æœ€é©åŒ–ã—ãŸç•Œé¢ã®ä¿å­˜å…ˆ\n",
    "    INTERFACES_DIR = \"/home/jovyan/Kaori/MD/LiB_2/structure/output/optimized_interfaces\"\n",
    "    # ====================\n",
    "\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    # STEP 1: ãƒ¡ãƒ¢ãƒªç®¡ç† (traj -> xyzå¤‰æ› & å‰Šé™¤)\n",
    "    cleanup = TrajectoryCleanup(OPTIMIZATION_OUTPUT_DIR)\n",
    "    cleanup.run()\n",
    "\n",
    "    # STEP 2: ç•Œé¢ã®æ§‹ç¯‰ã¨æœ€é©åŒ–\n",
    "    interface_opt = InterfaceOptimizer(surfaces_dir=OPTIMIZATION_OUTPUT_DIR, interfaces_dir=INTERFACES_DIR)\n",
    "    interface_opt.run()\n",
    "\n",
    "    print(\"\\n\\nâœ¨ å…¨ã¦ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãŒå®Œäº†ã—ã¾ã—ãŸã€‚ âœ¨\")\n",
    "\n",
    "    # STEP 3: çµæœã®è¡¨ç¤º\n",
    "    show_results_viewer(INTERFACES_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32da73ea-40fa-42da-8ea3-ba3a2faaf728",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 219)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m<tokenize>:219\u001b[0;36m\u001b[0m\n\u001b[0;31m    def cut_slab_to_size(self, slab, target_xy=(12.0, 12.0)):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Trajectoryãƒ•ã‚¡ã‚¤ãƒ«ã®æ•´ç†ã¨ã€ãã‚Œã«åŸºã¥ãç•Œé¢æ§‹ç¯‰ãƒ»æœ€é©åŒ–ã‚’è‡ªå‹•åŒ–ã™ã‚‹ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã€‚\n",
    "\n",
    "[ã‚¨ãƒ©ãƒ¼è€æ€§å¼·åŒ–ç‰ˆ]\n",
    "- ç ´æã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ãªã©ã€ç‰¹å®šãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¦ã‚‚å…¨ä½“ãŒåœæ­¢ã›ãšã€\n",
    "  æ¬¡ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†ã‚’ç¶šè¡Œã—ã¾ã™ã€‚\n",
    "\n",
    "STEP 1: Trajectoryãƒ•ã‚¡ã‚¤ãƒ«ã®åˆ†æã¨ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—\n",
    "  - 0KBã®.trajãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆå¤±æ•—ã—ãŸè¨ˆç®—ï¼‰ã‚’å‰Šé™¤\n",
    "  - æ­£å¸¸ãª.trajãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆæœŸ/æœ€çµ‚æ§‹é€ ã®.xyzã«å¤‰æ›ã—ã€å…ƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤\n",
    "\n",
    "STEP 2: ç•Œé¢ã®æ§‹ç¯‰ã¨æœ€é©åŒ–\n",
    "  - STEP 1ã§ç”Ÿæˆã•ã‚ŒãŸæœ€çµ‚æ§‹é€ (.xyz)ã‚’ç”¨ã„ã¦ç•Œé¢ã‚’æ§‹ç¯‰\n",
    "  - Matlantisã‚’ç”¨ã„ã¦åŸå­ä½ç½®ã®ã¿ã‚’æœ€é©åŒ–\n",
    "\"\"\"\n",
    "import os\n",
    "import itertools\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import nglview as nv\n",
    "\n",
    "# ASE\n",
    "from ase.io import read, write\n",
    "from ase.build import stack,cut\n",
    "\n",
    "# Matlantis / PFP\n",
    "from matlantis_features.atoms import MatlantisAtoms\n",
    "from matlantis_features.features.common.opt import FireLBFGSASEOptFeature\n",
    "from matlantis_features.utils.calculators import pfp_estimator_fn\n",
    "from pfp_api_client.pfp.estimator import EstimatorCalcMode\n",
    "\n",
    "# --- STEP 1: Trajectoryãƒ•ã‚¡ã‚¤ãƒ«ã®æ•´ç†ã‚¯ãƒ©ã‚¹ ---\n",
    "class TrajectoryCleanup:\n",
    "    \"\"\"\n",
    "    .trajãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†æã—ã€.xyzã«å¤‰æ›ã—ã¦ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã™ã‚‹ã‚¯ãƒ©ã‚¹ã€‚\n",
    "    \"\"\"\n",
    "    def __init__(self, directory):\n",
    "        self.directory = Path(directory)\n",
    "        print(\"--- STEP 1: Trajectoryãƒ•ã‚¡ã‚¤ãƒ«ã®åˆ†æã¨æ•´ç†ã‚’é–‹å§‹ ---\")\n",
    "        if not self.directory.is_dir():\n",
    "            print(f\"ğŸ›‘ ã‚¨ãƒ©ãƒ¼: ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª '{self.directory}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚\")\n",
    "            self.files_to_process = []\n",
    "        else:\n",
    "            self.files_to_process = list(self.directory.glob(\"*.traj\"))\n",
    "            print(f\"ğŸ” '{self.directory}' ã‹ã‚‰ {len(self.files_to_process)} å€‹ã® .traj ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç™ºè¦‹ã€‚\")\n",
    "\n",
    "    def process_file(self, traj_path):\n",
    "        \"\"\"\n",
    "        1ã¤ã®.trajãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã™ã‚‹ã€‚\n",
    "        [ä¿®æ­£] ã“ã®é–¢æ•°å…¨ä½“ã‚’try...exceptã§å›²ã¿ã€ã‚¨ãƒ©ãƒ¼è€æ€§ã‚’å‘ä¸Šã€‚\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã‚’ç¢ºèª\n",
    "            file_size = traj_path.stat().st_size\n",
    "            if file_size == 0:\n",
    "                print(f\"  -> ğŸ—‘ï¸  0KBãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¾ã™: {traj_path.name}\")\n",
    "                os.remove(traj_path)\n",
    "                return\n",
    "\n",
    "            # æ­£å¸¸ãªãƒ•ã‚¡ã‚¤ãƒ«ã¯å¤‰æ›\n",
    "            base_name = traj_path.stem\n",
    "            initial_xyz_path = self.directory / f\"{base_name}_initial.xyz\"\n",
    "            final_xyz_path = self.directory / f\"{base_name}_final.xyz\"\n",
    "            \n",
    "            print(f\"  -> ğŸ”„ å¤‰æ›ä¸­: {traj_path.name}\")\n",
    "            \n",
    "            # Trajectoryã‹ã‚‰åˆæœŸæ§‹é€ ã¨æœ€çµ‚æ§‹é€ ã‚’èª­ã¿è¾¼ã¿\n",
    "            atoms_list = read(traj_path, index=\":\")\n",
    "            if not atoms_list:\n",
    "                print(f\"  -> âŒ èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ï¼ˆç©ºã®Trajectoryï¼‰ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¾ã™: {traj_path.name}\")\n",
    "                os.remove(traj_path)\n",
    "                return\n",
    "\n",
    "            # .xyzãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜\n",
    "            write(str(initial_xyz_path), atoms_list[0])\n",
    "            write(str(final_xyz_path), atoms_list[-1])\n",
    "            \n",
    "            # å…ƒã®.trajãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤\n",
    "            os.remove(traj_path)\n",
    "            print(f\"  -> âœ”ï¸ å¤‰æ›æˆåŠŸã€å…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¾ã—ãŸ: {traj_path.name}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            # äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã€ãƒ­ã‚°ã‚’å‡ºåŠ›ã—ã¦å‡¦ç†ã‚’ç¶šè¡Œ\n",
    "            print(f\"  -> âŒ é‡å¤§ãªã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸãŸã‚ã€ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ ({traj_path.name}): {e}\")\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"å…¨ã¦ã®å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ã«å¯¾ã—ã¦å‡¦ç†ã‚’å®Ÿè¡Œã™ã‚‹ã€‚\"\"\"\n",
    "        if not self.files_to_process:\n",
    "            print(\" -> å‡¦ç†å¯¾è±¡ã®.trajãƒ•ã‚¡ã‚¤ãƒ«ãŒãªã„ãŸã‚ã€ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚\")\n",
    "            return\n",
    "        for traj_file in self.files_to_process:\n",
    "            self.process_file(traj_file)\n",
    "        print(\"\\nâœ¨ STEP 1 å®Œäº†ã€‚\")\n",
    "\n",
    "\n",
    "# --- Matlantisæœ€é©åŒ–é–¢æ•° (å…±é€š) ---\n",
    "def run_matlantis_optimization(atoms, trajectory_path, fmax=0.05, name=\"structure\"):\n",
    "    print(f\"  -> Matlantisæœ€é©åŒ–é–‹å§‹ ({name}, fmax = {fmax}) ...\")\n",
    "    matlantis_atoms = MatlantisAtoms(atoms)\n",
    "    estimator_function = pfp_estimator_fn(\n",
    "        model_version='v7.0.0', calc_mode=EstimatorCalcMode.CRYSTAL_PLUS_D3\n",
    "    )\n",
    "    position_optimizer = FireLBFGSASEOptFeature(\n",
    "        estimator_fn=estimator_function, filter=False, trajectory=str(trajectory_path),\n",
    "        n_run=5000, fmax=fmax, show_progress_bar=True\n",
    "    )\n",
    "    try:\n",
    "        result = position_optimizer(matlantis_atoms)\n",
    "        optimized_atoms = result.atoms.ase_atoms\n",
    "        final_energy = result.output.energy_log[-1]\n",
    "        print(f\"  -> âœ”ï¸ æœ€é©åŒ–å®Œäº†ï¼ ã‚¨ãƒãƒ«ã‚®ãƒ¼: {final_energy:.3f} eV\")\n",
    "        xyz_save_path = Path(trajectory_path).with_suffix('.xyz')\n",
    "        print(f\"  -> ğŸ’¾ æœ€é©åŒ–å¾Œã®æ§‹é€ ã‚’ä¿å­˜ã—ã¾ã™: {xyz_save_path.name}\")\n",
    "        write(str(xyz_save_path), optimized_atoms)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"  -> âŒ æœ€é©åŒ–ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}\")\n",
    "        return False\n",
    "\n",
    "# --- STEP 2: ç•Œé¢æœ€é©åŒ–ã‚¯ãƒ©ã‚¹ ---\n",
    "class InterfaceOptimizer:\n",
    "    def __init__(self, surfaces_dir, interfaces_dir):\n",
    "        self.surfaces_dir = Path(surfaces_dir)\n",
    "        self.interfaces_dir = Path(interfaces_dir)\n",
    "        self.interfaces_dir.mkdir(parents=True, exist_ok=True)\n",
    "        print(f\"\\n--- STEP 2: ç•Œé¢æ§‹ç¯‰ãƒ»æœ€é©åŒ–ãƒ—ãƒ­ã‚»ã‚¹ã‚’é–‹å§‹ ---\")\n",
    "        print(f\"âœ… ç•Œé¢æ§‹é€ ã®ä¿å­˜å…ˆ: '{self.interfaces_dir}'\")\n",
    "\n",
    "    # def build_and_cut_interface(self, slab1, slab2, target_xy=(12.0, 12.0), target_z=20.0, separation=2.0):\n",
    "    #     \"\"\"\n",
    "    #     ç·©å’Œæ¸ˆã¿è¡¨é¢ã‚’ç¶­æŒã—ã¤ã¤ã€æŒ‡å®šã‚µã‚¤ã‚ºã«ç•Œé¢ã‚’ç²¾å¯†ã«æ§‹ç¯‰ãƒ»ã‚«ãƒƒãƒˆã™ã‚‹ã€‚\n",
    "    #     \"\"\"\n",
    "    #     print(f\"    -> ç•Œé¢ã‚’ ({target_xy[0]}, {target_xy[1]}, {target_z}) Ã… ã«ç²¾å¯†æ§‹ç¯‰...\")\n",
    "    #     # Step 1: å„ã‚¹ãƒ©ãƒ–ã‚’X,Yæ–¹å‘ã«ã‚«ãƒƒãƒˆ\n",
    "    #     # cut_slab1 = cut(slab1, a=(target_xy[0], 0, 0), b=(0, target_xy[1], 0), origo=(0,0,0))\n",
    "    #     # cut_slab2 = cut(slab2, a=(target_xy[0], 0, 0), b=(0, target_xy[1], 0), origo=(0,0,0))\n",
    "    #     position1 = slab1.get_positions()\n",
    "    #     position2 = slab2.get_positions()\n",
    "    #     # æ¡ä»¶ï¼ˆx>=12 ã¾ãŸã¯ y>=12ï¼‰ã«åˆã†åŸå­ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ¢ã™\n",
    "    #     # np.whereã¯æ¡ä»¶ã«åˆã†è¦ç´ ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’è¿”ã™\n",
    "    #     indices_to_delete1 = np.where(\n",
    "    #         (position1[:, 0] >= target_xy[0]) | (position1[:, 1] >= target_xy[1])\n",
    "    #     )[0]\n",
    "    #     indices_to_delete2 = np.where(\n",
    "    #         (position2[:, 0] >= target_xy[0]) | (position2[:, 1] >= target_xy[1])\n",
    "    #     )[0]\n",
    "    #     # è¦‹ã¤ã‹ã£ãŸã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®åŸå­ã‚’å‰Šé™¤\n",
    "    #     cut_slab1=slab1.copy()\n",
    "    #     cut_slab2=slab2.copy()\n",
    "    #     del cut_slab1[indices_to_delete1]\n",
    "    #     del cut_slab2[indices_to_delete2]\n",
    "    #     print(f\"ç•Œé¢ã‹ã‚‰é ã„åŸå­ã‚’ {len(indices_to_delete1)},{len(indices_to_delete2)}å‰Šé™¤\")\n",
    "    #     # Step 2: ç·©å’Œæ¸ˆã¿è¡¨é¢ã®ä½ç½®ã‚’ç‰¹å®š\n",
    "    #     z1_max = cut_slab1.positions[:, 2].max()\n",
    "    #     z2_min = cut_slab2.positions[:, 2].min()\n",
    "\n",
    "    #     # Step 3: ç•Œé¢ãŒä¸­å¤®ã«æ¥ã‚‹ã‚ˆã†ã«å„ã‚¹ãƒ©ãƒ–ã‚’Zæ–¹å‘ã«ã‚·ãƒ•ãƒˆ\n",
    "    #     cut_slab1.positions[:, 2] += (target_z / 2) - (separation / 2) - z1_max\n",
    "    #     cut_slab2.positions[:, 2] += (target_z / 2) + (separation / 2) - z2_min\n",
    "        \n",
    "    #     # Step 4: 2ã¤ã®ã‚¹ãƒ©ãƒ–ã‚’çµåˆ\n",
    "    #     interface = cut_slab1 + cut_slab2\n",
    "        \n",
    "    #     # Step 5: æœ€çµ‚çš„ãªã‚»ãƒ«ã‚’è¨­å®š (åŸå­ã¯ã‚¹ã‚±ãƒ¼ãƒ«ã—ãªã„)\n",
    "    #     cell_z=target_z*2+2\n",
    "    #     interface.set_cell([target_xy[0], target_xy[1], cell_z], scale_atoms=False)\n",
    "    #     interface.pbc = (True, True, True) # MDç”¨ã«PBCã‚’Trueã«è¨­å®š\n",
    "        \n",
    "    #     # Step 6: ã‚»ãƒ«ã‹ã‚‰ã¯ã¿å‡ºã—ãŸåŸå­ï¼ˆç•Œé¢ã‹ã‚‰é ã„åŸå­ï¼‰ã‚’å‰Šé™¤\n",
    "    #     # np.deleteã¯ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®é‡è¤‡ã‚’è¨±ã•ãªã„ãŸã‚ã€ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—\n",
    "        \n",
    "    #     # if len(indices_to_delete) > 0:\n",
    "    #     #     del interface[indices_to_delete]\n",
    "    #     #     print(f\"    -> ç•Œé¢ã‹ã‚‰é ã„åŸå­ã‚’ {len(indices_to_delete)} å€‹å‰Šé™¤ã—ã¾ã—ãŸã€‚\")\n",
    "        \n",
    "    #     # Step 7: åŸå­ã‚’ã‚»ãƒ«å†…ã«æŠ˜ã‚ŠãŸãŸã‚€\n",
    "    #     interface.wrap()\n",
    "    #     print(f\"    -> æ§‹ç¯‰å¾Œã®åŸå­æ•°: {len(interface)}\")\n",
    "    #     return interface\n",
    "    def build_and_cut_interface(self, slab1, slab2, target_xy=(12.0, 12.0), separation=2.0, vacuum=1.0):\n",
    "        \"\"\"\n",
    "        ç·©å’Œæ¸ˆã¿è¡¨é¢ã‚’ç¶­æŒã—ã¤ã¤ã€æŒ‡å®šã‚µã‚¤ã‚ºã§2å±¤ã®ç•Œé¢ã‚’æ§‹ç¯‰ã™ã‚‹ã€‚\n",
    "        \"\"\"\n",
    "        print(f\"Â  Â  -> 2å±¤ç•Œé¢ã‚’ ({target_xy[0]}, {target_xy[1]}) Ã… ã«æ§‹ç¯‰...\")\n",
    "Â  Â  Â  Â Â \n",
    "        # Step 1: å„ã‚¹ãƒ©ãƒ–ã‹ã‚‰æŒ‡å®šç¯„å›²å¤–ã®åŸå­ã‚’å‰Šé™¤\n",
    "        position1 = slab1.get_positions()\n",
    "        position2 = slab2.get_positions()\n",
    "        indices_to_delete1 = np.where(\n",
    "            (position1[:, 0] >= target_xy[0]) | (position1[:, 1] >= target_xy[1])\n",
    "        )[0]\n",
    "        indices_to_delete2 = np.where(\n",
    "            (position2[:, 0] >= target_xy[0]) | (position2[:, 1] >= target_xy[1])\n",
    "        )[0]\n",
    "        cut_slab1=slab1.copy()\n",
    "        cut_slab2=slab2.copy()\n",
    "        if len(indices_to_delete1) > 0: del cut_slab1[indices_to_delete1]\n",
    "        if len(indices_to_delete2) > 0: del cut_slab2[indices_to_delete2]\n",
    "        print(f\"Â  Â  -> ã‚¹ãƒ©ãƒ–1, 2ã‹ã‚‰ãã‚Œãã‚Œ {len(indices_to_delete1)}, {len(indices_to_delete2)} å€‹ã®åŸå­ã‚’å‰Šé™¤ã€‚\")\n",
    "Â  Â  Â  Â Â \n",
    "        # Step 2: ç•Œé¢é–“ã®è·é›¢ã‚’èª¿æ•´ã—ã¦ã‚¹ã‚¿ãƒƒã‚¯\n",
    "        z1_max = cut_slab1.positions[:, 2].max()\n",
    "        z2_min = cut_slab2.positions[:, 2].min()\n",
    "        cut_slab2.positions[:, 2] += z1_max - z2_min + separation\n",
    "Â  Â  Â  Â Â \n",
    "        # Step 3: 2ã¤ã®ã‚¹ãƒ©ãƒ–ã‚’çµåˆã—ã€æ–°ã—ã„ã‚»ãƒ«ã‚’è¨­å®š\n",
    "        interface = cut_slab1 + cut_slab2\n",
    "        interface.set_cell([target_xy[0], target_xy[1], 50], scale_atoms=False) # Zã¯ä»®ã®é«˜ã•\n",
    "Â  Â  Â  Â Â \n",
    "        # Step 4: Zæ–¹å‘ã®å‘¨æœŸæ€§ã‚’ç„¡ãã—ã€çœŸç©ºå±¤ã‚’è¨­ã‘ã¦ä¸­å¤®ã«é…ç½®\n",
    "        interface.pbc = (True, True, False)\n",
    "        interface.center(vacuum=vacuum, axis=2)\n",
    "Â  Â  Â  Â Â \n",
    "        print(f\"Â  Â  -> æ§‹ç¯‰å¾Œã®åŸå­æ•°: {len(interface)}ã€‚Zæ–¹å‘ã«çœŸç©ºå±¤ã‚’æŒã¤2å±¤æ§‹é€ ã‚’ä½œæˆã€‚\")\n",
    "        return interface\n",
    "    def cut_slab_to_size(self, slab, target_xy=(12.0, 12.0)):\n",
    "        \"\"\"\n",
    "        ASEã®cutæ©Ÿèƒ½ã‚’ä½¿ã£ã¦ã€ã‚¹ãƒ©ãƒ–ã‚’ç›®æ¨™ã®x,yã‚µã‚¤ã‚ºã«åˆ‡ã‚Šå‡ºã™ã€‚\n",
    "        \"\"\"\n",
    "        print(f\"    -> ã‚¹ãƒ©ãƒ–ã‚’ ({target_xy[0]}, {target_xy[1]}) Ã… ã«ã‚«ãƒƒãƒˆ...\")\n",
    "        # æ–°ã—ã„ã‚»ãƒ«ã®åŸºåº•ãƒ™ã‚¯ãƒˆãƒ«ã‚’å®šç¾©\n",
    "        new_a = (target_xy[0], 0, 0)\n",
    "        new_b = (0, target_xy[1], 0)\n",
    "        \n",
    "        # å…ƒã®ã‚¹ãƒ©ãƒ–ã®ä¸­å¿ƒã‚’åŸºæº–ã«ã‚«ãƒƒãƒˆ\n",
    "        origo_cart = slab.cell.sum(axis=0) / 2 - (target_xy[0]/2, target_xy[1]/2, 0)\n",
    "        origo = np.linalg.solve(slab.cell.T, origo_cart.T)\n",
    "\n",
    "        cut_slab = cut(slab, a=new_a, b=new_b, origo=origo)\n",
    "        cut_slab.pbc = (True, True, False) # pbcã‚’å†è¨­å®š\n",
    "        print(f\"    -> ã‚«ãƒƒãƒˆå¾Œã®åŸå­æ•°: {len(cut_slab)}\")\n",
    "        return cut_slab\n",
    "\n",
    "    def find_and_categorize_surfaces(self):\n",
    "        print(f\"ğŸ” '{self.surfaces_dir}' ã‹ã‚‰æœ€é©åŒ–æ¸ˆã¿è¡¨é¢ (*_final.xyz) ã‚’åˆ†é¡ä¸­...\")\n",
    "        if not self.surfaces_dir.is_dir():\n",
    "             print(f\"ğŸ›‘ ã‚¨ãƒ©ãƒ¼: è¡¨é¢ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª '{self.surfaces_dir}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚\")\n",
    "             return [], []\n",
    "        \n",
    "        all_surfaces = list(self.surfaces_dir.glob(\"*_final.xyz\"))\n",
    "        \n",
    "        al_surfaces = [p for p in all_surfaces if \"Al\" in p.stem]\n",
    "        cathode_surfaces = [p for p in all_surfaces if \"NMC\" in p.stem]\n",
    "        print(f\"  - Alè¡¨é¢: {len(al_surfaces)}å€‹,  æ­£æ¥µæè¡¨é¢: {len(cathode_surfaces)}å€‹\")\n",
    "        return al_surfaces, cathode_surfaces\n",
    "\n",
    "    def create_and_optimize_interface(self, slab1_path, slab2_path):\n",
    "        slab1_name = slab1_path.stem.replace('_pos_opt_final', '').replace('_cell_opt_final', '')\n",
    "        slab2_name = slab2_path.stem.replace('_pos_opt_final', '').replace('_cell_opt_final', '')\n",
    "        interface_name = f\"Interface_{slab1_name}_on_{slab2_name}\"\n",
    "        output_path = self.interfaces_dir / f\"{interface_name}.cif\"\n",
    "        \n",
    "        if output_path.exists():\n",
    "            print(f\"âœ… æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚ã‚Šã€ã‚¹ã‚­ãƒƒãƒ—: {output_path.name}\")\n",
    "            return\n",
    "\n",
    "        print(f\"\\n--- ç•Œé¢ã‚’æ§‹ç¯‰ãƒ»æœ€é©åŒ–: {slab1_name} + {slab2_name} ---\")\n",
    "        try:\n",
    "            slab1, slab2 = read(slab1_path), read(slab2_path)\n",
    "            # ä¿®æ­£ã•ã‚ŒãŸé–¢æ•°ã‚’å‘¼ã³å‡ºã™\n",
    "            interface = self.build_and_cut_interface(slab1, slab2) \n",
    "            traj_path = self.interfaces_dir / f\"{interface_name}.traj\"\n",
    "            if run_matlantis_optimization(interface, traj_path, fmax=0.05, name=interface_name):\n",
    "                write(str(output_path), interface)\n",
    "                print(f\"  -> ğŸ’¾ ä¿å­˜ã—ã¾ã—ãŸ: {output_path.name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  -> âŒ ã“ã®ç•Œé¢ã®ä½œæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸãŸã‚ã€ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™: {e}\")\n",
    "\n",
    "    def run(self):\n",
    "        al_slabs, cathode_slabs = self.find_and_categorize_surfaces()\n",
    "        if not al_slabs and not cathode_slabs:\n",
    "            print(\" -> å‡¦ç†å¯¾è±¡ã®è¡¨é¢ãƒ•ã‚¡ã‚¤ãƒ«ãŒãªã„ãŸã‚ã€çµ‚äº†ã—ã¾ã™ã€‚\")\n",
    "            return\n",
    "            \n",
    "        print(\"\\n--- ã‚«ãƒ†ã‚´ãƒª1: Alã‚’å«ã‚€ç•Œé¢ ---\")\n",
    "        if al_slabs and cathode_slabs:\n",
    "            for al_path in al_slabs:\n",
    "                for cathode_path in cathode_slabs:\n",
    "                    self.create_and_optimize_interface(al_path, cathode_path)\n",
    "        else:\n",
    "            print(\" -> ã‚¹ã‚­ãƒƒãƒ— (Alè¡¨é¢ã¾ãŸã¯æ­£æ¥µæè¡¨é¢ã®ã„ãšã‚Œã‹ãŒä¸è¶³)\")\n",
    "            \n",
    "        # print(\"\\n--- ã‚«ãƒ†ã‚´ãƒª2: Alã‚’å«ã¾ãªã„ç•Œé¢ ---\")\n",
    "        # if len(cathode_slabs) >= 2:\n",
    "        #     for pair in itertools.combinations(cathode_slabs, 2):\n",
    "        #         self.create_and_optimize_interface(pair[0], pair[1])\n",
    "        # else:\n",
    "        #     print(\" -> ã‚¹ã‚­ãƒƒãƒ— (æ­£æ¥µæè¡¨é¢ãŒ2ã¤æœªæº€)\")\n",
    "        print(\"\\nâœ¨ STEP 2 å®Œäº†ã€‚\")\n",
    "\n",
    "def show_results_viewer(results_dir):\n",
    "    print(f\"\\n--- ğŸ”¬ çµæœãƒ“ãƒ¥ãƒ¼ãƒ¯ãƒ¼: '{results_dir}' ---\")\n",
    "    files = sorted(list(Path(results_dir).glob(\"*.cif\")))\n",
    "    if not files:\n",
    "        print(\"è¡¨ç¤ºã§ãã‚‹æ§‹é€ ãŒã‚ã‚Šã¾ã›ã‚“ã€‚\")\n",
    "        return\n",
    "    options = {\"-- é¸æŠã—ã¦ãã ã•ã„ --\": None}\n",
    "    options.update({p.name: p for p in files})\n",
    "    widgets.interact(\n",
    "        lambda file_path: display(nv.show_ase(read(file_path)) if file_path else None),\n",
    "        file_path=widgets.Dropdown(options=options, description='Interface:', layout={'width': 'max-content'})\n",
    "    )\n",
    "\n",
    "# --- ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œéƒ¨ ---\n",
    "if __name__ == \"__main__\":\n",
    "    # ===== è¨­å®šé …ç›® =====\n",
    "    # 1. Trajectoryãƒ•ã‚¡ã‚¤ãƒ«ãŒä¿å­˜ã•ã‚Œã¦ã„ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª\n",
    "    OPTIMIZATION_OUTPUT_DIR = \"/home/jovyan/Kaori/MD/LiB_2/structure/output\"\n",
    "    \n",
    "    # 2. æœ€é©åŒ–ã—ãŸç•Œé¢ã®ä¿å­˜å…ˆ\n",
    "    INTERFACES_DIR = \"/home/jovyan/Kaori/MD/LiB_2/structure/output/optimized_interfaces\"\n",
    "    # ====================\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    # STEP 1: ãƒ¡ãƒ¢ãƒªç®¡ç† (traj -> xyzå¤‰æ› & å‰Šé™¤)\n",
    "    cleanup = TrajectoryCleanup(OPTIMIZATION_OUTPUT_DIR)\n",
    "    cleanup.run()\n",
    "    \n",
    "    # STEP 2: ç•Œé¢ã®æ§‹ç¯‰ã¨æœ€é©åŒ–\n",
    "    interface_opt = InterfaceOptimizer(surfaces_dir=OPTIMIZATION_OUTPUT_DIR, interfaces_dir=INTERFACES_DIR)\n",
    "    interface_opt.run()\n",
    "    \n",
    "    print(\"\\n\\nâœ¨ å…¨ã¦ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãŒå®Œäº†ã—ã¾ã—ãŸã€‚ âœ¨\")\n",
    "    \n",
    "    # STEP 3: çµæœã®è¡¨ç¤º\n",
    "    show_results_viewer(INTERFACES_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31835dfd-a99d-46d3-9600-26081f4d283d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a5dedf9-9dbb-45b3-9ef2-1b27b5b9386e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ase.io import read, write,Trajectory\n",
    "# from pfcc.extras import Trajectory\n",
    "atoms=Trajectory(\"/home/jovyan/Kaori/MD/LiB_2/structure/output/Al2O3_10-12_(1, 0, 2)_cell_opt.traj\")[-1]\n",
    "ini=Trajectory(\"/home/jovyan/Kaori/MD/LiB_2/structure/output/Al2O3_10-12_(1, 0, 2)_cell_opt.traj\")[0]\n",
    "write(\"/home/jovyan/Kaori/MD/LiB_2/structure/output/Al2O3_10-12_(1, 0, 2)_cell_opt_initial.xyz\", ini)\n",
    "\n",
    "write(\"/home/jovyan/Kaori/MD/LiB_2/structure/output/Al2O3_10-12_(1, 0, 2)_cell_opt_final.xyz\", atoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5f2bb04-974c-4ced-bbc9-8330f92b3163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "971c267cecbc4e3e9549a52c21cc64ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 64\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mase\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbuild\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m sort\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msella\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Sella, Constraints\n\u001b[0;32m---> 64\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch_dftd\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtorch_dftd3_calculator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TorchDFTD3Calculator\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# PFP\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpfp_api_client\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpfp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcalculators\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mase_calculator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ASECalculator\n",
      "File \u001b[0;32m~/.py311/lib/python3.11/site-packages/torch_dftd/torch_dftd3_calculator.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dict, Optional, Tuple\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Atoms\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mase\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcalculators\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcalculator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Calculator, PropertyNotImplementedError, all_changes\n",
      "File \u001b[0;32m~/.py311/lib/python3.11/site-packages/torch/__init__.py:2240\u001b[0m\n\u001b[1;32m   2236\u001b[0m sys\u001b[38;5;241m.\u001b[39mmodules\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.classes\u001b[39m\u001b[38;5;124m\"\u001b[39m, classes)\n\u001b[1;32m   2238\u001b[0m \u001b[38;5;66;03m# quantization depends on torch.fx and torch.ops\u001b[39;00m\n\u001b[1;32m   2239\u001b[0m \u001b[38;5;66;03m# Import quantization\u001b[39;00m\n\u001b[0;32m-> 2240\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m quantization \u001b[38;5;28;01mas\u001b[39;00m quantization  \u001b[38;5;66;03m# usort: skip\u001b[39;00m\n\u001b[1;32m   2242\u001b[0m \u001b[38;5;66;03m# Import the quasi random sampler\u001b[39;00m\n\u001b[1;32m   2243\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m quasirandom \u001b[38;5;28;01mas\u001b[39;00m quasirandom  \u001b[38;5;66;03m# usort: skip\u001b[39;00m\n",
      "File \u001b[0;32m~/.py311/lib/python3.11/site-packages/torch/quantization/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# mypy: allow-untyped-defs\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfake_quantize\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfuse_modules\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m fuse_modules\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfuser_method_mappings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n",
      "File \u001b[0;32m~/.py311/lib/python3.11/site-packages/torch/quantization/fake_quantize.py:10\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# flake8: noqa: F401\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mThis file is in the process of migration to `torch/ao/quantization`, and\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03mis kept here for compatibility while the migration process is ongoing.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03mhere.\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mao\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfake_quantize\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     11\u001b[0m     _is_fake_quant_script_module,\n\u001b[1;32m     12\u001b[0m     _is_per_channel,\n\u001b[1;32m     13\u001b[0m     _is_per_tensor,\n\u001b[1;32m     14\u001b[0m     _is_symmetric_quant,\n\u001b[1;32m     15\u001b[0m     default_fake_quant,\n\u001b[1;32m     16\u001b[0m     default_fixed_qparams_range_0to1_fake_quant,\n\u001b[1;32m     17\u001b[0m     default_fixed_qparams_range_neg1to1_fake_quant,\n\u001b[1;32m     18\u001b[0m     default_fused_act_fake_quant,\n\u001b[1;32m     19\u001b[0m     default_fused_per_channel_wt_fake_quant,\n\u001b[1;32m     20\u001b[0m     default_fused_wt_fake_quant,\n\u001b[1;32m     21\u001b[0m     default_histogram_fake_quant,\n\u001b[1;32m     22\u001b[0m     default_per_channel_weight_fake_quant,\n\u001b[1;32m     23\u001b[0m     default_weight_fake_quant,\n\u001b[1;32m     24\u001b[0m     disable_fake_quant,\n\u001b[1;32m     25\u001b[0m     disable_observer,\n\u001b[1;32m     26\u001b[0m     enable_fake_quant,\n\u001b[1;32m     27\u001b[0m     enable_observer,\n\u001b[1;32m     28\u001b[0m     FakeQuantize,\n\u001b[1;32m     29\u001b[0m     FakeQuantizeBase,\n\u001b[1;32m     30\u001b[0m     FixedQParamsFakeQuantize,\n\u001b[1;32m     31\u001b[0m     FusedMovingAvgObsFakeQuantize,\n\u001b[1;32m     32\u001b[0m )\n",
      "File \u001b[0;32m~/.py311/lib/python3.11/site-packages/torch/ao/quantization/__init__.py:12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfuser_method_mappings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mobserver\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpt2e\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_numeric_debugger\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     compare_results,\n\u001b[1;32m     14\u001b[0m     CUSTOM_KEY,\n\u001b[1;32m     15\u001b[0m     extract_results_from_loggers,\n\u001b[1;32m     16\u001b[0m     generate_numeric_debug_handle,\n\u001b[1;32m     17\u001b[0m     NUMERIC_DEBUG_HANDLE_KEY,\n\u001b[1;32m     18\u001b[0m     prepare_for_propagation_comparison,\n\u001b[1;32m     19\u001b[0m )\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpt2e\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexport_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     21\u001b[0m     _allow_exported_model_train_eval \u001b[38;5;28;01mas\u001b[39;00m allow_exported_model_train_eval,\n\u001b[1;32m     22\u001b[0m     _move_exported_model_to_eval \u001b[38;5;28;01mas\u001b[39;00m move_exported_model_to_eval,\n\u001b[1;32m     23\u001b[0m     _move_exported_model_to_train \u001b[38;5;28;01mas\u001b[39;00m move_exported_model_to_train,\n\u001b[1;32m     24\u001b[0m )\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mqconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n",
      "File \u001b[0;32m~/.py311/lib/python3.11/site-packages/torch/ao/quantization/pt2e/_numeric_debugger.py:9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mao\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mns\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compute_sqnr\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mao\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpt2e\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m bfs_trace_with_node_process\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ExportedProgram\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GraphModule, Node\n",
      "File \u001b[0;32m~/.py311/lib/python3.11/site-packages/torch/ao/quantization/pt2e/graph_utils.py:9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, Callable, Optional, Union\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ExportedProgram\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Node\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpasses\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msource_matcher_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     12\u001b[0m     check_subgraphs_connected,\n\u001b[1;32m     13\u001b[0m     get_source_partitions,\n\u001b[1;32m     14\u001b[0m     SourcePartition,\n\u001b[1;32m     15\u001b[0m )\n",
      "File \u001b[0;32m~/.py311/lib/python3.11/site-packages/torch/export/__init__.py:17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pytree\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpytree\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_compatibility\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compatibility\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpasses\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minfra\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpass_base\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PassResult\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpasses\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minfra\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpass_manager\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PassManager\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FileLike\n",
      "File \u001b[0;32m~/.py311/lib/python3.11/site-packages/torch/fx/passes/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      2\u001b[0m     graph_drawer,\n\u001b[1;32m      3\u001b[0m     graph_manipulation,\n\u001b[1;32m      4\u001b[0m     net_min_base,\n\u001b[1;32m      5\u001b[0m     operator_support,\n\u001b[1;32m      6\u001b[0m     param_fetch,\n\u001b[1;32m      7\u001b[0m     reinplace,\n\u001b[1;32m      8\u001b[0m     runtime_assert,\n\u001b[1;32m      9\u001b[0m     shape_prop,\n\u001b[1;32m     10\u001b[0m     split_module,\n\u001b[1;32m     11\u001b[0m     split_utils,\n\u001b[1;32m     12\u001b[0m     splitter_base,\n\u001b[1;32m     13\u001b[0m     tools_common,\n\u001b[1;32m     14\u001b[0m )\n",
      "File \u001b[0;32m~/.py311/lib/python3.11/site-packages/torch/fx/passes/graph_drawer.py:13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnode\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _format_arg, _get_qualified_name\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moperator_schemas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m normalize_function\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpasses\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mshape_prop\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TensorMetadata\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpydot\u001b[39;00m\n",
      "File \u001b[0;32m~/.py311/lib/python3.11/site-packages/torch/fx/passes/shape_prop.py:8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dispatch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m enable_python_dispatcher\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_guards\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m detect_fake_mode\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_subclasses\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmeta_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_sparse_any\n",
      "File \u001b[0;32m~/.py311/lib/python3.11/site-packages/torch/_dispatch/python.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# mypy: allow-untyped-defs\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mitertools\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01munittest\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmock\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcollections\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mabc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Iterator\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcontextlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m contextmanager\n",
      "File \u001b[0;32m/usr/local/pyenv/versions/3.11.11/lib/python3.11/unittest/__init__.py:66\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msuite\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseTestSuite, TestSuite\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TestLoader, defaultTestLoader\n\u001b[0;32m---> 66\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmain\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TestProgram, main\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrunner\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TextTestRunner, TextTestResult\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msignals\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m installHandler, registerResult, removeResult, removeHandler\n",
      "File \u001b[0;32m/usr/local/pyenv/versions/3.11.11/lib/python3.11/unittest/main.py:8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m loader, runner\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msignals\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m installHandler\n\u001b[1;32m     11\u001b[0m __unittest \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1230\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "NMCç³»ææ–™ã¨Alç•Œé¢ã®ä½“ç³»çš„æ§‹é€ æ§‹ç¯‰ãƒ»æœ€é©åŒ–ãƒ—ãƒ­ã‚°ãƒ©ãƒ \n",
    "ãƒªãƒã‚¦ãƒ ã‚¤ã‚ªãƒ³é›»æ± ãƒªã‚µã‚¤ã‚¯ãƒ«ç ”ç©¶ç”¨\n",
    "\n",
    "Features:\n",
    "- æ®µéšçš„æ§‹é€ æœ€é©åŒ–\n",
    "- çµ„æˆå¤‰å‹•NMCæ§‹é€ ã®è‡ªå‹•ç”Ÿæˆ\n",
    "- ä½“ç³»çš„ãªè¡¨é¢ãƒ»ç•Œé¢æ§‹ç¯‰\n",
    "- è¤‡æ•°ãƒŸãƒ©ãƒ¼æŒ‡æ•°å¯¾å¿œ\n",
    "- ã‚«ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°åœ§åŠ›ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å¯¾å¿œ\n",
    "\"\"\"\n",
    "# æ±ç”¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from IPython.display import display_png\n",
    "from IPython.display import Image as ImageWidget\n",
    "import ipywidgets as widgets\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.widgets import Slider\n",
    "from matplotlib.animation import PillowWriter\n",
    "import seaborn as sns\n",
    "import math\n",
    "import optuna\n",
    "import nglview as nv\n",
    "import os,sys,csv,glob,shutil,re,time\n",
    "from pathlib import Path\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "# sklearn\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "# ASE\n",
    "import ase\n",
    "from ase import Atoms, units\n",
    "from ase.units import Bohr,Rydberg,kJ,kB,fs,Hartree,mol,kcal\n",
    "from ase.io import read, write\n",
    "from ase.build import surface, molecule, add_adsorbate\n",
    "from ase.cluster.cubic import FaceCenteredCubic\n",
    "from ase.constraints import FixAtoms, FixedPlane, FixBondLength, ExpCellFilter\n",
    "# from ase.neb import SingleCalculatorNEB\n",
    "from ase.neb import NEB\n",
    "from ase.vibrations import Vibrations\n",
    "from ase.visualize import view\n",
    "from ase.optimize import QuasiNewton\n",
    "from ase.thermochemistry import IdealGasThermo\n",
    "from ase.build.rotate import minimize_rotation_and_translation\n",
    "from ase.visualize import view\n",
    "from ase.optimize import BFGS, LBFGS, FIRE\n",
    "from ase.md.velocitydistribution import MaxwellBoltzmannDistribution, Stationary\n",
    "from ase.md.verlet import VelocityVerlet\n",
    "from ase.md.langevin import Langevin\n",
    "from ase.md.nptberendsen import NPTBerendsen, Inhomogeneous_NPTBerendsen\n",
    "from ase.md import MDLogger\n",
    "from ase.io import read, write, Trajectory\n",
    "# from ase.calculators.dftd3 import DFTD3\n",
    "from ase.build import sort\n",
    "\n",
    "from sella import Sella, Constraints\n",
    "from torch_dftd.torch_dftd3_calculator import TorchDFTD3Calculator\n",
    "\n",
    "# PFP\n",
    "from pfp_api_client.pfp.calculators.ase_calculator import ASECalculator\n",
    "from pfp_api_client.pfp.estimator import Estimator\n",
    "from pfp_api_client.pfp.estimator import EstimatorCalcMode\n",
    "# calculator = pfp_estimator_fn(model_version='v7.0.0', calc_mode='CRYSTAL_U0_PLUS_D3')\n",
    "estimator = Estimator(calc_mode='CRYSTAL_U0_PLUS_D3')\n",
    "calculator = ASECalculator(estimator)\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "class NMCInterfaceBuilder:\n",
    "    \"\"\"NMC-Alç•Œé¢æ§‹é€ æ§‹ç¯‰ã‚¯ãƒ©ã‚¹\"\"\"\n",
    "    \n",
    "    def __init__(self, base_dir=\"/home/jovyan/Kaori/MD\"):\n",
    "        self.base_dir = base_dir\n",
    "        self.input_dir = os.path.join(base_dir, \"input\")\n",
    "        self.output_dir = os.path.join(base_dir, \"output\")\n",
    "        os.makedirs(self.output_dir, exist_ok=True)\n",
    "        \n",
    "        # è¨ˆç®—å™¨è¨­å®š\n",
    "        self.calculator = calculator\n",
    "        \n",
    "        # MilleræŒ‡æ•°ãƒªã‚¹ãƒˆï¼ˆé‡è¦åº¦é †ã€NMC111æœ€é »é¢ã‚’åæ˜ ï¼‰\n",
    "        self.miller_indices = [\n",
    "            (0, 0, 1),  # NMC(001) - æœ€å®‰å®šé¢ã€ãƒ—ãƒ¬ãƒ¼ãƒˆå½¢çŠ¶\n",
    "            (1, 0, 4),  # NMC(104) - ä¸­æ´»æ€§ã€å¤šé¢ä½“å½¢çŠ¶\n",
    "            (0, 1, 2),  # NMC(012) - é«˜æ´»æ€§ã€åˆ‡é ­å…«é¢ä½“å½¢çŠ¶\n",
    "            (0, 1, 0),  # NMC(010) - Liæ‹¡æ•£æ´»æ€§é¢\n",
    "            (1, 1, 1),  # Al(111) - Alæœ€å®‰å®šé¢\n",
    "            (1, 0, 0),  # Al(100), NMC(100) - åŸºæœ¬é¢\n",
    "            (1, 1, 0),  # Al(110), NMC(110) - å‰¯æ¬¡é¢\n",
    "        ]\n",
    "        \n",
    "        # ã‚«ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°åœ§åŠ›è¨­å®šï¼ˆMPaï¼‰\n",
    "        self.calendering_pressures = [10, 30, 60, 120, 200]  # å®Ÿç”¨ç¯„å›²\n",
    "        \n",
    "    def optimize_structure_systematic(self, atoms, name=\"structure\"):\n",
    "        \"\"\"æ®µéšçš„æ§‹é€ æœ€é©åŒ–\"\"\"\n",
    "        print(f\"=== {name}ã®æ§‹é€ æœ€é©åŒ–é–‹å§‹ ===\")\n",
    "        \n",
    "        atoms.calc = self.calculator\n",
    "        \n",
    "        # Step 1: æ ¼å­å®šæ•°æœ€é©åŒ–\n",
    "        print(\"Step 1: æ ¼å­å®šæ•°æœ€é©åŒ–\")\n",
    "        cell_opt = BFGS(UnitCellFilter(atoms), \n",
    "                       trajectory=f\"{self.output_dir}/{name}_cell_opt.traj\")\n",
    "        try:\n",
    "            cell_opt.run(fmax=0.01)\n",
    "            print(f\"æ ¼å­æœ€é©åŒ–å®Œäº†: {atoms.cell.cellpar()}\")\n",
    "        except Exception as e:\n",
    "            print(f\"æ ¼å­æœ€é©åŒ–è­¦å‘Š: {e}\")\n",
    "        \n",
    "        # Step 2: åŸå­ä½ç½®æœ€é©åŒ–\n",
    "        print(\"Step 2: åŸå­ä½ç½®æœ€é©åŒ–\")\n",
    "        pos_opt = BFGS(atoms, \n",
    "                      trajectory=f\"{self.output_dir}/{name}_pos_opt.traj\")\n",
    "        try:\n",
    "            pos_opt.run(fmax=0.005)\n",
    "            print(f\"ä½ç½®æœ€é©åŒ–å®Œäº†: ã‚¨ãƒãƒ«ã‚®ãƒ¼ = {atoms.get_potential_energy():.3f} eV\")\n",
    "        except Exception as e:\n",
    "            print(f\"ä½ç½®æœ€é©åŒ–è­¦å‘Š: {e}\")\n",
    "        \n",
    "        return atoms\n",
    "    \n",
    "    def makesurface_advanced(self, atoms, miller_indices=(1,0,0), layers=4, \n",
    "                           rep=[4,4,1], vacuum=15.0, fix_ratio=0.3, name=\"surface\"):\n",
    "        \"\"\"æ”¹è‰¯ç‰ˆè¡¨é¢ä½œæˆé–¢æ•°\"\"\"\n",
    "        print(f\"è¡¨é¢ä½œæˆ: {name} {miller_indices}é¢, {layers}å±¤\")\n",
    "        \n",
    "        # è¡¨é¢ä½œæˆ\n",
    "        slab = surface(atoms, miller_indices, layers, vacuum=vacuum)\n",
    "        slab = slab.repeat(rep)\n",
    "        \n",
    "        # ä½ç½®èª¿æ•´\n",
    "        positions = slab.get_positions()\n",
    "        z_min = positions[:, 2].min()\n",
    "        slab.set_positions(positions - [0, 0, z_min])\n",
    "        \n",
    "        # ä¸‹å±¤åŸå­ã®å›ºå®šï¼ˆfix_ratioåˆ†ã‚’å›ºå®šï¼‰\n",
    "        z_coords = slab.positions[:, 2]\n",
    "        z_max = z_coords.max()\n",
    "        z_threshold = z_coords.min() + (z_max - z_coords.min()) * fix_ratio\n",
    "        fixed_indices = [i for i, z in enumerate(z_coords) if z <= z_threshold]\n",
    "        \n",
    "        if fixed_indices:\n",
    "            constraint = FixAtoms(indices=fixed_indices)\n",
    "            slab.set_constraint(constraint)\n",
    "            print(f\"å›ºå®šåŸå­æ•°: {len(fixed_indices)}/{len(slab)}\")\n",
    "        \n",
    "        # æ§‹é€ æœ€é©åŒ–\n",
    "        slab = self.optimize_structure_systematic(slab, f\"{name}_{miller_indices}\")\n",
    "        \n",
    "        return slab\n",
    "    \n",
    "    def create_composition_variants(self, base_atoms, base_name=\"NMC\"):\n",
    "        \"\"\"çµ„æˆå¤‰å‹•NMCæ§‹é€ ã®ä½œæˆï¼ˆåŒ–å­¦é‡è«–ä¿æŒç½®æ›ï¼‰\"\"\"\n",
    "        print(f\"=== {base_name}ã®çµ„æˆå¤‰å‹•æ§‹é€ ä½œæˆ ===\")\n",
    "        \n",
    "        variants = {f\"{base_name}_pristine\": base_atoms.copy()}\n",
    "        \n",
    "        # å…ƒç´ ç½®æ›ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆåŒ–å­¦é‡è«–ä¿æŒï¼‰\n",
    "        substitution_patterns = [\n",
    "            # Niæ¸›å°‘ç³»ï¼ˆä»–å…ƒç´ ã§ç½®æ›ï¼‰\n",
    "            {\"reduce\": \"Ni\", \"increase\": [\"Mn\", \"Co\"], \"ratios\": [0.1, 0.2, 0.3]},\n",
    "            # Coæ¸›å°‘ç³»ï¼ˆNi richåŒ–ï¼‰\n",
    "            {\"reduce\": \"Co\", \"increase\": [\"Ni\"], \"ratios\": [0.2, 0.5, 0.8]},\n",
    "            # Mnæ¸›å°‘ç³»ï¼ˆNi richåŒ–ï¼‰\n",
    "            {\"reduce\": \"Mn\", \"increase\": [\"Ni\"], \"ratios\": [0.1, 0.2, 0.4]},\n",
    "            # äºŒå…ƒç´ ç½®æ›ï¼ˆCo+Mnæ¸›å°‘ â†’ Niå¢—åŠ ï¼‰\n",
    "            {\"reduce\": [\"Co\", \"Mn\"], \"increase\": [\"Ni\"], \"ratios\": [0.2, 0.4]},\n",
    "        ]\n",
    "        \n",
    "        for pattern in substitution_patterns:\n",
    "            reduce_elements = pattern[\"reduce\"] if isinstance(pattern[\"reduce\"], list) else [pattern[\"reduce\"]]\n",
    "            increase_elements = pattern[\"increase\"] if isinstance(pattern[\"increase\"], list) else [pattern[\"increase\"]]\n",
    "            ratios = pattern[\"ratios\"]\n",
    "            \n",
    "            for ratio in ratios:\n",
    "                variant_atoms = self._create_substituted_structure(\n",
    "                    base_atoms, reduce_elements, increase_elements, ratio, base_name\n",
    "                )\n",
    "                \n",
    "                if variant_atoms is not None:\n",
    "                    # çµ„æˆåä½œæˆ\n",
    "                    reduce_str = \"_\".join(reduce_elements)\n",
    "                    increase_str = \"_\".join(increase_elements)\n",
    "                    variant_name = f\"{base_name}_{reduce_str}to{increase_str}_{int(ratio*100)}\"\n",
    "                    \n",
    "                    # æ§‹é€ æœ€é©åŒ–\n",
    "                    variant_atoms = self.optimize_structure_systematic(variant_atoms, variant_name)\n",
    "                    variants[variant_name] = variant_atoms\n",
    "                    \n",
    "                    # çµ„æˆåˆ†æ\n",
    "                    composition = self._analyze_composition(variant_atoms)\n",
    "                    print(f\"ä½œæˆ: {variant_name}\")\n",
    "                    print(f\"  çµ„æˆ: {composition}\")\n",
    "        \n",
    "        return variants\n",
    "    \n",
    "    def _create_substituted_structure(self, base_atoms, reduce_elements, increase_elements, ratio, base_name):\n",
    "        \"\"\"åŒ–å­¦é‡è«–ä¿æŒç½®æ›æ§‹é€ ã®ä½œæˆ\"\"\"\n",
    "        variant_atoms = base_atoms.copy()\n",
    "        \n",
    "        # ç½®æ›å¯¾è±¡åŸå­ã®ç‰¹å®š\n",
    "        reduce_indices = []\n",
    "        for element in reduce_elements:\n",
    "            element_indices = [i for i, atom in enumerate(variant_atoms) if atom.symbol == element]\n",
    "            reduce_indices.extend(element_indices)\n",
    "        \n",
    "        if not reduce_indices:\n",
    "            print(f\"è­¦å‘Š: æ¸›å°‘å¯¾è±¡å…ƒç´  {reduce_elements} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "            return None\n",
    "        \n",
    "        # å¢—åŠ å¯¾è±¡åŸå­ã®ç‰¹å®š\n",
    "        increase_indices = []\n",
    "        for element in increase_elements:\n",
    "            element_indices = [i for i, atom in enumerate(variant_atoms) if atom.symbol == element]\n",
    "            increase_indices.extend(element_indices)\n",
    "        \n",
    "        # ç½®æ›æ•°ã®è¨ˆç®—\n",
    "        total_reduce = len(reduce_indices)\n",
    "        substitute_count = min(int(total_reduce * ratio), total_reduce)\n",
    "        \n",
    "        if substitute_count == 0:\n",
    "            return None\n",
    "        \n",
    "        # ãƒ©ãƒ³ãƒ€ãƒ é¸æŠï¼ˆå†ç¾æ€§ç¢ºä¿ï¼‰\n",
    "        random.seed(42)\n",
    "        selected_reduce = random.sample(reduce_indices, substitute_count)\n",
    "        \n",
    "        # ç½®æ›å®Ÿè¡Œ\n",
    "        if len(increase_elements) == 1:\n",
    "            # å˜ä¸€å…ƒç´ ã¸ã®ç½®æ›\n",
    "            new_symbol = increase_elements[0]\n",
    "            for idx in selected_reduce:\n",
    "                variant_atoms[idx].symbol = new_symbol\n",
    "        else:\n",
    "            # è¤‡æ•°å…ƒç´ ã¸ã®åˆ†æ•£ç½®æ›\n",
    "            for i, idx in enumerate(selected_reduce):\n",
    "                new_symbol = increase_elements[i % len(increase_elements)]\n",
    "                variant_atoms[idx].symbol = new_symbol\n",
    "        \n",
    "        return variant_atoms\n",
    "    \n",
    "    def _analyze_composition(self, atoms):\n",
    "        \"\"\"çµ„æˆåˆ†æ\"\"\"\n",
    "        from collections import Counter\n",
    "        symbols = [atom.symbol for atom in atoms]\n",
    "        composition = Counter(symbols)\n",
    "        \n",
    "        # é·ç§»é‡‘å±ã®ã¿ã®æ¯”ç‡è¨ˆç®—\n",
    "        tm_elements = ['Ni', 'Mn', 'Co']\n",
    "        tm_counts = {elem: composition.get(elem, 0) for elem in tm_elements}\n",
    "        total_tm = sum(tm_counts.values())\n",
    "        \n",
    "        if total_tm > 0:\n",
    "            tm_ratios = {elem: count/total_tm for elem, count in tm_counts.items()}\n",
    "            return f\"Li{composition.get('Li', 0)}[Ni{tm_ratios['Ni']:.2f}Mn{tm_ratios['Mn']:.2f}Co{tm_ratios['Co']:.2f}]O{composition.get('O', 0)}\"\n",
    "        else:\n",
    "            return str(dict(composition))\n",
    "    \n",
    "    def create_realistic_degradation_variants(self, base_atoms, base_name=\"NMC\"):\n",
    "        \"\"\"å®Ÿéš›ã®åŠ£åŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³ã«åŸºã¥ãçµ„æˆå¤‰å‹•\"\"\"\n",
    "        print(f\"=== {base_name}ã®åŠ£åŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³æ§‹é€ ä½œæˆ ===\")\n",
    "        \n",
    "        variants = {}\n",
    "        \n",
    "        # å®Ÿéš›ã®åŠ£åŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³\n",
    "        degradation_patterns = [\n",
    "            # è¡¨é¢Nié‚„å…ƒ (Ni2+ â†’ Ni0, è¡¨é¢ã§ã®Niæå¤±)\n",
    "            {\"name\": \"surface_Ni_reduction\", \"reduce\": \"Ni\", \"increase\": [\"Mn\"], \"ratio\": 0.1},\n",
    "            \n",
    "            # Coæº¶å‡º (é›»è§£æ¶²ä¸­ã¸ã®æº¶å‡º)\n",
    "            {\"name\": \"Co_dissolution\", \"reduce\": \"Co\", \"increase\": [\"Ni\"], \"ratio\": 0.3},\n",
    "            \n",
    "            # Mnæº¶å‡º (ä¸å‡åŒ–åå¿œã«ã‚ˆã‚‹Mnæå¤±)  \n",
    "            {\"name\": \"Mn_dissolution\", \"reduce\": \"Mn\", \"increase\": [\"Ni\"], \"ratio\": 0.2},\n",
    "            \n",
    "            # ãƒªã‚µã‚¤ã‚¯ãƒ«éç¨‹ã§ã®é¸æŠçš„é™¤å»\n",
    "            {\"name\": \"selective_Co_removal\", \"reduce\": \"Co\", \"increase\": [\"Ni\", \"Mn\"], \"ratio\": 0.7},\n",
    "            \n",
    "            # é«˜æ¸©å‡¦ç†ã«ã‚ˆã‚‹Co/Mnæå¤±\n",
    "            {\"name\": \"thermal_Co_Mn_loss\", \"reduce\": [\"Co\", \"Mn\"], \"increase\": [\"Ni\"], \"ratio\": 0.3},\n",
    "            \n",
    "            # æ¥µç«¯Ni richåŒ– (NMC111 â†’ NMC955ç›¸å½“)\n",
    "            {\"name\": \"extreme_Ni_rich\", \"reduce\": [\"Co\", \"Mn\"], \"increase\": [\"Ni\"], \"ratio\": 0.8},\n",
    "        ]\n",
    "        \n",
    "        for pattern in degradation_patterns:\n",
    "            reduce_elements = pattern[\"reduce\"] if isinstance(pattern[\"reduce\"], list) else [pattern[\"reduce\"]]\n",
    "            increase_elements = pattern[\"increase\"] if isinstance(pattern[\"increase\"], list) else [pattern[\"increase\"]]\n",
    "            ratio = pattern[\"ratio\"]\n",
    "            name = pattern[\"name\"]\n",
    "            \n",
    "            variant_atoms = self._create_substituted_structure(\n",
    "                base_atoms, reduce_elements, increase_elements, ratio, base_name\n",
    "            )\n",
    "            \n",
    "            if variant_atoms is not None:\n",
    "                variant_name = f\"{base_name}_{name}\"\n",
    "                \n",
    "                # æ§‹é€ æœ€é©åŒ–\n",
    "                variant_atoms = self.optimize_structure_systematic(variant_atoms, variant_name)\n",
    "                variants[variant_name] = variant_atoms\n",
    "                \n",
    "                # çµ„æˆåˆ†æ\n",
    "                composition = self._analyze_composition(variant_atoms)\n",
    "                print(f\"ä½œæˆ: {variant_name}\")\n",
    "                print(f\"  çµ„æˆ: {composition}\")\n",
    "                print(f\"  æƒ³å®šåŠ£åŒ–: {name}\")\n",
    "        \n",
    "        return variants\n",
    "    \n",
    "    def adjust_slab_size(self, slab, target_area=100.0):\n",
    "        \"\"\"ã‚¹ãƒ©ãƒ–ã‚µã‚¤ã‚ºã®èª¿æ•´ï¼ˆæ ¼å­ä¸æ•´åˆæœ€å°åŒ–ï¼‰\"\"\"\n",
    "        current_area = np.linalg.norm(np.cross(slab.cell[0], slab.cell[1]))\n",
    "        scale_factor = np.sqrt(target_area / current_area)\n",
    "        \n",
    "        rep_x = max(1, int(scale_factor))\n",
    "        rep_y = max(1, int(scale_factor))\n",
    "        \n",
    "        return slab.repeat([rep_x, rep_y, 1])\n",
    "    \n",
    "    def create_interface(self, slab1, slab2, separation=2.0, name=\"interface\"):\n",
    "        \"\"\"ç•Œé¢æ§‹é€ ä½œæˆ\"\"\"\n",
    "        print(f\"ç•Œé¢ä½œæˆ: {name}, åˆ†é›¢è·é›¢: {separation} Ã…\")\n",
    "        \n",
    "        # ã‚µã‚¤ã‚ºèª¿æ•´ï¼ˆæ ¼å­ä¸æ•´åˆã®æœ€å°åŒ–ï¼‰\n",
    "        area1 = np.linalg.norm(np.cross(slab1.cell[0], slab1.cell[1]))\n",
    "        area2 = np.linalg.norm(np.cross(slab2.cell[0], slab2.cell[1]))\n",
    "        target_area = max(area1, area2)\n",
    "        \n",
    "        slab1_adj = self.adjust_slab_size(slab1, target_area)\n",
    "        slab2_adj = self.adjust_slab_size(slab2, target_area)\n",
    "        \n",
    "        # ç•Œé¢ä½œæˆ\n",
    "        interface = stack(slab1_adj, slab2_adj, axis=2, distance=separation)\n",
    "        \n",
    "        # åˆ¶ç´„è¨­å®šï¼ˆä¸¡ç«¯ã‚’å›ºå®šï¼‰\n",
    "        z_coords = interface.positions[:, 2]\n",
    "        z_min, z_max = z_coords.min(), z_coords.max()\n",
    "        z_range = z_max - z_min\n",
    "        \n",
    "        # ä¸‹éƒ¨20%ã¨ä¸Šéƒ¨20%ã‚’å›ºå®š\n",
    "        bottom_threshold = z_min + z_range * 0.2\n",
    "        top_threshold = z_max - z_range * 0.2\n",
    "        \n",
    "        fixed_indices = [i for i, z in enumerate(z_coords) \n",
    "                        if z <= bottom_threshold or z >= top_threshold]\n",
    "        \n",
    "        if fixed_indices:\n",
    "            constraint = FixAtoms(indices=fixed_indices)\n",
    "            interface.set_constraint(constraint)\n",
    "        \n",
    "        # æ§‹é€ æœ€é©åŒ–\n",
    "        interface = self.optimize_structure_systematic(interface, name)\n",
    "        \n",
    "        return interface\n",
    "    \n",
    "    def build_al_structures(self):\n",
    "        \"\"\"Alæ§‹é€ ã®æ§‹ç¯‰\"\"\"\n",
    "        print(\"=== Alæ§‹é€ æ§‹ç¯‰ ===\")\n",
    "        \n",
    "        # Al bulkæ§‹é€ ä½œæˆ\n",
    "        al_bulk = ase_bulk('Al', 'fcc', a=4.046)\n",
    "        al_bulk = self.optimize_structure_systematic(al_bulk, \"Al_bulk\")\n",
    "        \n",
    "        # Alè¡¨é¢æ§‹ç¯‰\n",
    "        al_surfaces = {}\n",
    "        for miller in self.miller_indices[:3]:  # Alä¸»è¦é¢ã®ã¿\n",
    "            surface_name = f\"Al_{miller[0]}{miller[1]}{miller[2]}\"\n",
    "            al_slab = self.makesurface_advanced(al_bulk, miller_indices=miller, \n",
    "                                              name=surface_name)\n",
    "            al_surfaces[surface_name] = al_slab\n",
    "            \n",
    "        return al_bulk, al_surfaces\n",
    "    \n",
    "    def build_all_structures(self, cif_files):\n",
    "        \"\"\"å…¨æ§‹é€ ã®ä½“ç³»çš„æ§‹ç¯‰\"\"\"\n",
    "        print(\"=\" * 50)\n",
    "        print(\"NMC-Alç•Œé¢æ§‹é€ ä½“ç³»çš„æ§‹ç¯‰é–‹å§‹\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        all_structures = {}\n",
    "        all_surfaces = {}\n",
    "        all_interfaces = {}\n",
    "        \n",
    "        # 1. Alæ§‹é€ æ§‹ç¯‰\n",
    "        al_bulk, al_surfaces = self.build_al_structures()\n",
    "        all_structures[\"Al_bulk\"] = al_bulk\n",
    "        all_surfaces.update(al_surfaces)\n",
    "        \n",
    "        # 2. NMCç³»æ§‹é€ æ§‹ç¯‰\n",
    "        for material_name, cif_path in cif_files.items():\n",
    "            if not os.path.exists(cif_path):\n",
    "                print(f\"è­¦å‘Š: {cif_path}ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "                continue\n",
    "                \n",
    "            print(f\"\\n=== {material_name}æ§‹é€ æ§‹ç¯‰ ===\")\n",
    "            \n",
    "            # åŸºæœ¬æ§‹é€ èª­ã¿è¾¼ã¿ãƒ»æœ€é©åŒ–\n",
    "            base_atoms = read(cif_path)\n",
    "            base_atoms = self.optimize_structure_systematic(base_atoms, material_name)\n",
    "            all_structures[material_name] = base_atoms\n",
    "            \n",
    "            # çµ„æˆå¤‰å‹•æ§‹é€ ä½œæˆï¼ˆNMCç³»ã®ã¿ï¼‰\n",
    "            if \"NMC\" in material_name or \"Li\" in material_name:\n",
    "                # åŸºæœ¬çš„ãªçµ„æˆå¤‰å‹•\n",
    "                variants = self.create_composition_variants(base_atoms, material_name)\n",
    "                \n",
    "                # å®Ÿéš›ã®åŠ£åŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚‚è¿½åŠ \n",
    "                degradation_variants = self.create_realistic_degradation_variants(base_atoms, material_name)\n",
    "                variants.update(degradation_variants)\n",
    "                \n",
    "                all_structures.update(variants)\n",
    "            else:\n",
    "                variants = {material_name: base_atoms}\n",
    "            \n",
    "            # å„ææ–™ãƒ»çµ„æˆã®è¡¨é¢æ§‹ç¯‰\n",
    "            for variant_name, atoms in variants.items():\n",
    "                for miller in self.miller_indices:\n",
    "                    try:\n",
    "                        surface_name = f\"{variant_name}_{miller[0]}{miller[1]}{miller[2]}\"\n",
    "                        slab = self.makesurface_advanced(atoms, miller_indices=miller,\n",
    "                                                       name=surface_name)\n",
    "                        all_surfaces[surface_name] = slab\n",
    "                    except Exception as e:\n",
    "                        print(f\"è¡¨é¢ä½œæˆå¤±æ•—: {surface_name}, ã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "        \n",
    "        # 3. ç•Œé¢æ§‹é€ æ§‹ç¯‰\n",
    "        print(\"\\n=== ç•Œé¢æ§‹é€ æ§‹ç¯‰ ===\")\n",
    "        al_reference = al_surfaces[\"Al_111\"]  # Al(111)ã‚’åŸºæº–é¢ã¨ã™ã‚‹\n",
    "        \n",
    "        for surf_name, nmc_slab in all_surfaces.items():\n",
    "            if surf_name.startswith(\"Al_\"):\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                interface_name = f\"Al111_{surf_name}\"\n",
    "                interface = self.create_interface(al_reference, nmc_slab, \n",
    "                                                name=interface_name)\n",
    "                all_interfaces[interface_name] = interface\n",
    "            except Exception as e:\n",
    "                print(f\"ç•Œé¢ä½œæˆå¤±æ•—: {interface_name}, ã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "        \n",
    "        return all_structures, all_surfaces, all_interfaces\n",
    "    \n",
    "    def save_all_structures(self, structures, surfaces, interfaces):\n",
    "        \"\"\"å…¨æ§‹é€ ã®ä¿å­˜\"\"\"\n",
    "        print(\"\\n=== æ§‹é€ ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ ===\")\n",
    "        \n",
    "        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ\n",
    "        dirs = [\"bulk\", \"surfaces\", \"interfaces\"]\n",
    "        for d in dirs:\n",
    "            os.makedirs(os.path.join(self.output_dir, d), exist_ok=True)\n",
    "        \n",
    "        # ãƒãƒ«ã‚¯æ§‹é€ ä¿å­˜\n",
    "        for name, atoms in structures.items():\n",
    "            filepath = os.path.join(self.output_dir, \"bulk\", f\"{name}.traj\")\n",
    "            write(filepath, atoms)\n",
    "            print(f\"ä¿å­˜: {filepath}\")\n",
    "        \n",
    "        # è¡¨é¢æ§‹é€ ä¿å­˜\n",
    "        for name, atoms in surfaces.items():\n",
    "            filepath = os.path.join(self.output_dir, \"surfaces\", f\"{name}.traj\")\n",
    "            write(filepath, atoms)\n",
    "        \n",
    "        # ç•Œé¢æ§‹é€ ä¿å­˜\n",
    "        for name, atoms in interfaces.items():\n",
    "            filepath = os.path.join(self.output_dir, \"interfaces\", f\"{name}.traj\")\n",
    "            write(filepath, atoms)\n",
    "        \n",
    "        print(f\"ç·ä¿å­˜æ•°: ãƒãƒ«ã‚¯{len(structures)}, è¡¨é¢{len(surfaces)}, ç•Œé¢{len(interfaces)}\")\n",
    "    \n",
    "    def generate_analysis_summary(self, structures, surfaces, interfaces):\n",
    "        \"\"\"è§£æã‚µãƒãƒªãƒ¼ç”Ÿæˆ\"\"\"\n",
    "        summary = []\n",
    "        summary.append(\"=\" * 60)\n",
    "        summary.append(\"NMC-Alç•Œé¢æ§‹é€ æ§‹ç¯‰ã‚µãƒãƒªãƒ¼\")\n",
    "        summary.append(\"=\" * 60)\n",
    "        \n",
    "        summary.append(f\"\\næ§‹ç¯‰ã—ãŸæ§‹é€ æ•°:\")\n",
    "        summary.append(f\"  - ãƒãƒ«ã‚¯æ§‹é€ : {len(structures)}\")\n",
    "        summary.append(f\"  - è¡¨é¢æ§‹é€ : {len(surfaces)}\")\n",
    "        summary.append(f\"  - ç•Œé¢æ§‹é€ : {len(interfaces)}\")\n",
    "        \n",
    "        summary.append(f\"\\nä¸»è¦ææ–™:\")\n",
    "        composition_types = {\"pristine\": 0, \"substitution\": 0, \"degradation\": 0}\n",
    "        for name in structures.keys():\n",
    "            if \"pristine\" in name:\n",
    "                summary.append(f\"  - {name} (ç´”ç²‹çµ„æˆ)\")\n",
    "                composition_types[\"pristine\"] += 1\n",
    "            elif \"to\" in name and any(x in name for x in [\"Ni\", \"Co\", \"Mn\"]):\n",
    "                summary.append(f\"  - {name} (å…ƒç´ ç½®æ›)\")\n",
    "                composition_types[\"substitution\"] += 1\n",
    "            elif any(x in name for x in [\"reduction\", \"dissolution\", \"loss\", \"rich\"]):\n",
    "                summary.append(f\"  - {name} (åŠ£åŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³)\")\n",
    "                composition_types[\"degradation\"] += 1\n",
    "            else:\n",
    "                summary.append(f\"  - {name}\")\n",
    "        \n",
    "        summary.append(f\"\\nçµ„æˆå¤‰å‹•ã‚¿ã‚¤ãƒ—:\")\n",
    "        summary.append(f\"  - ç´”ç²‹çµ„æˆ: {composition_types['pristine']}\")\n",
    "        summary.append(f\"  - å…ƒç´ ç½®æ›ç³»: {composition_types['substitution']}\")\n",
    "        summary.append(f\"  - åŠ£åŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³ç³»: {composition_types['degradation']}\")\n",
    "        \n",
    "        summary.append(f\"\\næ¤œè¨ãƒŸãƒ©ãƒ¼æŒ‡æ•° (NMCæœ€é »é¢å„ªå…ˆ):\")\n",
    "        miller_descriptions = {\n",
    "            (0, 0, 1): \"æœ€å®‰å®šé¢ã€ãƒ—ãƒ¬ãƒ¼ãƒˆå½¢çŠ¶\",\n",
    "            (1, 0, 4): \"ä¸­æ´»æ€§ã€å¤šé¢ä½“å½¢çŠ¶\", \n",
    "            (0, 1, 2): \"é«˜æ´»æ€§ã€åˆ‡é ­å…«é¢ä½“å½¢çŠ¶\",\n",
    "            (0, 1, 0): \"Liæ‹¡æ•£æ´»æ€§é¢\",\n",
    "            (1, 1, 1): \"Alæœ€å®‰å®šé¢\",\n",
    "            (1, 0, 0): \"åŸºæœ¬é¢\",\n",
    "            (1, 1, 0): \"å‰¯æ¬¡é¢\"\n",
    "        }\n",
    "        for miller in self.miller_indices:\n",
    "            desc = miller_descriptions.get(miller, \"\")\n",
    "            summary.append(f\"  - {miller} : {desc}\")\n",
    "        \n",
    "        summary.append(f\"\\nåŒ–å­¦é‡è«–ä¿æŒç½®æ›ã®åˆ©ç‚¹:\")\n",
    "        summary.append(\"  - å®Ÿéš›ã®åŠ£åŒ–ãƒ»ãƒªã‚µã‚¤ã‚¯ãƒ«ãƒ—ãƒ­ã‚»ã‚¹ã‚’åæ˜ \")\n",
    "        summary.append(\"  - æ§‹é€ å®‰å®šæ€§ã®ç¶­æŒ\")\n",
    "        summary.append(\"  - ç•Œé¢ç‰¹æ€§ã®ç³»çµ±çš„è©•ä¾¡ãŒå¯èƒ½\")\n",
    "        \n",
    "        summary.append(f\"\\næ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:\")\n",
    "        summary.append(\"  1. ã‚«ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°åœ§åŠ›ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ (10-200 MPa)\")\n",
    "        summary.append(\"  2. ç†±å‡¦ç†ãƒ—ãƒ­ã‚»ã‚¹ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ (300-600Â°C)\")\n",
    "        summary.append(\"  3. å¼•å¼µè©¦é¨“ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³\")\n",
    "        summary.append(\"  4. çµ„æˆåˆ¥åˆ†é›¢åŠ¹ç‡è©•ä¾¡\")\n",
    "        summary.append(\"  5. æœ€é©ãƒªã‚µã‚¤ã‚¯ãƒ«æ¡ä»¶ã®æ±ºå®š\")\n",
    "        \n",
    "        summary_text = \"\\n\".join(summary)\n",
    "        \n",
    "        # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜\n",
    "        with open(os.path.join(self.output_dir, \"analysis_summary.txt\"), \"w\") as f:\n",
    "            f.write(summary_text)\n",
    "        \n",
    "        print(summary_text)\n",
    "        return summary_text\n",
    "\n",
    "def main():\n",
    "    \"\"\"ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°\"\"\"\n",
    "    \n",
    "    # ãƒ“ãƒ«ãƒ€ãƒ¼åˆæœŸåŒ–\n",
    "    builder = NMCInterfaceBuilder()\n",
    "    \n",
    "    # CIFãƒ•ã‚¡ã‚¤ãƒ«è¨­å®š\n",
    "    cif_files = {\n",
    "        \"NMC111\": \"/home/jovyan/Kaori/MD/input/Li3MnCoNiO6.cif\",\n",
    "        # ä»¥ä¸‹ã¯åˆ©ç”¨å¯èƒ½ãªå ´åˆã«è¿½åŠ \n",
    "        \"Li2O\": \"/home/jovyan/Kaori/MD/input/Li2O.cif\",\n",
    "        \"CoO\": \"/home/jovyan/Kaori/MD/input/CoO.cif\", \n",
    "        \"MnO\": \"/home/jovyan/Kaori/MD/input/MnO.cif\",\n",
    "        \"NiO\": \"/home/jovyan/Kaori/MD/input/NiO.cif\",\n",
    "    }\n",
    "    \n",
    "    # åˆ©ç”¨å¯èƒ½ãªCIFãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼\n",
    "    available_cifs = {name: path for name, path in cif_files.items() \n",
    "                     if os.path.exists(path)}\n",
    "    \n",
    "    if not available_cifs:\n",
    "        print(\"ã‚¨ãƒ©ãƒ¼: åˆ©ç”¨å¯èƒ½ãªCIFãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“\")\n",
    "        return\n",
    "    \n",
    "    print(f\"åˆ©ç”¨å¯èƒ½ãªCIFãƒ•ã‚¡ã‚¤ãƒ«: {list(available_cifs.keys())}\")\n",
    "    \n",
    "    # å…¨æ§‹é€ æ§‹ç¯‰\n",
    "    structures, surfaces, interfaces = builder.build_all_structures(available_cifs)\n",
    "    \n",
    "    # çµæœä¿å­˜\n",
    "    builder.save_all_structures(structures, surfaces, interfaces)\n",
    "    \n",
    "    # ã‚µãƒãƒªãƒ¼ç”Ÿæˆ\n",
    "    builder.generate_analysis_summary(structures, surfaces, interfaces)\n",
    "    \n",
    "    print(\"\\næ§‹ç¯‰å®Œäº†ï¼æ¬¡ã¯ã‚«ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã«é€²ã‚“ã§ãã ã•ã„ã€‚\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23dda38d-f81d-4e42-9395-97c871445682",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… è¡¨é¢ã‚¹ãƒ©ãƒ–ã®ä¿å­˜å…ˆ: 'MD_Workflow_Output/surfaces'\n",
      "ğŸ” '/home/jovyan/Kaori/MD/LiB_2/structure/output' ã‹ã‚‰ 74 å€‹ã®æœ€é©åŒ–æ¸ˆã¿ãƒãƒ«ã‚¯æ§‹é€ ã‚’ç™ºè¦‹ã—ã¾ã—ãŸã€‚\n",
      "\n",
      "--- ãƒãƒ«ã‚¯ 'NMC111_selective_Co_removal' ã‹ã‚‰è¡¨é¢ã‚’ç”Ÿæˆä¸­ ---\n",
      "  -> âš™ï¸  (1, 1, 1) é¢ã‚’ç”Ÿæˆä¸­...\n",
      "  -> âŒ ã‚¨ãƒ©ãƒ¼: (1, 1, 1) é¢ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚è©³ç´°: No EMT-potential for Li\n",
      "  -> âš™ï¸  (0, 0, 1) é¢ã‚’ç”Ÿæˆä¸­...\n",
      "  -> âŒ ã‚¨ãƒ©ãƒ¼: (0, 0, 1) é¢ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚è©³ç´°: 'EMT' object has no attribute 'nl'\n",
      "  -> âš™ï¸  (1, 0, 4) é¢ã‚’ç”Ÿæˆä¸­...\n",
      "  -> âŒ ã‚¨ãƒ©ãƒ¼: (1, 0, 4) é¢ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚è©³ç´°: 'EMT' object has no attribute 'nl'\n",
      "\n",
      "--- ãƒãƒ«ã‚¯ 'NMC111_extreme_Ni_rich' ã‹ã‚‰è¡¨é¢ã‚’ç”Ÿæˆä¸­ ---\n",
      "  -> âš™ï¸  (1, 1, 1) é¢ã‚’ç”Ÿæˆä¸­...\n",
      "  -> âŒ ã‚¨ãƒ©ãƒ¼: (1, 1, 1) é¢ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚è©³ç´°: No EMT-potential for Li\n",
      "  -> âš™ï¸  (0, 0, 1) é¢ã‚’ç”Ÿæˆä¸­...\n",
      "  -> âŒ ã‚¨ãƒ©ãƒ¼: (0, 0, 1) é¢ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚è©³ç´°: 'EMT' object has no attribute 'nl'\n",
      "  -> âš™ï¸  (1, 0, 4) é¢ã‚’ç”Ÿæˆä¸­...\n",
      "  -> âŒ ã‚¨ãƒ©ãƒ¼: (1, 0, 4) é¢ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚è©³ç´°: 'EMT' object has no attribute 'nl'\n",
      "\n",
      "--- ãƒãƒ«ã‚¯ 'NMC111_CotoNi_80_110_(1, 1, 0)' ã‹ã‚‰è¡¨é¢ã‚’ç”Ÿæˆä¸­ ---\n",
      "  -> âš™ï¸  (1, 1, 1) é¢ã‚’ç”Ÿæˆä¸­...\n",
      "  -> âŒ ã‚¨ãƒ©ãƒ¼: (1, 1, 1) é¢ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚è©³ç´°: No EMT-potential for Li\n",
      "  -> âš™ï¸  (0, 0, 1) é¢ã‚’ç”Ÿæˆä¸­...\n",
      "  -> âŒ ã‚¨ãƒ©ãƒ¼: (0, 0, 1) é¢ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚è©³ç´°: 'EMT' object has no attribute 'nl'\n",
      "  -> âš™ï¸  (1, 0, 4) é¢ã‚’ç”Ÿæˆä¸­...\n",
      "  -> âŒ ã‚¨ãƒ©ãƒ¼: (1, 0, 4) é¢ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚è©³ç´°: 'EMT' object has no attribute 'nl'\n",
      "\n",
      "--- ãƒãƒ«ã‚¯ 'Li2O_pristine_010_(0, 1, 0)' ã‹ã‚‰è¡¨é¢ã‚’ç”Ÿæˆä¸­ ---\n",
      "  -> âš™ï¸  (1, 1, 1) é¢ã‚’ç”Ÿæˆä¸­...\n",
      "  -> âŒ ã‚¨ãƒ©ãƒ¼: (1, 1, 1) é¢ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚è©³ç´°: No EMT-potential for Li\n",
      "  -> âš™ï¸  (0, 0, 1) é¢ã‚’ç”Ÿæˆä¸­...\n",
      "  -> âŒ ã‚¨ãƒ©ãƒ¼: (0, 0, 1) é¢ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚è©³ç´°: 'EMT' object has no attribute 'nl'\n",
      "  -> âš™ï¸  (1, 0, 4) é¢ã‚’ç”Ÿæˆä¸­...\n",
      "  -> âŒ ã‚¨ãƒ©ãƒ¼: (1, 0, 4) é¢ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚è©³ç´°: 'EMT' object has no attribute 'nl'\n",
      "\n",
      "--- ãƒãƒ«ã‚¯ 'Li2O_pristine_104_(1, 0, 4)' ã‹ã‚‰è¡¨é¢ã‚’ç”Ÿæˆä¸­ ---\n",
      "  -> âš™ï¸  (1, 1, 1) é¢ã‚’ç”Ÿæˆä¸­...\n",
      "  -> âŒ ã‚¨ãƒ©ãƒ¼: (1, 1, 1) é¢ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚è©³ç´°: No EMT-potential for Li\n",
      "  -> âš™ï¸  (0, 0, 1) é¢ã‚’ç”Ÿæˆä¸­...\n",
      "  -> âŒ ã‚¨ãƒ©ãƒ¼: (0, 0, 1) é¢ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚è©³ç´°: 'EMT' object has no attribute 'nl'\n",
      "  -> âš™ï¸  (1, 0, 4) é¢ã‚’ç”Ÿæˆä¸­...\n",
      "  -> âŒ ã‚¨ãƒ©ãƒ¼: (1, 0, 4) é¢ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚è©³ç´°: 'EMT' object has no attribute 'nl'\n",
      "\n",
      "--- ãƒãƒ«ã‚¯ 'NMC111_selective_Co_removal_110_(1, 1, 0)' ã‹ã‚‰è¡¨é¢ã‚’ç”Ÿæˆä¸­ ---\n",
      "  -> âš™ï¸  (1, 1, 1) é¢ã‚’ç”Ÿæˆä¸­...\n",
      "  -> âŒ ã‚¨ãƒ©ãƒ¼: (1, 1, 1) é¢ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚è©³ç´°: No EMT-potential for Li\n",
      "  -> âš™ï¸  (0, 0, 1) é¢ã‚’ç”Ÿæˆä¸­...\n",
      "  -> âŒ ã‚¨ãƒ©ãƒ¼: (0, 0, 1) é¢ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚è©³ç´°: 'EMT' object has no attribute 'nl'\n",
      "  -> âš™ï¸  (1, 0, 4) é¢ã‚’ç”Ÿæˆä¸­...\n",
      "  -> âŒ ã‚¨ãƒ©ãƒ¼: (1, 0, 4) é¢ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚è©³ç´°: 'EMT' object has no attribute 'nl'\n",
      "\n",
      "--- ãƒãƒ«ã‚¯ 'NMC111_Co_MntoNi_40_001_(0, 0, 1)' ã‹ã‚‰è¡¨é¢ã‚’ç”Ÿæˆä¸­ ---\n",
      "  -> âš™ï¸  (1, 1, 1) é¢ã‚’ç”Ÿæˆä¸­...\n",
      "  -> âŒ ã‚¨ãƒ©ãƒ¼: (1, 1, 1) é¢ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚è©³ç´°: No EMT-potential for Li\n",
      "  -> âš™ï¸  (0, 0, 1) é¢ã‚’ç”Ÿæˆä¸­...\n",
      "  -> âŒ ã‚¨ãƒ©ãƒ¼: (0, 0, 1) é¢ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚è©³ç´°: 'EMT' object has no attribute 'nl'\n",
      "  -> âš™ï¸  (1, 0, 4) é¢ã‚’ç”Ÿæˆä¸­...\n",
      "  -> âŒ ã‚¨ãƒ©ãƒ¼: (1, 0, 4) é¢ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚è©³ç´°: 'EMT' object has no attribute 'nl'\n",
      "\n",
      "--- ãƒãƒ«ã‚¯ 'NMC111_Co_MntoNi_40' ã‹ã‚‰è¡¨é¢ã‚’ç”Ÿæˆä¸­ ---\n",
      "  -> âš™ï¸  (1, 1, 1) é¢ã‚’ç”Ÿæˆä¸­...\n",
      "  -> âŒ ã‚¨ãƒ©ãƒ¼: (1, 1, 1) é¢ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚è©³ç´°: No EMT-potential for Li\n",
      "  -> âš™ï¸  (0, 0, 1) é¢ã‚’ç”Ÿæˆä¸­...\n",
      "  -> âŒ ã‚¨ãƒ©ãƒ¼: (0, 0, 1) é¢ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚è©³ç´°: 'EMT' object has no attribute 'nl'\n",
      "  -> âš™ï¸  (1, 0, 4) é¢ã‚’ç”Ÿæˆä¸­...\n",
      "  -> âŒ ã‚¨ãƒ©ãƒ¼: (1, 0, 4) é¢ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚è©³ç´°: 'EMT' object has no attribute 'nl'\n",
      "\n",
      "--- ãƒãƒ«ã‚¯ 'AlF3_0001_(0, 0, 1)' ã‹ã‚‰è¡¨é¢ã‚’ç”Ÿæˆä¸­ ---\n"
     ]
    },
    {
     "ename": "UnknownFileTypeError",
     "evalue": "Empty file: /home/jovyan/Kaori/MD/LiB_2/structure/output/AlF3_0001_(0, 0, 1)_pos_opt.traj",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownFileTypeError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 169\u001b[0m\n\u001b[1;32m    167\u001b[0m clear_output(wait\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    168\u001b[0m surface_gen \u001b[38;5;241m=\u001b[39m SurfaceGenerator(BULK_DIR, SURFACES_DIR, MILLER_INDICES, CALCULATOR)\n\u001b[0;32m--> 169\u001b[0m \u001b[43msurface_gen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_surface_creation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# STEP 2 & 3: ç•Œé¢ã®æ§‹ç¯‰ã¨æœ€é©åŒ–\u001b[39;00m\n\u001b[1;32m    172\u001b[0m interface_opt \u001b[38;5;241m=\u001b[39m InterfaceOptimizer(SURFACES_DIR, INTERFACES_DIR, CALCULATOR)\n",
      "Cell \u001b[0;32mIn[4], line 72\u001b[0m, in \u001b[0;36mSurfaceGenerator.run_surface_creation\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     70\u001b[0m bulk_files \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfind_optimized_bulk_files()\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m bulk_file \u001b[38;5;129;01min\u001b[39;00m bulk_files:\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_and_relax_surface\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbulk_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mâœ¨ å…¨ã¦ã®è¡¨é¢ç”Ÿæˆãƒ—ãƒ­ã‚»ã‚¹ãŒå®Œäº†ã—ã¾ã—ãŸã€‚\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 42\u001b[0m, in \u001b[0;36mSurfaceGenerator.create_and_relax_surface\u001b[0;34m(self, bulk_path)\u001b[0m\n\u001b[1;32m     39\u001b[0m base_name \u001b[38;5;241m=\u001b[39m bulk_path\u001b[38;5;241m.\u001b[39mstem\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_pos_opt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- ãƒãƒ«ã‚¯ \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m ã‹ã‚‰è¡¨é¢ã‚’ç”Ÿæˆä¸­ ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 42\u001b[0m bulk_atoms \u001b[38;5;241m=\u001b[39m \u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbulk_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m miller \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmiller_indices:\n\u001b[1;32m     45\u001b[0m     miller_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mstr\u001b[39m, miller))\n",
      "File \u001b[0;32m~/.py311/lib/python3.11/site-packages/ase/io/formats.py:808\u001b[0m, in \u001b[0;36mread\u001b[0;34m(filename, index, format, parallel, do_not_split_by_at_sign, **kwargs)\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    807\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 808\u001b[0m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mfiletype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    810\u001b[0m io \u001b[38;5;241m=\u001b[39m get_ioformat(\u001b[38;5;28mformat\u001b[39m)\n\u001b[1;32m    811\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(index, (\u001b[38;5;28mslice\u001b[39m, \u001b[38;5;28mstr\u001b[39m)):\n",
      "File \u001b[0;32m~/.py311/lib/python3.11/site-packages/ase/io/formats.py:998\u001b[0m, in \u001b[0;36mfiletype\u001b[0;34m(filename, read, guess)\u001b[0m\n\u001b[1;32m    995\u001b[0m     fd\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    997\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 998\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UnknownFileTypeError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEmpty file: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m filename)\n\u001b[1;32m   1000\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1001\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m match_magic(data)\u001b[38;5;241m.\u001b[39mname\n",
      "\u001b[0;31mUnknownFileTypeError\u001b[0m: Empty file: /home/jovyan/Kaori/MD/LiB_2/structure/output/AlF3_0001_(0, 0, 1)_pos_opt.traj"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3decb9f4-8c0d-4881-ad40-f3b39d2f6f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Trajectoryãƒ•ã‚¡ã‚¤ãƒ«ã®æ•´ç†ã¨ã€ãã‚Œã«åŸºã¥ãç•Œé¢æ§‹ç¯‰ãƒ»æœ€é©åŒ–ã‚’è‡ªå‹•åŒ–ã™ã‚‹ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã€‚\n",
    "\n",
    "STEP 1: Trajectoryãƒ•ã‚¡ã‚¤ãƒ«ã®åˆ†æã¨ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—\n",
    "  - 0KBã®.trajãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆå¤±æ•—ã—ãŸè¨ˆç®—ï¼‰ã‚’å‰Šé™¤\n",
    "  - æ­£å¸¸ãª.trajãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆæœŸ/æœ€çµ‚æ§‹é€ ã®.xyzã«å¤‰æ›ã—ã€å…ƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤\n",
    "\n",
    "STEP 2: ç•Œé¢ã®æ§‹ç¯‰ã¨æœ€é©åŒ–\n",
    "  - STEP 1ã§ç”Ÿæˆã•ã‚ŒãŸæœ€çµ‚æ§‹é€ (.xyz)ã‚’ç”¨ã„ã¦ç•Œé¢ã‚’æ§‹ç¯‰\n",
    "  - Matlantisã‚’ç”¨ã„ã¦åŸå­ä½ç½®ã®ã¿ã‚’æœ€é©åŒ–\n",
    "\"\"\"\n",
    "import os\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import nglview as nv\n",
    "\n",
    "# ASE\n",
    "from ase.io import read, write\n",
    "from ase.build import stack\n",
    "\n",
    "# Matlantis / PFP\n",
    "from matlantis_features.atoms import MatlantisAtoms\n",
    "from matlantis_features.features.common.opt import FireLBFGSASEOptFeature\n",
    "from matlantis_features.utils.calculators import pfp_estimator_fn\n",
    "from pfp_api_client.pfp.estimator import EstimatorCalcMode\n",
    "\n",
    "# --- STEP 1: Trajectoryãƒ•ã‚¡ã‚¤ãƒ«ã®æ•´ç†ã‚¯ãƒ©ã‚¹ ---\n",
    "class TrajectoryCleanup:\n",
    "    \"\"\"\n",
    "    .trajãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†æã—ã€.xyzã«å¤‰æ›ã—ã¦ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã™ã‚‹ã‚¯ãƒ©ã‚¹ã€‚\n",
    "    \"\"\"\n",
    "    def __init__(self, directory):\n",
    "        self.directory = Path(directory)\n",
    "        print(\"--- STEP 1: Trajectoryãƒ•ã‚¡ã‚¤ãƒ«ã®åˆ†æã¨æ•´ç†ã‚’é–‹å§‹ ---\")\n",
    "        if not self.directory.is_dir():\n",
    "            print(f\"ğŸ›‘ ã‚¨ãƒ©ãƒ¼: ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª '{self.directory}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚\")\n",
    "            self.files_to_process = []\n",
    "        else:\n",
    "            self.files_to_process = list(self.directory.glob(\"*.traj\"))\n",
    "            print(f\"ğŸ” '{self.directory}' ã‹ã‚‰ {len(self.files_to_process)} å€‹ã® .traj ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç™ºè¦‹ã€‚\")\n",
    "\n",
    "    def process_file(self, traj_path):\n",
    "        \"\"\"1ã¤ã®.trajãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã™ã‚‹ã€‚\"\"\"\n",
    "        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã‚’ç¢ºèª\n",
    "        try:\n",
    "            file_size = traj_path.stat().st_size\n",
    "        except FileNotFoundError:\n",
    "            return # ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—\n",
    "\n",
    "        # 0KBã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯å‰Šé™¤\n",
    "        if file_size == 0:\n",
    "            print(f\"  -> ğŸ—‘ï¸  0KBãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¾ã™: {traj_path.name}\")\n",
    "            os.remove(traj_path)\n",
    "            return\n",
    "\n",
    "        # æ­£å¸¸ãªãƒ•ã‚¡ã‚¤ãƒ«ã¯å¤‰æ›\n",
    "        base_name = traj_path.stem\n",
    "        initial_xyz_path = self.directory / f\"{base_name}_initial.xyz\"\n",
    "        final_xyz_path = self.directory / f\"{base_name}_final.xyz\"\n",
    "        \n",
    "        print(f\"  -> ğŸ”„ å¤‰æ›ä¸­: {traj_path.name}\")\n",
    "        try:\n",
    "            # Trajectoryã‹ã‚‰åˆæœŸæ§‹é€ ã¨æœ€çµ‚æ§‹é€ ã‚’èª­ã¿è¾¼ã¿\n",
    "            atoms_list = read(traj_path, index=\":\")\n",
    "            if not atoms_list:\n",
    "                print(f\"  -> âŒ èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ï¼ˆç©ºã®Trajectoryï¼‰: {traj_path.name}\")\n",
    "                os.remove(traj_path)\n",
    "                return\n",
    "\n",
    "            # .xyzãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜\n",
    "            write(str(initial_xyz_path), atoms_list[0])\n",
    "            write(str(final_xyz_path), atoms_list[-1])\n",
    "            \n",
    "            # å…ƒã®.trajãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤\n",
    "            os.remove(traj_path)\n",
    "            print(f\"  -> âœ”ï¸ å¤‰æ›æˆåŠŸã€å…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¾ã—ãŸ: {traj_path.name}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  -> âŒ å¤‰æ›ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ ({traj_path.name}): {e}\")\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"å…¨ã¦ã®å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ã«å¯¾ã—ã¦å‡¦ç†ã‚’å®Ÿè¡Œã™ã‚‹ã€‚\"\"\"\n",
    "        if not self.files_to_process:\n",
    "            print(\" -> å‡¦ç†å¯¾è±¡ã®.trajãƒ•ã‚¡ã‚¤ãƒ«ãŒãªã„ãŸã‚ã€ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚\")\n",
    "            return\n",
    "        for traj_file in self.files_to_process:\n",
    "            self.process_file(traj_file)\n",
    "        print(\"\\nâœ¨ STEP 1 å®Œäº†ã€‚\")\n",
    "\n",
    "\n",
    "# --- Matlantisæœ€é©åŒ–é–¢æ•° (å…±é€š) ---\n",
    "def run_matlantis_optimization(atoms, trajectory_path, fmax=0.05, name=\"structure\"):\n",
    "    print(f\"  -> Matlantisæœ€é©åŒ–é–‹å§‹ ({name}, fmax = {fmax}) ...\")\n",
    "    matlantis_atoms = MatlantisAtoms(atoms)\n",
    "    estimator_function = pfp_estimator_fn(\n",
    "        model_version='v7.0.0', calc_mode=EstimatorCalcMode.CRYSTAL_PLUS_D3\n",
    "    )\n",
    "    position_optimizer = FireLBFGSASEOptFeature(\n",
    "        estimator_fn=estimator_function, filter=False, trajectory=str(trajectory_path),\n",
    "        n_run=5000, fmax=fmax, show_progress_bar=True\n",
    "    )\n",
    "    try:\n",
    "        result = position_optimizer(matlantis_atoms)\n",
    "        optimized_atoms = result[\"atoms\"]\n",
    "        final_energy = optimized_atoms.get_potential_energy()\n",
    "        print(f\"  -> âœ”ï¸ æœ€é©åŒ–å®Œäº†ï¼ ã‚¨ãƒãƒ«ã‚®ãƒ¼: {final_energy:.3f} eV\")\n",
    "        atoms.set_positions(optimized_atoms.get_positions())\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"  -> âŒ æœ€é©åŒ–ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}\")\n",
    "        return False\n",
    "\n",
    "# --- STEP 2: ç•Œé¢æœ€é©åŒ–ã‚¯ãƒ©ã‚¹ ---\n",
    "class InterfaceOptimizer:\n",
    "    def __init__(self, surfaces_dir, interfaces_dir):\n",
    "        self.surfaces_dir = Path(surfaces_dir)\n",
    "        self.interfaces_dir = Path(interfaces_dir)\n",
    "        self.interfaces_dir.mkdir(parents=True, exist_ok=True)\n",
    "        print(f\"\\n--- STEP 2: ç•Œé¢æ§‹ç¯‰ãƒ»æœ€é©åŒ–ãƒ—ãƒ­ã‚»ã‚¹ã‚’é–‹å§‹ ---\")\n",
    "        print(f\"âœ… ç•Œé¢æ§‹é€ ã®ä¿å­˜å…ˆ: '{self.interfaces_dir}'\")\n",
    "\n",
    "    def find_and_categorize_surfaces(self):\n",
    "        print(f\"ğŸ” '{self.surfaces_dir}' ã‹ã‚‰æœ€é©åŒ–æ¸ˆã¿è¡¨é¢ (*_final.xyz) ã‚’åˆ†é¡ä¸­...\")\n",
    "        if not self.surfaces_dir.is_dir():\n",
    "             print(f\"ğŸ›‘ ã‚¨ãƒ©ãƒ¼: è¡¨é¢ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª '{self.surfaces_dir}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚\")\n",
    "             return [], []\n",
    "        \n",
    "        # æœ€çµ‚æ§‹é€ ã®.xyzãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ã‚’å¯¾è±¡ã«ã™ã‚‹\n",
    "        all_surfaces = list(self.surfaces_dir.glob(\"*_final.xyz\"))\n",
    "        \n",
    "        al_surfaces = [p for p in all_surfaces if \"Al_\" in p.stem]\n",
    "        cathode_surfaces = [p for p in all_surfaces if \"Al_\" not in p.stem]\n",
    "        print(f\"  - Alè¡¨é¢: {len(al_surfaces)}å€‹,  æ­£æ¥µæè¡¨é¢: {len(cathode_surfaces)}å€‹\")\n",
    "        return al_surfaces, cathode_surfaces\n",
    "\n",
    "    def create_and_optimize_interface(self, slab1_path, slab2_path):\n",
    "        # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰ä¸è¦ãªéƒ¨åˆ†ã‚’å‰Šé™¤ã—ã¦å‘½å\n",
    "        slab1_name = slab1_path.stem.replace('_pos_opt_final', '').replace('_cell_opt_final', '')\n",
    "        slab2_name = slab2_path.stem.replace('_pos_opt_final', '').replace('_cell_opt_final', '')\n",
    "        interface_name = f\"Interface_{slab1_name}_on_{slab2_name}\"\n",
    "        output_path = self.interfaces_dir / f\"{interface_name}.cif\"\n",
    "        \n",
    "        if output_path.exists():\n",
    "            print(f\"âœ… æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚ã‚Šã€ã‚¹ã‚­ãƒƒãƒ—: {output_path.name}\")\n",
    "            return\n",
    "\n",
    "        print(f\"\\n--- ç•Œé¢ã‚’æ§‹ç¯‰ãƒ»æœ€é©åŒ–: {slab1_name} + {slab2_name} ---\")\n",
    "        try:\n",
    "            slab1, slab2 = read(slab1_path), read(slab2_path)\n",
    "            interface = stack(slab1, slab2, axis=2, distance=2.5)\n",
    "            interface.pbc = (True, True, False)\n",
    "            interface.center(vacuum=10.0, axis=2)\n",
    "            \n",
    "            traj_path = self.interfaces_dir / f\"{interface_name}.traj\"\n",
    "            if run_matlantis_optimization(interface, traj_path, fmax=0.05, name=interface_name):\n",
    "                write(str(output_path), interface)\n",
    "                print(f\"  -> ğŸ’¾ ä¿å­˜ã—ã¾ã—ãŸ: {output_path.name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  -> âŒ ã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "\n",
    "    def run(self):\n",
    "        al_slabs, cathode_slabs = self.find_and_categorize_surfaces()\n",
    "        if not al_slabs and not cathode_slabs:\n",
    "            print(\" -> å‡¦ç†å¯¾è±¡ã®è¡¨é¢ãƒ•ã‚¡ã‚¤ãƒ«ãŒãªã„ãŸã‚ã€çµ‚äº†ã—ã¾ã™ã€‚\")\n",
    "            return\n",
    "            \n",
    "        print(\"\\n--- ã‚«ãƒ†ã‚´ãƒª1: Alã‚’å«ã‚€ç•Œé¢ ---\")\n",
    "        if al_slabs and cathode_slabs:\n",
    "            for al_path in al_slabs:\n",
    "                for cathode_path in cathode_slabs:\n",
    "                    self.create_and_optimize_interface(al_path, cathode_path)\n",
    "        else:\n",
    "            print(\" -> ã‚¹ã‚­ãƒƒãƒ— (Alè¡¨é¢ã¾ãŸã¯æ­£æ¥µæè¡¨é¢ã®ã„ãšã‚Œã‹ãŒä¸è¶³)\")\n",
    "            \n",
    "        print(\"\\n--- ã‚«ãƒ†ã‚´ãƒª2: Alã‚’å«ã¾ãªã„ç•Œé¢ ---\")\n",
    "        if len(cathode_slabs) >= 2:\n",
    "            for pair in itertools.combinations(cathode_slabs, 2):\n",
    "                self.create_and_optimize_interface(pair[0], pair[1])\n",
    "        else:\n",
    "            print(\" -> ã‚¹ã‚­ãƒƒãƒ— (æ­£æ¥µæè¡¨é¢ãŒ2ã¤æœªæº€)\")\n",
    "        print(\"\\nâœ¨ STEP 2 å®Œäº†ã€‚\")\n",
    "\n",
    "def show_results_viewer(results_dir):\n",
    "    print(f\"\\n--- ğŸ”¬ çµæœãƒ“ãƒ¥ãƒ¼ãƒ¯ãƒ¼: '{results_dir}' ---\")\n",
    "    files = sorted(list(Path(results_dir).glob(\"*.cif\")))\n",
    "    if not files:\n",
    "        print(\"è¡¨ç¤ºã§ãã‚‹æ§‹é€ ãŒã‚ã‚Šã¾ã›ã‚“ã€‚\")\n",
    "        return\n",
    "    options = {\"-- é¸æŠã—ã¦ãã ã•ã„ --\": None}\n",
    "    options.update({p.name: p for p in files})\n",
    "    widgets.interact(\n",
    "        lambda file_path: display(nv.show_ase(read(file_path)) if file_path else None),\n",
    "        file_path=widgets.Dropdown(options=options, description='Interface:', layout={'width': 'max-content'})\n",
    "    )\n",
    "\n",
    "# --- ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œéƒ¨ ---\n",
    "if __name__ == \"__main__\":\n",
    "    # ===== è¨­å®šé …ç›® =====\n",
    "    # 1. Trajectoryãƒ•ã‚¡ã‚¤ãƒ«ãŒä¿å­˜ã•ã‚Œã¦ã„ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª\n",
    "    OPTIMIZATION_OUTPUT_DIR = \"/home/jovyan/Kaori/MD/LiB_2/structure/output\"\n",
    "    \n",
    "    # 2. æœ€é©åŒ–ã—ãŸç•Œé¢ã®ä¿å­˜å…ˆ\n",
    "    INTERFACES_DIR = \"/home/jovyan/Kaori/MD/LiB_2/structure/output/optimized_interfaces\")\n",
    "    # ====================\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    # STEP 1: ãƒ¡ãƒ¢ãƒªç®¡ç† (traj -> xyzå¤‰æ› & å‰Šé™¤)\n",
    "    cleanup = TrajectoryCleanup(OPTIMIZATION_OUTPUT_DIR)\n",
    "    cleanup.run()\n",
    "    \n",
    "    # STEP 2: ç•Œé¢ã®æ§‹ç¯‰ã¨æœ€é©åŒ–\n",
    "    # è¡¨é¢ãƒ•ã‚¡ã‚¤ãƒ«ã‚‚åŒã˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã‚ã‚‹ãŸã‚ã€surfaces_dirã¨ã—ã¦åŒã˜ãƒ‘ã‚¹ã‚’æŒ‡å®š\n",
    "    interface_opt = InterfaceOptimizer(surfaces_dir=OPTIMIZATION_OUTPUT_DIR, interfaces_dir=INTERFACES_DIR)\n",
    "    interface_opt.run()\n",
    "    \n",
    "    print(\"\\n\\nâœ¨ å…¨ã¦ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãŒå®Œäº†ã—ã¾ã—ãŸã€‚ âœ¨\")\n",
    "    \n",
    "    # STEP 3: çµæœã®è¡¨ç¤º\n",
    "    show_results_viewer(INTERFACES_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5a180730-1523-4984-8420-254fb1c0744b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'standardize_cell' from 'ase.build' (/home/jovyan/.py311/lib/python3.11/site-packages/ase/build/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mase\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbuild\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m standardize_cell\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'standardize_cell' from 'ase.build' (/home/jovyan/.py311/lib/python3.11/site-packages/ase/build/__init__.py)"
     ]
    }
   ],
   "source": [
    "from ase.build import standardize_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681df43e-83a9-4f28-8107-0bd9e8d71b03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "1: Python 3.11",
   "language": "python",
   "name": "python311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
